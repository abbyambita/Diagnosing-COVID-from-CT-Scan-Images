{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "trial_bagan_kaggle.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abbyambita/Diagnosing-COVID-from-CT-Scan-Images/blob/main/trial_bagan_kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZBMv7HEE81_"
      },
      "source": [
        "https://github.com/seokinj/BAGAN/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrbY_X-nvYFM",
        "outputId": "2b1291a7-d529-4c86-82e8-b38cce5077d7"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncGTysumvhSl",
        "outputId": "7d5d6425-f336-49db-85d7-7b11b55c110e"
      },
      "source": [
        "import os \r\n",
        "\r\n",
        "os.chdir(\"/content/gdrive/My Drive\")\r\n",
        "\r\n",
        "#!ls  '/content/gdrive/My Drive/CS 284 Mini-Project/Code/'\r\n",
        "\r\n",
        "%cd \"/content/gdrive/My Drive/CS 284 Mini-Project/Code/\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/.shortcut-targets-by-id/1eVFVz23F6ROX0s10Oe3tT9HVzr502iW2/CS 284 Mini-Project/Code\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu35A4u7wEDx"
      },
      "source": [
        "from __future__ import print_function\r\n",
        "#%matplotlib inline\r\n",
        "import argparse\r\n",
        "import os\r\n",
        "import PIL\r\n",
        "import glob\r\n",
        "import xml.etree.ElementTree as ET\r\n",
        "import random\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.parallel\r\n",
        "import torch.backends.cudnn as cudnn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.utils.data\r\n",
        "import torchvision.datasets as dset\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torchvision.utils as vutils\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.animation as animation\r\n",
        "import seaborn as sns\r\n",
        "from IPython.display import HTML\r\n",
        "from torchvision.utils import save_image\r\n",
        "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\r\n",
        "from tqdm import tqdm_notebook as tqdm\r\n",
        "from IPython.display import clear_output\r\n",
        "from scipy.stats import truncnorm\r\n",
        "%matplotlib inline\r\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\r\n",
        "\r\n",
        "from easydict import EasyDict as edict\r\n",
        "from PIL import Image\r\n",
        "from collections import OrderedDict\r\n",
        "import yaml\r\n",
        "import imageio\r\n",
        "import numpy as np\r\n",
        "import torch.utils.data as data\r\n",
        "import torchvision.datasets as datasets\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import matplotlib\r\n",
        "matplotlib.use('Agg')\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import sys\r\n",
        "import time\r\n",
        "import math\r\n",
        "\r\n",
        "import scipy.misc\r\n",
        "import torchvision\r\n",
        "import torchvision.datasets as datasets\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6Ylm3_NuanS"
      },
      "source": [
        "workers = 6\r\n",
        "display= 10\r\n",
        "epoches= 100\r\n",
        "test_epoches= 30\r\n",
        "batch_size= 32\r\n",
        "base_lr= 0.0002\r\n",
        "beta1= 0.5\r\n",
        "ano_para= 0.1\r\n",
        "image_size= 64 \r\n",
        "z_dim= 100\r\n",
        "c_dim= 3\r\n",
        "gf_dim= 64\r\n",
        "df_dim= 64\r\n",
        "#class_num= 10\r\n",
        "class_num= 2\r\n",
        "pretrained = True\r\n",
        "\r\n",
        "dir = \"epochs=\"+str(epoches)+\"_lr=\"+str(base_lr)+\"_batch_size=\"+str(batch_size)\r\n",
        "checkpoint_dir = \"model_backup/bagan/kaggle/\"+dir\r\n",
        "save_dir = \"plots/bagan/kaggle/\"+dir\r\n",
        "distribution_dir =\"model_result/bagan/kaggle/\"+dir+\"/distribution\"\r\n",
        "output_images_dir = \"bagan_output_images/kaggle/\"+dir\r\n",
        "\r\n",
        "os.makedirs(\"model_result/bagan/kaggle/\"+dir, exist_ok=True)\r\n",
        "os.makedirs(\"plots/bagan/kaggle/\"+dir, exist_ok=True)\r\n",
        "os.makedirs(\"model_backup/bagan/kaggle/\"+dir, exist_ok=True)\r\n",
        "os.makedirs(output_images_dir, exist_ok=True)\r\n",
        "\r\n",
        "os.makedirs(\"model_result/bagan/kaggle/\"+dir+\"/distribution\", exist_ok=True)\r\n",
        "\r\n",
        "os.makedirs(save_dir+\"/accuracy\", exist_ok=True)\r\n",
        "os.makedirs(save_dir+\"/loss\", exist_ok=True)\r\n",
        "os.makedirs(checkpoint_dir+\"/gan\", exist_ok=True)\r\n",
        "os.makedirs(checkpoint_dir+\"/vae\", exist_ok=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-tWCNsN0c-g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3QUSZYhy9T5"
      },
      "source": [
        "def load_images(batch_size, image_size):\r\n",
        "  dataroot = \"revised-kaggle-validation/train\"\r\n",
        "\r\n",
        "  dataset = dset.ImageFolder(root=dataroot,\r\n",
        "                            transform=transforms.Compose([\r\n",
        "                                transforms.Resize(image_size),\r\n",
        "                                transforms.RandomHorizontalFlip(),\r\n",
        "                                transforms.CenterCrop(image_size),\r\n",
        "                                transforms.ToTensor(),\r\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\r\n",
        "                            ]))\r\n",
        "  \r\n",
        "  \r\n",
        "  dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,shuffle=True, num_workers=workers)\r\n",
        "\r\n",
        "  return dataloader"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EJwL7DAzXXa",
        "outputId": "6c2d9c02-2ee2-49e2-ddd7-3724b5b55184"
      },
      "source": [
        "dataloader = load_images(32, 128)\r\n",
        "print(len(dataloader))\r\n",
        "# real_batch = iter(dataloader).next()\r\n",
        "# plt.figure(figsize=(15,15))\r\n",
        "# plt.axis(\"off\")\r\n",
        "# plt.title(\"Training Images\")\r\n",
        "# image = np.transpose(vutils.make_grid(real_batch[0].to(device), normalize=True).cpu(),axes=(1,2,0))\r\n",
        "# plt.imshow(image)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoXkR1rPnm70"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D58t3IfNW_pC"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "\r\n",
        "# Generator\r\n",
        "class Decoder(nn.Module):\r\n",
        "\tdef __init__(self, z_dim, c_dim, gf_dim):\r\n",
        "\t\tsuper(Decoder, self).__init__()\r\n",
        "\r\n",
        "\t\tself.convTrans0 = nn.ConvTranspose2d(z_dim, gf_dim*8, 4, 1, 0, bias=False)\r\n",
        "\t\tself.bn0 = nn.BatchNorm2d(gf_dim*8)\r\n",
        "\t\tself.relu0 = nn.ReLU(inplace=True)\r\n",
        "\t\t\r\n",
        "\t\tself.convTrans1 = nn.ConvTranspose2d(gf_dim*8, gf_dim*4, 4, 2, 1, bias=False)\r\n",
        "\t\tself.bn1 = nn.BatchNorm2d(gf_dim*4)\r\n",
        "\t\tself.relu1 = nn.ReLU(inplace=True)\r\n",
        "\r\n",
        "\t\tself.convTrans2 = nn.ConvTranspose2d(gf_dim*4, gf_dim*2, 4, 2, 1, bias=False)\r\n",
        "\t\tself.bn2 = nn.BatchNorm2d(gf_dim*2)\r\n",
        "\t\tself.relu2 = nn.ReLU(inplace=True)\r\n",
        "\r\n",
        "\t\tself.convTrans3 = nn.ConvTranspose2d(gf_dim*2, gf_dim, 4, 2, 1, bias=False)\r\n",
        "\t\tself.bn3 = nn.BatchNorm2d(gf_dim)\r\n",
        "\t\tself.relu3 = nn.ReLU(inplace=True)\r\n",
        "\r\n",
        "\t\tself.convTrans4 = nn.ConvTranspose2d(gf_dim, c_dim, 4, 2, 1, bias=False)\r\n",
        "\t\tself.tanh = nn.Tanh()\r\n",
        "\r\n",
        "\t\tfor m in self.modules():\r\n",
        "\t\t\t\tif isinstance(m, nn.ConvTranspose2d):\r\n",
        "\t\t\t\t\t\tm.weight.data.normal_(0.0, 0.02)\r\n",
        "\t\t\t\t\t\tif m.bias is not None:\r\n",
        "\t\t\t\t\t\t\t\tm.bias.data.zero_()\r\n",
        "\r\n",
        "\tdef forward(self, z):\r\n",
        "\t\th0 = self.relu0(self.bn0(self.convTrans0(z)))\r\n",
        "\t\th1 = self.relu1(self.bn1(self.convTrans1(h0)))\r\n",
        "\t\th2 = self.relu2(self.bn2(self.convTrans2(h1)))\r\n",
        "\t\th3 = self.relu3(self.bn3(self.convTrans3(h2)))\r\n",
        "\t\th4 = self.convTrans4(h3)\r\n",
        "\t\toutput = self.tanh(h4)\r\n",
        "\t\treturn output # (c_dim, 64, 64)\r\n",
        "\r\n",
        "# Discriminator\r\n",
        "class Encoder(nn.Module): \r\n",
        "\tdef __init__(self, z_dim, c_dim, df_dim):\r\n",
        "\t\tsuper(Encoder, self).__init__()\r\n",
        "\t\tself.df_dim = df_dim\r\n",
        "\r\n",
        "\t\tself.conv0 = nn.Conv2d(c_dim, df_dim, 4, 2, 1, bias=False)\r\n",
        "\t\tself.relu0 = nn.LeakyReLU(0.2, inplace=True)\r\n",
        "\t\t\r\n",
        "\t\tself.conv1 = nn.Conv2d(df_dim, df_dim*2, 4, 2, 1, bias=False)\r\n",
        "\t\tself.bn1 = nn.BatchNorm2d(df_dim*2)\r\n",
        "\t\tself.relu1 = nn.LeakyReLU(0.2, inplace=True)\r\n",
        "\r\n",
        "\t\tself.conv2 = nn.Conv2d(df_dim*2, df_dim*4, 4, 2, 1, bias=False)\r\n",
        "\t\tself.bn2 = nn.BatchNorm2d(df_dim*4)\r\n",
        "\t\tself.relu2 = nn.LeakyReLU(0.2, inplace=True)\r\n",
        "\r\n",
        "\t\tself.conv3 = nn.Conv2d(df_dim*4, df_dim*8, 4, 2, 1, bias=False)\r\n",
        "\t\tself.bn3 = nn.BatchNorm2d(df_dim*8)\r\n",
        "\t\tself.relu3 = nn.LeakyReLU(0.2, inplace=True)\r\n",
        "\r\n",
        "\t\tself.fc_z1 = nn.Linear(df_dim*8*4*4, z_dim)\r\n",
        "\t\tself.fc_z2 = nn.Linear(df_dim*8*4*4, z_dim)\r\n",
        "\r\n",
        "\t\t#self.conv4 = nn.Conv2d(df_dim*8, 1, 4, 1, 0, bias=False)\r\n",
        "\r\n",
        "\t\tfor m in self.modules():\r\n",
        "\t\t\t\tif isinstance(m, nn.Conv2d):\r\n",
        "\t\t\t\t\t\tm.weight.data.normal_(0.0, 0.02)\r\n",
        "\t\t\t\t\t\tif m.bias is not None:\r\n",
        "\t\t\t\t\t\t\t\tm.bias.data.zero_()\r\n",
        "\r\n",
        "\tdef forward(self, input):\r\n",
        "\t\th0 = self.relu0(self.conv0(input))\r\n",
        "\t\th1 = self.relu1(self.bn1(self.conv1(h0)))\r\n",
        "\t\th2 = self.relu2(self.bn2(self.conv2(h1)))\r\n",
        "\t\th3 = self.relu3(self.bn3(self.conv3(h2)))\r\n",
        "\t\t\r\n",
        "\t\tmu = self.fc_z1(h3.view(-1, self.df_dim*8*4*4))\t# (1, 128*8*4*4)\r\n",
        "\t\tsigma = self.fc_z2(h3.view(-1, self.df_dim*8*4*4))\r\n",
        "\t\treturn mu,sigma # by squeeze, get just float not float Tenosor\r\n",
        "\r\n",
        "\r\n",
        "class Generator(nn.Module):\r\n",
        "        def __init__(self, z_dim, c_dim, gf_dim):\r\n",
        "                super(Generator, self).__init__()\r\n",
        "\r\n",
        "                self.convTrans0 = nn.ConvTranspose2d(z_dim, gf_dim*8, 4, 1, 0, bias=False)\r\n",
        "                self.bn0 = nn.BatchNorm2d(gf_dim*8)\r\n",
        "                self.relu0 = nn.ReLU(inplace=True)\r\n",
        "\r\n",
        "                self.convTrans1 = nn.ConvTranspose2d(gf_dim*8, gf_dim*4, 4, 2, 1, bias=False)\r\n",
        "                self.bn1 = nn.BatchNorm2d(gf_dim*4)\r\n",
        "                self.relu1 = nn.ReLU(inplace=True)\r\n",
        "\r\n",
        "                self.convTrans2 = nn.ConvTranspose2d(gf_dim*4, gf_dim*2, 4, 2, 1, bias=False)\r\n",
        "                self.bn2 = nn.BatchNorm2d(gf_dim*2)\r\n",
        "                self.relu2 = nn.ReLU(inplace=True)\r\n",
        "\r\n",
        "                self.convTrans3 = nn.ConvTranspose2d(gf_dim*2, gf_dim, 4, 2, 1, bias=False)\r\n",
        "                self.bn3 = nn.BatchNorm2d(gf_dim)\r\n",
        "                self.relu3 = nn.ReLU(inplace=True)\r\n",
        "\r\n",
        "                self.convTrans4 = nn.ConvTranspose2d(gf_dim, c_dim, 4, 2, 1, bias=False)\r\n",
        "                self.tanh = nn.Tanh()\r\n",
        "\r\n",
        "\r\n",
        "        def forward(self, z):\r\n",
        "                h0 = self.relu0(self.bn0(self.convTrans0(z)))\r\n",
        "                h1 = self.relu1(self.bn1(self.convTrans1(h0)))\r\n",
        "                h2 = self.relu2(self.bn2(self.convTrans2(h1)))\r\n",
        "                h3 = self.relu3(self.bn3(self.convTrans3(h2)))\r\n",
        "                h4 = self.convTrans4(h3)\r\n",
        "                output = self.tanh(h4)\r\n",
        "                return output # (c_dim, 64, 64)\r\n",
        "\r\n",
        "class _ganLokaggles(nn.Module):\r\n",
        "    '''\r\n",
        "    Layer of the GAN logits of the discriminator\r\n",
        "    The layer gets class logits as inputs and calculates GAN logits to\r\n",
        "    differentiate real and fake images in a numerical stable way\r\n",
        "    '''\r\n",
        "    def __init__(self, num_classes):\r\n",
        "        '''\r\n",
        "        :param num_classes: Number of real data classes (10 for SVHN)\r\n",
        "        '''\r\n",
        "        super(_ganLogits, self).__init__()\r\n",
        "        self.num_classes = num_classes\r\n",
        "\r\n",
        "    def forward(self, class_logits):\r\n",
        "        '''\r\n",
        "        :param class_logits: Unscaled log probabilities of house numbers\r\n",
        "        '''\r\n",
        "\r\n",
        "        # Set gan_logits such that P(input is real | input) = sigmoid(gan_logits).\r\n",
        "        # Keep in mind that class_logits gives you the probability distribution over all the real\r\n",
        "        # classes and the fake class. You need to work out how to transform this multiclass softmax\r\n",
        "        # distribution into a binary real-vs-fake decision that can be described with a sigmoid.\r\n",
        "        # Numerical stability is very important.\r\n",
        "        # You'll probably need to use this numerical stability trick:\r\n",
        "        # log sum_i exp a_i = m + log sum_i exp(a_i - m).\r\n",
        "        # This is numerically stable when m = max_i a_i.\r\n",
        "        # (It helps to think about what goes wrong when...\r\n",
        "        #   1. One value of a_i is very large\r\n",
        "        #   2. All the values of a_i are very negative\r\n",
        "        # This trick and this value of m fix both those cases, but the naive implementation and\r\n",
        "        # other values of m encounter various problems)\r\n",
        "        real_class_logits, fake_class_logits = torch.split(class_logits, self.num_classes, dim=1)\r\n",
        "        fake_class_logits = torch.squeeze(fake_class_logits)\r\n",
        "\r\n",
        "        max_val, _ = torch.max(real_class_logits, 1, keepdim=True)\r\n",
        "        stable_class_logits = real_class_logits - max_val\r\n",
        "        max_val = torch.squeeze(max_val)\r\n",
        "        gan_logits = torch.log(torch.sum(torch.exp(stable_class_logits), 1)) + max_val - fake_class_logits\r\n",
        "\r\n",
        "        return gan_logits\t# [128]\r\n",
        "\r\n",
        "class Discriminator(nn.Module):\r\n",
        "        def __init__(self, z_dim, c_dim, df_dim, class_num):\r\n",
        "                super(Discriminator, self).__init__()\r\n",
        "                self.df_dim = df_dim\r\n",
        "\r\n",
        "                self.conv0 = nn.Conv2d(c_dim, df_dim, 4, 2, 1, bias=False)\r\n",
        "                self.relu0 = nn.LeakyReLU(0.2, inplace=True)\r\n",
        "\r\n",
        "                self.conv1 = nn.Conv2d(df_dim, df_dim*2, 4, 2, 1, bias=False)\r\n",
        "                self.bn1 = nn.BatchNorm2d(df_dim*2)\r\n",
        "                self.relu1 = nn.LeakyReLU(0.2, inplace=True)\r\n",
        "\r\n",
        "                self.conv2 = nn.Conv2d(df_dim*2, df_dim*4, 4, 2, 1, bias=False)\r\n",
        "                self.bn2 = nn.BatchNorm2d(df_dim*4)\r\n",
        "                self.relu2 = nn.LeakyReLU(0.2, inplace=True)\r\n",
        "\r\n",
        "                self.conv3 = nn.Conv2d(df_dim*4, df_dim*8, 4, 2, 1, bias=False)\r\n",
        "                self.bn3 = nn.BatchNorm2d(df_dim*8)\r\n",
        "                self.relu3 = nn.LeakyReLU(0.2, inplace=True)\r\n",
        "\r\n",
        "\t\t#self.fc_z = nn.Linear(df_dim*8*4*4, z_dim)\r\n",
        "                self.fc_aux = nn.Linear(df_dim*8*4*4, class_num+1)\r\n",
        "                self.softmax = nn.LogSoftmax()\r\n",
        "\r\n",
        "                for m in self.modules():\r\n",
        "                        if isinstance(m, nn.Linear):\r\n",
        "                                m.weight.data.normal_(0.0, 0.02)\r\n",
        "                                if m.bias is not None:\r\n",
        "                                        m.bias.data.zero_()\r\n",
        "\r\n",
        "\r\n",
        "        def forward(self, input):\r\n",
        "                h0 = self.relu0(self.conv0(input))\r\n",
        "                h1 = self.relu1(self.bn1(self.conv1(h0)))\r\n",
        "                h2 = self.relu2(self.bn2(self.conv2(h1)))\r\n",
        "                h3 = self.relu3(self.bn3(self.conv3(h2)))\r\n",
        "                #cl = self.class_logistics(h3.view(-1, self.df_dim*8*4*4))\r\n",
        "                #gl = self.gan_logistics(cl)    \r\n",
        "                output = self.softmax(self.fc_aux(h3.view(-1, self.df_dim*8*4*4)))\r\n",
        "                return h3, output\r\n",
        "                #return h3, output.view(-1,1).squeeze(1) # by squeeze, get just float not float Tenosor"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRU147caRRFw"
      },
      "source": [
        "def conditional_latent_generator(distribution, class_num, batch):\r\n",
        "\tclass_labels = torch.randint(0, class_num, (batch,), dtype=torch.long)\r\n",
        "\tfake_z = distribution[class_labels[0].item()].sample((1,))\r\n",
        "\tfor c in class_labels[1:]:\r\n",
        "\t\tfake_z = torch.cat((fake_z, distribution[c.item()].sample((1,))), dim=0)\r\n",
        "\treturn fake_z, class_labels"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFjMloLlRgZk"
      },
      "source": [
        "def batch2one(Z, y, z, class_num):\r\n",
        "\tfor i in range(y.shape[0]):\r\n",
        "\t\tZ[y[i]] = torch.cat((Z[y[i]], z[i].cpu()), dim=0) # Z[label][0] should be deleted..\r\n",
        "\treturn Z\t\t\t\r\n",
        "\t\r\n",
        "class AverageMeter(object):\r\n",
        "    \"\"\" Computes ans stores the average and current value\"\"\"\r\n",
        "    def __init__(self):\r\n",
        "        self.reset()\r\n",
        "    \r\n",
        "    def reset(self):\r\n",
        "        self.val = 0.\r\n",
        "        self.avg = 0.\r\n",
        "        self.sum = 0.\r\n",
        "        self.count = 0\r\n",
        "    \r\n",
        "    def update(self, val, n=1):\r\n",
        "        self.val = val\r\n",
        "        self.sum += val * n\r\n",
        "        self.count += n\r\n",
        "        self.avg = self.sum / self.count\r\n",
        "\r\n",
        "def one_hot(x, num_classes):\r\n",
        "        '''\r\n",
        "        One-hot encoding of the vector of classes. It uses number of classes + 1 to\r\n",
        "        encode fake images\r\n",
        "        :param x: vector of output classes to one-hot encode\r\n",
        "        :return: one-hot encoded version of the input vector\r\n",
        "        '''\r\n",
        "        label_numpy = x.data.cpu().numpy()\r\n",
        "        label_onehot = np.zeros((label_numpy.shape[0], num_classes + 1))\r\n",
        "        label_onehot[np.arange(label_numpy.shape[0]), label_numpy] = 1\r\n",
        "        return torch.FloatTensor(label_onehot)\r\n",
        "\r\n",
        "\r\n",
        "def weights_init(m):\r\n",
        "        classname = m.__class__.__name__\r\n",
        "        if classname.find('Conv') != -1:\r\n",
        "                m.weight.data.normal_(0.0, 0.02)\r\n",
        "        elif classname.find('BatchNorm') != -1:\r\n",
        "                m.weight.data.normal_(1.0, 0.02)\r\n",
        "                m.bias.data.fill_(0)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCst51DRRkkW"
      },
      "source": [
        "def save_checkpoint(state, filename='checkpoint'):\r\n",
        "    torch.save(state, filename + '.pth.tar')\r\n",
        "\r\n",
        "def print_gan_log(epoch, epoches, iteration, iters, learning_rate,\r\n",
        "              display, batch_time, data_time, D_losses, G_losses):\r\n",
        "    print('epoch: [{}/{}] iteration: [{}/{}]\\t'\r\n",
        "          'Learning rate: {}'.format(epoch, epoches, iteration, iters, learning_rate))\r\n",
        "    print('Time {batch_time.sum:.3f}s / {0}iters, ({batch_time.avg:.3f})\\t'\r\n",
        "          'Data load {data_time.sum:.3f}s / {0}iters, ({data_time.avg:3f})\\n'\r\n",
        "          'Loss_D = {loss_D.val:.8f} (ave = {loss_D.avg:.8f})\\n'\r\n",
        "          'Loss_G = {loss_G.val:.8f} (ave = {loss_G.avg:.8f})\\n'.format(\r\n",
        "              display, batch_time=batch_time,\r\n",
        "              data_time=data_time, loss_D=D_losses, loss_G=G_losses))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocAcgo24RxDa"
      },
      "source": [
        "#Clear\r\n",
        "def print_vae_log(epoch, epoches, iteration, iters, learning_rate,\r\n",
        "              display, batch_time, data_time, losses):\r\n",
        "\r\n",
        "    print('epoch: [{}/{}] iteration: [{}/{}]\\t'\r\n",
        "          'Learning rate: {}'.format(epoch, epoches, iteration, iters, learning_rate))\r\n",
        "    print('Time {batch_time.sum:.3f}s / {0}iters, ({batch_time.avg:.3f})\\t'\r\n",
        "          'Data load {data_time.sum:.3f}s / {0}iters, ({data_time.avg:3f})\\n'\r\n",
        "          'Loss = {loss.val:.8f} (ave = {loss.avg:.8f})\\n'.format(\r\n",
        "              display, batch_time=batch_time,\r\n",
        "              data_time=data_time, loss=losses))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXPZrvD6Rz9T"
      },
      "source": [
        "def plot_result2(fake, image_size, num_epoch, save_dir, name, fig_size=(8, 8), is_gray=False):\r\n",
        "\r\n",
        "    generate_images = fake\r\n",
        "    #G.train() # for next train after plot_result at a epoch ...\r\n",
        "\r\n",
        "    n_rows = n_cols = 8\r\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=fig_size)\r\n",
        "\r\n",
        "    for ax, img in zip(axes.flatten(), generate_images):\r\n",
        "        ax.axis('off')\r\n",
        "        ax.set_adjustable('box')\r\n",
        "        if is_gray:\r\n",
        "            img = img.cpu().data.view(image_size, image_size).numpy()\r\n",
        "            ax.imshow(img, cmap='gray', aspect='equal')\r\n",
        "        else:\r\n",
        "            img = (((img - img.min()) * 255) / (img.max() - img.min())).cpu().data.numpy().transpose(1, 2, 0).astype(np.uint8)\r\n",
        "            ax.imshow(img, cmap=None, aspect='equal')\r\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\r\n",
        "    title = 'Epoch {0}'.format(num_epoch)\r\n",
        "    fig.text(0.5, 0.04, title, ha='center')\r\n",
        "\r\n",
        "    if name == \"dcgan\":\r\n",
        "        plt.savefig(os.path.join(save_dir, 'DCGAN_epoch_{}.png'.format(num_epoch)))\r\n",
        "        plt.close()\r\n",
        "\r\n",
        "    elif name == \"anomaly\":\r\n",
        "        plt.savefig(os.path.join(save_dir, 'anoGAN_epoch_{}.png'.format(num_epoch)))\r\n",
        "        plt.close()\r\n",
        "\r\n",
        "    elif name == \"vae\":\r\n",
        "        plt.savefig(os.path.join(save_dir, 'vae_epoch_{}.png'.format(num_epoch)))\r\n",
        "        plt.close()\r\n",
        "\r\n",
        "    elif name ==\"gan\":\r\n",
        "        plt.savefig(os.path.join(save_dir, 'gan_epoch_{}.png'.format(num_epoch)))\r\n",
        "        plt.close()\r\n",
        "\r\n",
        "def plot_result(G, fixed_noise, image_size, num_epoch, save_dir, name, fig_size=(8, 8), is_gray=False):\r\n",
        "\r\n",
        "    G.eval()\r\n",
        "    generate_images = G(fixed_noise)\r\n",
        "    G.train() # for next train after plot_result at a epoch ... \r\n",
        "    \r\n",
        "    n_rows = n_cols = 8\r\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=fig_size)\r\n",
        "    \r\n",
        "    for ax, img in zip(axes.flatten(), generate_images):\r\n",
        "        ax.axis('off')\r\n",
        "        ax.set_adjustable('box')\r\n",
        "        if is_gray:\r\n",
        "            img = img.cpu().data.view(image_size, image_size).numpy()\r\n",
        "            ax.imshow(img, cmap='gray', aspect='equal')\r\n",
        "        else:\r\n",
        "            img = (((img - img.min()) * 255) / (img.max() - img.min())).cpu().data.numpy().transpose(1, 2, 0).astype(np.uint8)\r\n",
        "            ax.imshow(img, cmap=None, aspect='equal')\r\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\r\n",
        "    title = 'Epoch {0}'.format(num_epoch)\r\n",
        "    fig.text(0.5, 0.04, title, ha='center')\r\n",
        "    \r\n",
        "    if name == \"dcgan\":\r\n",
        "        plt.savefig(os.path.join(save_dir, 'DCGAN_epoch_{}.png'.format(num_epoch)))\r\n",
        "        plt.close()\r\n",
        "\r\n",
        "    elif name == \"anomaly\":\r\n",
        "        plt.savefig(os.path.join(save_dir, 'anoGAN_epoch_{}.png'.format(num_epoch)))\r\n",
        "        plt.close()\r\n",
        "\r\n",
        "    elif name == \"vae\":\r\n",
        "        plt.savefig(os.path.join(save_dir, 'vae_epoch_{}.png'.format(num_epoch)))\r\n",
        "        plt.close()\r\n",
        "    \r\n",
        "    elif name ==\"gan\":\r\n",
        "        plt.savefig(os.path.join(save_dir, 'gan_epoch_{}.png'.format(num_epoch)))\r\n",
        "        plt.close()\r\n",
        "\r\n",
        "#Clear    \r\n",
        "def plot_loss(num_epoch, epoches, save_dir, **loss):\r\n",
        "    fig, ax = plt.subplots() \r\n",
        "    ax.set_xlim(0,epoches + 1)\r\n",
        "    if len(loss) == 2:\r\n",
        "        ax.set_ylim(0, max(np.max(loss['g_loss']), np.max(loss['d_loss'])) * 1.1)\r\n",
        "    elif len(loss) == 1:\r\n",
        "        ax.set_ylim(0, max(np.max(loss['vae_loss'])) * 1.1)\r\n",
        "    plt.xlabel('Epoch {}'.format(num_epoch))\r\n",
        "    plt.ylabel('Loss')\r\n",
        "    \r\n",
        "    if len(loss) == 2:\r\n",
        "        plt.plot([i for i in range(1, num_epoch + 1)], loss['d_loss'], label='Discriminator', color='red', linewidth=3)\r\n",
        "        plt.plot([i for i in range(1, num_epoch + 1)], loss['g_loss'], label='Generator', color='mediumblue', linewidth=3)\r\n",
        "        plt.legend()\r\n",
        "        plt.savefig(os.path.join(os.path.join(save_dir, \"loss\"), 'gan_loss_epoch_{}.png'.format(num_epoch)))\r\n",
        "    elif len(loss) == 1:\r\n",
        "        plt.plot([i for i in range(1, num_epoch + 1)], loss['vae_loss'], label='vae_loss', color='red', linewidht=3)\r\n",
        "        plt.legend()\r\n",
        "        plt.savefig(os.path.join(os.path.join(save_dir, \"loss\"), 'vae_loss_epoch_{}.png'.format(num_epoch)))\r\n",
        " \r\n",
        "    plt.close()\r\n",
        "\r\n",
        "#Clear\r\n",
        "def plot_accuracy(num_epoch, epoches, save_dir, real_acc, fake_acc):\r\n",
        "\tfig, ax = plt.subplots()\r\n",
        "\tax.set_xlim(0,epoches + 1)\r\n",
        "\tax.set_ylim(0, max(np.max(real_acc), np.max(fake_acc)) * 1.1)\r\n",
        "\tplt.xlabel('Epoch {}'.format(num_epoch))\r\n",
        "\tplt.ylabel('Accuracy')\r\n",
        "\r\n",
        "\tplt.plot([i for i in range(1, num_epoch + 1)], real_acc, label='real data', color='red', linewidth=3)\r\n",
        "\tplt.plot([i for i in range(1, num_epoch + 1)], fake_acc, label='fake data', color='mediumblue', linewidth=3)\r\n",
        "\tplt.legend()\r\n",
        "\tplt.savefig(os.path.join(os.path.join(save_dir, \"accuracy\"), 'gan_accuracy_epoch_{}.png'.format(num_epoch)))\r\n",
        "\r\n",
        "\tplt.close()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7sEvv5gSer1"
      },
      "source": [
        "import torch.distributions.multivariate_normal as mn"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCdghNksVggK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0a3122f-464e-4729-9639-199204ef5992"
      },
      "source": [
        "#run as pretrained = False first then run again with pretrained = True??? Baket?\r\n",
        "pretrained = True\r\n",
        "if __name__ == \"__main__\":\r\n",
        "  use_cuda = torch.cuda.is_available()\r\n",
        "  gpu = 0\r\n",
        "\r\n",
        "  train_loader = load_images(batch_size, image_size)\r\n",
        "\r\n",
        "\r\n",
        "  decoder = Decoder(z_dim, c_dim, gf_dim)\r\n",
        "  encoder = Encoder(z_dim, c_dim, df_dim)\r\n",
        "\r\n",
        "  if not pretrained:\r\n",
        "    if use_cuda:\r\n",
        "      decoder = decoder.cuda(gpu)\r\n",
        "      encoder = encoder.cuda(gpu)\r\n",
        "\r\n",
        "    # WHY BECLoss() - only need to determine fake/real for Discriminator\r\n",
        "    criterion = nn.BCELoss()\r\n",
        "    if use_cuda:\r\n",
        "      criterion = criterion.cuda(gpu)\r\n",
        "\r\n",
        "    optimizerE = torch.optim.Adam(encoder.parameters(), lr=base_lr, betas=(beta1, 0.999))\r\n",
        "    optimizerD = torch.optim.Adam(decoder.parameters(), lr=base_lr, betas=(beta1, 0.999))\r\n",
        "\r\n",
        "    batch_time = AverageMeter()\r\n",
        "    data_time = AverageMeter()\r\n",
        "    losses = AverageMeter()\r\n",
        "\r\n",
        "    fixed_noise = torch.FloatTensor(8 * 8, z_dim, 1, 1).normal_(0, 1)\r\n",
        "    if use_cuda:\r\n",
        "      fixed_noise = fixed_noise.cuda(gpu)\r\n",
        "    with torch.no_grad():\r\n",
        "      fixed_noisev = fixed_noise\r\n",
        "\r\n",
        "    end = time.time()\r\n",
        "    \r\n",
        "    encoder.train()\r\n",
        "    decoder.train()\r\n",
        "    loss_list = []\r\n",
        "\r\n",
        "    \r\n",
        "    criterion = nn.MSELoss(size_average=False)\t\r\n",
        "    for epoch in range(epoches):\r\n",
        "      for i, (input, label) in enumerate(train_loader):\r\n",
        "        #l Update 'D' : max log(D(x)) + log(1-D(G(z)))\r\n",
        "        data_time.update(time.time()-end)\r\n",
        "      \r\n",
        "        batch_size = input.size(0)\r\n",
        "        if use_cuda:\r\n",
        "          input = input.cuda(gpu)\r\n",
        "        \r\n",
        "        mu, log_sigmoid = encoder(input)\r\n",
        "        # reparameterization\r\n",
        "        std = torch.exp(log_sigmoid/2)\r\n",
        "        eps = torch.randn_like(std)\r\n",
        "        z = mu + eps * std\r\n",
        "        z = z.view(-1, z_dim, 1, 1)\t\r\n",
        "        if use_cuda:\r\n",
        "          z = z.cuda(gpu)\r\n",
        "\r\n",
        "        # reconstruct image\r\n",
        "        x_reconstruct = decoder(z)\r\n",
        "\r\n",
        "        # reconstruct_loss + KL_divergence\r\n",
        "        reconstruct_loss = criterion(x_reconstruct, input)\r\n",
        "        kl_div = -0.5 * torch.sum(1+log_sigmoid-mu.pow(2)-log_sigmoid.exp())\r\n",
        "        loss = reconstruct_loss + kl_div\r\n",
        "        losses.update(loss.item())\t\r\n",
        "        optimizerE.zero_grad()\r\n",
        "        optimizerD.zero_grad()\r\n",
        "        loss.backward()\r\n",
        "        optimizerE.step()\r\n",
        "        optimizerD.step()\r\n",
        "\r\n",
        "        batch_time.update(time.time()-end)\r\n",
        "        end = time.time()\r\n",
        "    \r\n",
        "        # log every 100th train data of train_loader - display(100)\t\r\n",
        "        if (i+1) % display == 0:\r\n",
        "          print_vae_log(epoch+1, epoches, i+1, len(train_loader), base_lr, display, batch_time, data_time, losses)\r\n",
        "          # Is it Continous ???\r\n",
        "          batch_time.reset()\r\n",
        "          data_time.reset()\r\n",
        "        # log every 1 epoch (all of train_loader)\r\n",
        "        elif (i+1) == len(train_loader):\r\n",
        "          print_vae_log(epoch + 1, epoches, i + 1, len(train_loader), base_lr, (i + 1) % display, batch_time, data_time, losses)\r\n",
        "          batch_time.reset()\r\n",
        "          data_time.reset()\r\n",
        "\r\n",
        "      # log every 1 epoch\r\n",
        "      loss_list.append(losses.avg)\r\n",
        "      losses.reset()\r\n",
        "\r\n",
        "      plot_result(decoder, fixed_noisev, image_size, epoch + 1,save_dir, 'vae', is_gray=(c_dim == 1))\r\n",
        "      #plot_loss(epoch+1, config.epoches, args.save_dir, vae_loss=loss_list)\r\n",
        "      # save the D and G.\r\n",
        "      save_checkpoint({'epoch': epoch, 'state_dict': encoder.state_dict(),}, os.path.join(os.path.join(checkpoint_dir,\"vae\"), 'encoder_epoch_{}'.format(epoch)))\r\n",
        "      save_checkpoint({'epoch': epoch, 'state_dict': decoder.state_dict(),}, os.path.join(os.path.join(checkpoint_dir,\"vae\"), 'decoder_epoch_{}'.format(epoch)))\r\n",
        "\r\n",
        "    #create_gif(epoches, save_dir, 'vae')\r\n",
        "\r\n",
        "  ## Class Conditional Generator - Pretrained Model\"\r\n",
        "  else:\r\n",
        "    print(\"Class Conditional Generator - Use Pretrained Model\")\r\n",
        "    if use_cuda:\r\n",
        "      encoder = encoder.cuda(gpu)\r\n",
        "      decoder = decoder.cuda(gpu)\r\n",
        "    encoder.load_state_dict(torch.load(os.path.join(os.path.join(checkpoint_dir, \"vae\"), \"encoder_epoch_\"+ str(epoches-1) + \".pth.tar\"))['state_dict'])\r\n",
        "    decoder.load_state_dict(torch.load(os.path.join(os.path.join(checkpoint_dir, \"vae\"), \"decoder_epoch_\"+ str(epoches-1) + \".pth.tar\"))['state_dict'])\r\n",
        "    #Z = np.empty([config.class_num, config.z_dim], dtype=float)\r\n",
        "    # Z : [label-1, labe-2, ... ]\r\n",
        "    # Z[label-1] : [[z1], [z2], ... ] (#labeld_data, #z_dim)\r\n",
        "    encoder.eval()\r\n",
        "    decoder.eval()\r\n",
        "    Z = []\r\n",
        "    with torch.no_grad():\r\n",
        "      for i in range(class_num):\r\n",
        "        Z.append(torch.zeros((1, z_dim), dtype=torch.float)) # Z : [class_num, z_dim]\r\n",
        "    \r\n",
        "      for i, (input, label) in enumerate(train_loader):\r\n",
        "        if use_cuda:\r\n",
        "          input = input.cuda(gpu)\r\n",
        "        mu, log_sigmoid = encoder(input)\r\n",
        "        std = torch.exp(log_sigmoid/2)\r\n",
        "        eps = torch.randn_like(std)\r\n",
        "        z = mu + eps * std\r\n",
        "        z = z.view(-1, 1, z_dim)\r\n",
        "        Z = batch2one(Z, label, z, class_num)\r\n",
        "\r\n",
        "      N = []\r\n",
        "      for i in range(class_num):\r\n",
        "        label_mean = torch.mean(Z[i][1:], dim=0).float()\r\n",
        "        label_cov = torch.from_numpy(np.cov(Z[i][1:].numpy(), rowvar=False)).float()\r\n",
        "        #print(\"{}th Z : {}\".format(i+1, Z[i][1:].shape))\r\n",
        "        #print(\"{}-class  mean : {}\".format(i+1, label_mean.shape))\r\n",
        "        #print(\"{}-class covariance : {}\".format(i+1, label_cov.shape))\r\n",
        "        m = mn.MultivariateNormal(label_mean, label_cov)\r\n",
        "        sample = m.sample((64,))\r\n",
        "        print(sample.shape)\r\n",
        "        if use_cuda:\r\n",
        "          sample = sample.cuda(gpu)\r\n",
        "        fake = decoder(sample.view(-1, z_dim, 1, 1))\r\n",
        "        \r\n",
        "        \r\n",
        "        plot_result2(fake, image_size, i, 'data/gan/samples', 'ssgan', is_gray=(c_dim == 1))\r\n",
        "        N.append(m)\r\n",
        "      print(\"uhm\")\r\n",
        "      torch.save({'distribution': N}, os.path.join(distribution_dir, 'class_distribution')+'.dt')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class Conditional Generator - Use Pretrained Model\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "uhm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58SE8dlOTKJD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae920508-515f-429e-d273-8be2100cce3e"
      },
      "source": [
        "pretrained = True\r\n",
        "if __name__ == \"__main__\":\r\n",
        "  use_cuda = torch.cuda.is_available()\r\n",
        "  gpu = 0\r\n",
        "\r\n",
        "  # parser.add_argument('--save_dir', type=str, dest='save_dir', help='the path of generated data dir', default='sample')\r\n",
        "  # parser.add_argument('--distribution_dir', type=str, dest='distribution_dir', help='the path of class distribution dir', default='distribution')\r\n",
        "  # parser.add_argument('--test_dir', type=str, dest='test_dir', help='the path of anomaly test data')\r\n",
        "  # parser.add_argument('--test_result_dir', type=str, dest='test_result_dir', help='the path of anomaly test result dir')\r\n",
        "  train_loader = load_images(batch_size, image_size)\r\n",
        "\r\n",
        "  G = Generator(z_dim, c_dim, gf_dim)\r\n",
        "  G.apply(weights_init)\r\n",
        "\r\n",
        "  D = Discriminator(z_dim, c_dim, df_dim, class_num)\r\n",
        "  D.apply(weights_init)\r\n",
        "\r\n",
        "  # if not pretrained:\r\n",
        "  #   if use_cuda:\r\n",
        "  #     print(\"duh\")\r\n",
        "  #     G = G.cuda(gpu)\r\n",
        "  #     D = D.cuda(gpu)\r\n",
        "\r\n",
        "  if use_cuda:\r\n",
        "    print(\"duh\")\r\n",
        "    G = G.cuda(gpu)\r\n",
        "    D = D.cuda(gpu)\r\n",
        "\r\n",
        "\r\n",
        "  distribution = torch.load(os.path.join(distribution_dir,'class_distribution.dt'))['distribution']\r\n",
        "\r\n",
        "  #G.load_state_dict(torch.load(os.path.join(os.path.join(args.checkpoint_dir,\"vae\") , \"decoder_epoch_\"+str(config.epoches-1) + \".pth.tar\"))['state_dict'])\r\n",
        "\r\n",
        "  # state_e = torch.load(os.path.join(os.path.join(args.checkpoint_dir,\"vae\"), \"encoder_epoch_\"+str(config.epoches-1) + \".pth.tar\"))['state_dict']\r\n",
        "  # del state_e['fc_z1.weight']\r\n",
        "  # del state_e['fc_z1.bias']\r\n",
        "  # del state_e['fc_z2.weight']\r\n",
        "  # del state_e['fc_z2.bias']\r\n",
        "  # state_e.update({'fc_aux.weight':D.state_dict()['fc_aux.weight']})\r\n",
        "  # state_e.update({'fc_aux.bias':D.state_dict()['fc_aux.bias']})\r\n",
        "\r\n",
        "  # D.load_state_dict(state_e)\r\n",
        "\r\n",
        "  criterion = nn.NLLLoss()\r\n",
        "\r\n",
        "  optimizerD = torch.optim.Adam(D.parameters(), lr=base_lr, betas=(beta1, 0.999))\r\n",
        "  optimizerG = torch.optim.Adam(G.parameters(), lr=base_lr, betas=(beta1, 0.999))\r\n",
        "\r\n",
        "  batch_time = AverageMeter()\r\n",
        "  data_time = AverageMeter()\r\n",
        "  D_losses = AverageMeter()\r\n",
        "  G_losses = AverageMeter()\r\n",
        "\r\n",
        "  #fixed_noise = torch.FloatTensor(8 * 8, config.z_dim, 1, 1).normal_(0, 1)\r\n",
        "  #if use_cuda:\r\n",
        "  #\tfixed_noise = fixed_noise.cuda(gpu)\r\n",
        "  #with torch.no_grad():\r\n",
        "  #\tfixed_noisev = fixed_noise\r\n",
        "\r\n",
        "  end = time.time()\r\n",
        "\r\n",
        "  D.train()\r\n",
        "  G.train()\r\n",
        "  D_loss_list = []\r\n",
        "  G_loss_list = []\r\n",
        "\r\n",
        "  real_label = torch.LongTensor(batch_size)\r\n",
        "  fake_label = torch.LongTensor(batch_size)\t\r\n",
        "\r\n",
        "  for epoch in range(epoches):\r\n",
        "    total_real = 0\r\n",
        "    total_fake = 0\r\n",
        "    correct_real = 0\r\n",
        "    correct_fake = 0\r\n",
        "    for i, (input, label) in enumerate(train_loader):\r\n",
        "      # Update 'D' : max log(D(x)) + log(1-D(G(z)))\r\n",
        "      data_time.update(time.time()-end)\r\n",
        "      batch_size = input.size(0)\r\n",
        "      fake_num = math.ceil(batch_size/class_num)\t# For each batch, 1/(n+1) of total images are fake\r\n",
        "      conditional_z, z_label = conditional_latent_generator(distribution, class_num, batch_size)\r\n",
        "\r\n",
        "      label = label.long().squeeze() # \"squeeze\" : [batch, 1] --> [batch] ... e.g) [1,2,3,4...]\t\t\r\n",
        "      #print(label[0])\r\n",
        "      #print(path[0])\r\n",
        "      if use_cuda:\r\n",
        "        input = input.cuda(gpu)\r\n",
        "        label = label.cuda(gpu)\r\n",
        "\r\n",
        "      sample_features, D_real = D(input)\r\n",
        "      real_label.resize_(batch_size).copy_(label)\t# \"cpu\" : gpu --> cpu // <<.data.cpu vs cpu>> // \"resize_as\" : get tensor size and resize \r\n",
        "      if use_cuda:\r\n",
        "        real_label = real_label.cuda(gpu) \r\n",
        "      \r\n",
        "      D_loss_real = criterion(D_real, real_label)\r\n",
        "      noise = conditional_z[0:fake_num].view(-1, z_dim, 1, 1)\r\n",
        "\r\n",
        "      fake_label.resize_(noise.shape[0]).fill_(class_num)\t# fake_label = '(num_class)+1'\r\n",
        "      if use_cuda:\r\n",
        "        noise = noise.cuda(gpu)\r\n",
        "        fake_label = fake_label.cuda(gpu)\r\n",
        "        z_label = z_label.cuda(gpu)\r\n",
        "      \r\n",
        "      fake = G(noise)\r\n",
        "\r\n",
        "      _, D_fake = D(fake.detach())\t# Fake image...\r\n",
        "      D_loss_fake = criterion(D_fake, fake_label)\t# Hmmmm...... fake_label? or z_label?\r\n",
        "\r\n",
        "      D_loss = D_loss_real + D_loss_fake\r\n",
        "      D_losses.update(D_loss.item())\r\n",
        "      D.zero_grad()\r\n",
        "      G.zero_grad()\r\n",
        "      D_loss.backward()\r\n",
        "      optimizerD.step()\r\n",
        "\r\n",
        "      # Update 'G' : max log(D(G(z)))\r\n",
        "      noise = conditional_z.view(-1, z_dim, 1, 1)\r\n",
        "      if use_cuda:\r\n",
        "        noise = noise.cuda(gpu)\r\n",
        "      fake = G(noise)\r\n",
        "      _, D_fake = D(fake)\r\n",
        "      G_loss = criterion(D_fake, z_label)\r\n",
        "      #G_losses.update(G_loss.data[0])\r\n",
        "      G_losses.update(G_loss.item())\r\n",
        "\r\n",
        "      D.zero_grad()\r\n",
        "      G.zero_grad()\r\n",
        "      G_loss.backward()\r\n",
        "      optimizerG.step()\r\n",
        "\r\n",
        "      batch_time.update(time.time()-end)\r\n",
        "      end = time.time()\r\n",
        "      \r\n",
        "      pred_real = torch.max(D_real.data, 1)[1]\r\n",
        "      pred_fake = torch.max(D_fake.data, 1)[1]\r\n",
        "      total_real += real_label.size(0)\r\n",
        "      total_fake += z_label.size(0)\r\n",
        "      correct_real += (pred_real == real_label).sum().item()\r\n",
        "      correct_fake += (pred_fake == z_label).sum().item()\r\n",
        "\r\n",
        "      # log every 100th train data of train_loader - display(100)\t\r\n",
        "      if (i+1) % display == 0:\r\n",
        "        print_gan_log(epoch+1, epoches, i+1, len(train_loader), base_lr, display, batch_time, data_time, D_losses, G_losses)\r\n",
        "        # Is it Continous ???\r\n",
        "        batch_time.reset()\r\n",
        "        data_time.reset()\r\n",
        "      # log every 1 epoch (all of train_loader) ... \"End of all mini-Batch\"\r\n",
        "      elif (i+1) == len(train_loader):\r\n",
        "        print_gan_log(epoch + 1, epoches, i + 1, len(train_loader), base_lr,\r\n",
        "                          (i + 1) % display, batch_time, data_time, D_losses, G_losses)\r\n",
        "        #accuracy = masked_correct.item()/max(1.0, num_samples.item())\r\n",
        "        plot_result2(fake, image_size, epoch + 1, save_dir, 'gan', is_gray=(c_dim == 1))\r\n",
        "        real_acc = 100 * correct_real / total_real\r\n",
        "        fake_acc = 100 * correct_fake / total_fake\r\n",
        "        print('Real Accuracy : {}'.format(real_acc))\r\n",
        "        print('Fake Accuracy : {}'.format(fake_acc))\r\n",
        "        #plot_accuracy(epoch+1, epoches, save_dir, real_acc, fake_acc)\r\n",
        "        batch_time.reset()\r\n",
        "        data_time.reset()\r\n",
        "\r\n",
        "    # log every 1 epoch\r\n",
        "    D_loss_list.append(D_losses.avg)\r\n",
        "    G_loss_list.append(G_losses.avg)\r\n",
        "    D_losses.reset()\r\n",
        "    G_losses.reset()\r\n",
        "\r\n",
        "    plot_result(G, fixed_noisev, image_size, epoch + 1, save_dir, 'gan', is_gray=(c_dim == 1))\r\n",
        "    plot_loss(epoch+1,epoches, save_dir, d_loss=D_loss_list, g_loss=G_loss_list)\r\n",
        "    # save the D and G.\r\n",
        "    #save_checkpoint({'epoch': epoch, 'state_dict': D.state_dict(),}, os.path.join(os.path.join(checkpoint_dir,'gan'), 'D_epoch_{}'.format(epoch)))\r\n",
        "    #save_checkpoint({'epoch': epoch, 'state_dict': G.state_dict(),}, os.path.join(os.path.join(checkpoint_dir,'gan'), 'G_epoch_{}'.format(epoch)))\r\n",
        "\r\n",
        "    torch.save(D, os.path.join(os.path.join(checkpoint_dir,'gan'), 'D_epoch_{}.pth'.format(epoch)))\r\n",
        "    torch.save(G, os.path.join(os.path.join(checkpoint_dir,'gan'), 'G_epoch_{}.pth'.format(epoch)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "duh\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:198: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Loss_D = 0.35089561 (ave = 0.38767664)\n",
            "Loss_G = 6.09893894 (ave = 4.78857150)\n",
            "\n",
            "epoch: [60/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.645s / 10iters, (0.065)\tData load 0.081s / 10iters, (0.008076)\n",
            "Loss_D = 0.40680173 (ave = 0.44787712)\n",
            "Loss_G = 4.62285614 (ave = 4.43431598)\n",
            "\n",
            "epoch: [60/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.622s / 10iters, (0.062)\tData load 0.086s / 10iters, (0.008563)\n",
            "Loss_D = 0.42860150 (ave = 0.40254110)\n",
            "Loss_G = 6.48008394 (ave = 4.45258946)\n",
            "\n",
            "epoch: [60/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.668s / 10iters, (0.067)\tData load 0.056s / 10iters, (0.005630)\n",
            "Loss_D = 0.13578060 (ave = 0.37855432)\n",
            "Loss_G = 4.94299126 (ave = 4.47154877)\n",
            "\n",
            "epoch: [60/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.554s / 10iters, (0.055)\tData load 0.074s / 10iters, (0.007363)\n",
            "Loss_D = 0.97744823 (ave = 0.42442407)\n",
            "Loss_G = 3.37397122 (ave = 4.47826848)\n",
            "\n",
            "epoch: [60/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.705s / 10iters, (0.071)\tData load 0.087s / 10iters, (0.008680)\n",
            "Loss_D = 0.14525878 (ave = 0.44227108)\n",
            "Loss_G = 3.99302244 (ave = 4.46760518)\n",
            "\n",
            "epoch: [60/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.680s / 10iters, (0.068)\tData load 0.077s / 10iters, (0.007737)\n",
            "Loss_D = 0.90363997 (ave = 0.44728697)\n",
            "Loss_G = 7.31776762 (ave = 4.48745352)\n",
            "\n",
            "epoch: [60/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.567s / 10iters, (0.057)\tData load 0.091s / 10iters, (0.009060)\n",
            "Loss_D = 0.75155967 (ave = 0.46852745)\n",
            "Loss_G = 6.86457109 (ave = 4.57453857)\n",
            "\n",
            "epoch: [60/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.648s / 10iters, (0.065)\tData load 0.075s / 10iters, (0.007475)\n",
            "Loss_D = 0.97343910 (ave = 0.47828026)\n",
            "Loss_G = 3.16589761 (ave = 4.55859736)\n",
            "\n",
            "epoch: [60/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.617s / 10iters, (0.062)\tData load 0.049s / 10iters, (0.004851)\n",
            "Loss_D = 0.47720566 (ave = 0.49013853)\n",
            "Loss_G = 5.54589510 (ave = 4.62843989)\n",
            "\n",
            "epoch: [60/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.664s / 10iters, (0.066)\tData load 0.074s / 10iters, (0.007388)\n",
            "Loss_D = 0.17369305 (ave = 0.48307261)\n",
            "Loss_G = 4.80444098 (ave = 4.57659384)\n",
            "\n",
            "epoch: [60/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.744s / 10iters, (0.074)\tData load 0.104s / 10iters, (0.010418)\n",
            "Loss_D = 0.38988122 (ave = 0.46597968)\n",
            "Loss_G = 3.64627981 (ave = 4.53875250)\n",
            "\n",
            "epoch: [60/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.602s / 10iters, (0.060)\tData load 0.086s / 10iters, (0.008622)\n",
            "Loss_D = 0.20280463 (ave = 0.46140219)\n",
            "Loss_G = 5.90416718 (ave = 4.56566975)\n",
            "\n",
            "epoch: [60/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.572s / 10iters, (0.057)\tData load 0.072s / 10iters, (0.007169)\n",
            "Loss_D = 0.20770949 (ave = 0.45513872)\n",
            "Loss_G = 5.29615736 (ave = 4.55006156)\n",
            "\n",
            "epoch: [60/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.663s / 10iters, (0.066)\tData load 0.076s / 10iters, (0.007609)\n",
            "Loss_D = 0.32783657 (ave = 0.45413020)\n",
            "Loss_G = 3.16046643 (ave = 4.55400151)\n",
            "\n",
            "epoch: [60/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.584s / 10iters, (0.058)\tData load 0.070s / 10iters, (0.007041)\n",
            "Loss_D = 0.16652913 (ave = 0.45110820)\n",
            "Loss_G = 4.75220394 (ave = 4.55114955)\n",
            "\n",
            "epoch: [60/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.567s / 10iters, (0.057)\tData load 0.070s / 10iters, (0.006978)\n",
            "Loss_D = 0.15762876 (ave = 0.44359416)\n",
            "Loss_G = 3.74143863 (ave = 4.51506909)\n",
            "\n",
            "epoch: [60/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.679s / 10iters, (0.068)\tData load 0.081s / 10iters, (0.008123)\n",
            "Loss_D = 0.22251511 (ave = 0.43589646)\n",
            "Loss_G = 3.57767701 (ave = 4.50346415)\n",
            "\n",
            "epoch: [60/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.685s / 10iters, (0.068)\tData load 0.095s / 10iters, (0.009464)\n",
            "Loss_D = 0.18036628 (ave = 0.42882242)\n",
            "Loss_G = 5.94227266 (ave = 4.52376046)\n",
            "\n",
            "epoch: [60/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.591s / 10iters, (0.059)\tData load 0.061s / 10iters, (0.006063)\n",
            "Loss_D = 0.20709674 (ave = 0.42661798)\n",
            "Loss_G = 4.38420916 (ave = 4.49826529)\n",
            "\n",
            "epoch: [60/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.597s / 10iters, (0.060)\tData load 0.064s / 10iters, (0.006443)\n",
            "Loss_D = 0.19844715 (ave = 0.45563482)\n",
            "Loss_G = 4.62635088 (ave = 4.50895436)\n",
            "\n",
            "epoch: [60/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.669s / 10iters, (0.067)\tData load 0.068s / 10iters, (0.006825)\n",
            "Loss_D = 0.39785200 (ave = 0.45523904)\n",
            "Loss_G = 4.72883558 (ave = 4.50307438)\n",
            "\n",
            "epoch: [60/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.347s / 10iters, (0.035)\tData load 0.048s / 10iters, (0.004781)\n",
            "Loss_D = 0.94294536 (ave = 0.45445218)\n",
            "Loss_G = 7.50144768 (ave = 4.50078523)\n",
            "\n",
            "epoch: [60/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.071s / 3iters, (0.024)\tData load 0.014s / 3iters, (0.004759)\n",
            "Loss_D = 0.32422185 (ave = 0.45273079)\n",
            "Loss_G = 3.86168242 (ave = 4.49857042)\n",
            "\n",
            "Real Accuracy : 90.53293611386958\n",
            "Fake Accuracy : 4.1708043694141015\n",
            "epoch: [61/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.032s / 10iters, (0.503)\tData load 4.309s / 10iters, (0.430853)\n",
            "Loss_D = 0.31204849 (ave = 0.32043135)\n",
            "Loss_G = 2.70991778 (ave = 4.39180593)\n",
            "\n",
            "epoch: [61/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.668s / 10iters, (0.067)\tData load 0.095s / 10iters, (0.009487)\n",
            "Loss_D = 0.50037944 (ave = 0.49371086)\n",
            "Loss_G = 3.86712289 (ave = 4.81153990)\n",
            "\n",
            "epoch: [61/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.593s / 10iters, (0.059)\tData load 0.081s / 10iters, (0.008122)\n",
            "Loss_D = 0.25720966 (ave = 0.52978828)\n",
            "Loss_G = 4.66607571 (ave = 5.05724474)\n",
            "\n",
            "epoch: [61/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.656s / 10iters, (0.066)\tData load 0.084s / 10iters, (0.008363)\n",
            "Loss_D = 0.44178689 (ave = 0.50169150)\n",
            "Loss_G = 4.43072081 (ave = 4.91959683)\n",
            "\n",
            "epoch: [61/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.631s / 10iters, (0.063)\tData load 0.078s / 10iters, (0.007779)\n",
            "Loss_D = 0.58984232 (ave = 0.48954127)\n",
            "Loss_G = 3.14352298 (ave = 4.75964315)\n",
            "\n",
            "epoch: [61/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.550s / 10iters, (0.055)\tData load 0.070s / 10iters, (0.007021)\n",
            "Loss_D = 0.40959114 (ave = 0.52636687)\n",
            "Loss_G = 3.07976818 (ave = 4.80692019)\n",
            "\n",
            "epoch: [61/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.656s / 10iters, (0.066)\tData load 0.093s / 10iters, (0.009290)\n",
            "Loss_D = 0.49610248 (ave = 0.50241937)\n",
            "Loss_G = 4.97340441 (ave = 4.78097875)\n",
            "\n",
            "epoch: [61/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.628s / 10iters, (0.063)\tData load 0.073s / 10iters, (0.007263)\n",
            "Loss_D = 0.37969622 (ave = 0.48719043)\n",
            "Loss_G = 5.59186077 (ave = 4.78233883)\n",
            "\n",
            "epoch: [61/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.579s / 10iters, (0.058)\tData load 0.086s / 10iters, (0.008600)\n",
            "Loss_D = 0.35306418 (ave = 0.50735960)\n",
            "Loss_G = 5.55524397 (ave = 4.86445561)\n",
            "\n",
            "epoch: [61/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.602s / 10iters, (0.060)\tData load 0.088s / 10iters, (0.008772)\n",
            "Loss_D = 0.34424469 (ave = 0.49733656)\n",
            "Loss_G = 3.23507667 (ave = 4.86795964)\n",
            "\n",
            "epoch: [61/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.708s / 10iters, (0.071)\tData load 0.059s / 10iters, (0.005912)\n",
            "Loss_D = 0.42278942 (ave = 0.50213011)\n",
            "Loss_G = 3.28510904 (ave = 4.84543533)\n",
            "\n",
            "epoch: [61/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.654s / 10iters, (0.065)\tData load 0.081s / 10iters, (0.008117)\n",
            "Loss_D = 0.26317397 (ave = 0.49635052)\n",
            "Loss_G = 3.48142719 (ave = 4.78711982)\n",
            "\n",
            "epoch: [61/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.632s / 10iters, (0.063)\tData load 0.101s / 10iters, (0.010126)\n",
            "Loss_D = 0.14941162 (ave = 0.49441109)\n",
            "Loss_G = 5.39733076 (ave = 4.79216451)\n",
            "\n",
            "epoch: [61/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.648s / 10iters, (0.065)\tData load 0.096s / 10iters, (0.009632)\n",
            "Loss_D = 0.35266885 (ave = 0.48503902)\n",
            "Loss_G = 3.65626574 (ave = 4.74879972)\n",
            "\n",
            "epoch: [61/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.598s / 10iters, (0.060)\tData load 0.072s / 10iters, (0.007203)\n",
            "Loss_D = 0.34313363 (ave = 0.47419855)\n",
            "Loss_G = 3.92790818 (ave = 4.70648095)\n",
            "\n",
            "epoch: [61/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.663s / 10iters, (0.066)\tData load 0.092s / 10iters, (0.009168)\n",
            "Loss_D = 0.51561147 (ave = 0.46826784)\n",
            "Loss_G = 4.79506350 (ave = 4.68553791)\n",
            "\n",
            "epoch: [61/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.608s / 10iters, (0.061)\tData load 0.086s / 10iters, (0.008624)\n",
            "Loss_D = 0.19070929 (ave = 0.47271388)\n",
            "Loss_G = 3.79468417 (ave = 4.67845030)\n",
            "\n",
            "epoch: [61/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.587s / 10iters, (0.059)\tData load 0.085s / 10iters, (0.008502)\n",
            "Loss_D = 0.33488935 (ave = 0.46749666)\n",
            "Loss_G = 5.02246618 (ave = 4.66878747)\n",
            "\n",
            "epoch: [61/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.603s / 10iters, (0.060)\tData load 0.105s / 10iters, (0.010479)\n",
            "Loss_D = 0.38071984 (ave = 0.46278470)\n",
            "Loss_G = 3.96428037 (ave = 4.64454361)\n",
            "\n",
            "epoch: [61/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.658s / 10iters, (0.066)\tData load 0.067s / 10iters, (0.006718)\n",
            "Loss_D = 0.68151414 (ave = 0.45827312)\n",
            "Loss_G = 4.49056387 (ave = 4.61332523)\n",
            "\n",
            "epoch: [61/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.596s / 10iters, (0.060)\tData load 0.078s / 10iters, (0.007799)\n",
            "Loss_D = 0.36224180 (ave = 0.45208359)\n",
            "Loss_G = 3.58845043 (ave = 4.62278042)\n",
            "\n",
            "epoch: [61/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.608s / 10iters, (0.061)\tData load 0.092s / 10iters, (0.009168)\n",
            "Loss_D = 1.13649786 (ave = 0.45318088)\n",
            "Loss_G = 3.10234165 (ave = 4.61006877)\n",
            "\n",
            "epoch: [61/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.363s / 10iters, (0.036)\tData load 0.060s / 10iters, (0.005966)\n",
            "Loss_D = 0.71213365 (ave = 0.44850607)\n",
            "Loss_G = 3.81070304 (ave = 4.59745396)\n",
            "\n",
            "epoch: [61/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.069s / 3iters, (0.023)\tData load 0.017s / 3iters, (0.005735)\n",
            "Loss_D = 0.20074397 (ave = 0.44700404)\n",
            "Loss_G = 5.46859312 (ave = 4.61156373)\n",
            "\n",
            "Real Accuracy : 90.40052962595168\n",
            "Fake Accuracy : 3.2439589539887455\n",
            "epoch: [62/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.120s / 10iters, (0.512)\tData load 4.490s / 10iters, (0.448975)\n",
            "Loss_D = 0.07943112 (ave = 0.64441539)\n",
            "Loss_G = 4.02433157 (ave = 5.01481466)\n",
            "\n",
            "epoch: [62/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.686s / 10iters, (0.069)\tData load 0.126s / 10iters, (0.012613)\n",
            "Loss_D = 0.36911845 (ave = 0.49661659)\n",
            "Loss_G = 2.83204389 (ave = 4.71064336)\n",
            "\n",
            "epoch: [62/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.650s / 10iters, (0.065)\tData load 0.086s / 10iters, (0.008636)\n",
            "Loss_D = 0.19613951 (ave = 0.45068403)\n",
            "Loss_G = 3.76979542 (ave = 4.63230843)\n",
            "\n",
            "epoch: [62/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.666s / 10iters, (0.067)\tData load 0.104s / 10iters, (0.010365)\n",
            "Loss_D = 0.17304605 (ave = 0.43259824)\n",
            "Loss_G = 4.02351809 (ave = 4.55482381)\n",
            "\n",
            "epoch: [62/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.589s / 10iters, (0.059)\tData load 0.086s / 10iters, (0.008644)\n",
            "Loss_D = 0.25229889 (ave = 0.41516475)\n",
            "Loss_G = 6.42333794 (ave = 4.63088326)\n",
            "\n",
            "epoch: [62/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.596s / 10iters, (0.060)\tData load 0.066s / 10iters, (0.006637)\n",
            "Loss_D = 0.05349471 (ave = 0.40475038)\n",
            "Loss_G = 3.57307196 (ave = 4.59795165)\n",
            "\n",
            "epoch: [62/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.621s / 10iters, (0.062)\tData load 0.102s / 10iters, (0.010181)\n",
            "Loss_D = 1.18492353 (ave = 0.41354358)\n",
            "Loss_G = 4.41161680 (ave = 4.60893263)\n",
            "\n",
            "epoch: [62/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.584s / 10iters, (0.058)\tData load 0.077s / 10iters, (0.007709)\n",
            "Loss_D = 0.65529430 (ave = 0.42985193)\n",
            "Loss_G = 5.40880537 (ave = 4.64168976)\n",
            "\n",
            "epoch: [62/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.631s / 10iters, (0.063)\tData load 0.100s / 10iters, (0.010035)\n",
            "Loss_D = 0.31330529 (ave = 0.44644080)\n",
            "Loss_G = 5.42735767 (ave = 4.64894317)\n",
            "\n",
            "epoch: [62/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.601s / 10iters, (0.060)\tData load 0.096s / 10iters, (0.009613)\n",
            "Loss_D = 0.42432371 (ave = 0.43358779)\n",
            "Loss_G = 4.67668200 (ave = 4.59093210)\n",
            "\n",
            "epoch: [62/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.633s / 10iters, (0.063)\tData load 0.099s / 10iters, (0.009934)\n",
            "Loss_D = 0.28046942 (ave = 0.42467328)\n",
            "Loss_G = 3.84554768 (ave = 4.55965068)\n",
            "\n",
            "epoch: [62/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.682s / 10iters, (0.068)\tData load 0.082s / 10iters, (0.008248)\n",
            "Loss_D = 0.11646228 (ave = 0.42640167)\n",
            "Loss_G = 6.25165081 (ave = 4.58874733)\n",
            "\n",
            "epoch: [62/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.639s / 10iters, (0.064)\tData load 0.075s / 10iters, (0.007527)\n",
            "Loss_D = 0.25644800 (ave = 0.42010437)\n",
            "Loss_G = 5.45725298 (ave = 4.62686420)\n",
            "\n",
            "epoch: [62/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.559s / 10iters, (0.056)\tData load 0.076s / 10iters, (0.007559)\n",
            "Loss_D = 0.36263776 (ave = 0.41210653)\n",
            "Loss_G = 4.61933899 (ave = 4.60455276)\n",
            "\n",
            "epoch: [62/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.637s / 10iters, (0.064)\tData load 0.086s / 10iters, (0.008626)\n",
            "Loss_D = 0.23482129 (ave = 0.41208925)\n",
            "Loss_G = 4.41295815 (ave = 4.56965130)\n",
            "\n",
            "epoch: [62/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.609s / 10iters, (0.061)\tData load 0.082s / 10iters, (0.008240)\n",
            "Loss_D = 0.61486757 (ave = 0.41380352)\n",
            "Loss_G = 5.12150240 (ave = 4.60092045)\n",
            "\n",
            "epoch: [62/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.594s / 10iters, (0.059)\tData load 0.059s / 10iters, (0.005905)\n",
            "Loss_D = 0.51536965 (ave = 0.42018893)\n",
            "Loss_G = 4.87422466 (ave = 4.61447254)\n",
            "\n",
            "epoch: [62/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.706s / 10iters, (0.071)\tData load 0.077s / 10iters, (0.007662)\n",
            "Loss_D = 0.37502548 (ave = 0.42422962)\n",
            "Loss_G = 4.23167992 (ave = 4.62392697)\n",
            "\n",
            "epoch: [62/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.621s / 10iters, (0.062)\tData load 0.073s / 10iters, (0.007305)\n",
            "Loss_D = 1.51689613 (ave = 0.43777075)\n",
            "Loss_G = 3.54703903 (ave = 4.64197899)\n",
            "\n",
            "epoch: [62/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.585s / 10iters, (0.059)\tData load 0.065s / 10iters, (0.006534)\n",
            "Loss_D = 0.65509784 (ave = 0.44213289)\n",
            "Loss_G = 6.11977100 (ave = 4.64678443)\n",
            "\n",
            "epoch: [62/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.671s / 10iters, (0.067)\tData load 0.120s / 10iters, (0.012033)\n",
            "Loss_D = 0.08439421 (ave = 0.43935940)\n",
            "Loss_G = 3.70553827 (ave = 4.64400038)\n",
            "\n",
            "epoch: [62/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.628s / 10iters, (0.063)\tData load 0.063s / 10iters, (0.006323)\n",
            "Loss_D = 0.27056602 (ave = 0.43959872)\n",
            "Loss_G = 3.25707507 (ave = 4.63940483)\n",
            "\n",
            "epoch: [62/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.332s / 10iters, (0.033)\tData load 0.056s / 10iters, (0.005569)\n",
            "Loss_D = 0.46925223 (ave = 0.43774937)\n",
            "Loss_G = 4.29227877 (ave = 4.63544698)\n",
            "\n",
            "epoch: [62/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.067s / 3iters, (0.022)\tData load 0.015s / 3iters, (0.005052)\n",
            "Loss_D = 0.04684167 (ave = 0.43698188)\n",
            "Loss_G = 5.55365086 (ave = 4.64128295)\n",
            "\n",
            "Real Accuracy : 90.96325719960278\n",
            "Fake Accuracy : 3.4756703078450846\n",
            "epoch: [63/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.025s / 10iters, (0.502)\tData load 4.419s / 10iters, (0.441919)\n",
            "Loss_D = 0.66514671 (ave = 0.50143922)\n",
            "Loss_G = 4.55752563 (ave = 4.18358912)\n",
            "\n",
            "epoch: [63/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.643s / 10iters, (0.064)\tData load 0.070s / 10iters, (0.007000)\n",
            "Loss_D = 0.35485876 (ave = 0.47082982)\n",
            "Loss_G = 4.65206337 (ave = 4.65521086)\n",
            "\n",
            "epoch: [63/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.653s / 10iters, (0.065)\tData load 0.091s / 10iters, (0.009121)\n",
            "Loss_D = 0.42193782 (ave = 0.40388987)\n",
            "Loss_G = 6.73307848 (ave = 4.70943950)\n",
            "\n",
            "epoch: [63/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.503s / 10iters, (0.050)\tData load 0.062s / 10iters, (0.006152)\n",
            "Loss_D = 1.64854169 (ave = 0.47721436)\n",
            "Loss_G = 2.84415913 (ave = 4.78015766)\n",
            "\n",
            "epoch: [63/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.777s / 10iters, (0.078)\tData load 0.116s / 10iters, (0.011619)\n",
            "Loss_D = 0.68641627 (ave = 0.46350353)\n",
            "Loss_G = 6.47413683 (ave = 4.75598001)\n",
            "\n",
            "epoch: [63/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.650s / 10iters, (0.065)\tData load 0.086s / 10iters, (0.008593)\n",
            "Loss_D = 0.32077938 (ave = 0.46854223)\n",
            "Loss_G = 5.17329741 (ave = 4.71122219)\n",
            "\n",
            "epoch: [63/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.597s / 10iters, (0.060)\tData load 0.075s / 10iters, (0.007468)\n",
            "Loss_D = 0.38970038 (ave = 0.46110791)\n",
            "Loss_G = 5.98390675 (ave = 4.76116528)\n",
            "\n",
            "epoch: [63/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.639s / 10iters, (0.064)\tData load 0.074s / 10iters, (0.007450)\n",
            "Loss_D = 0.42211944 (ave = 0.48364290)\n",
            "Loss_G = 4.50037909 (ave = 4.75293369)\n",
            "\n",
            "epoch: [63/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.595s / 10iters, (0.059)\tData load 0.094s / 10iters, (0.009418)\n",
            "Loss_D = 0.92454952 (ave = 0.50687183)\n",
            "Loss_G = 6.88961983 (ave = 4.78978589)\n",
            "\n",
            "epoch: [63/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.664s / 10iters, (0.066)\tData load 0.111s / 10iters, (0.011052)\n",
            "Loss_D = 0.79542476 (ave = 0.50801654)\n",
            "Loss_G = 5.01270199 (ave = 4.80195521)\n",
            "\n",
            "epoch: [63/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.679s / 10iters, (0.068)\tData load 0.090s / 10iters, (0.008984)\n",
            "Loss_D = 0.69551200 (ave = 0.50772032)\n",
            "Loss_G = 5.29645586 (ave = 4.76791643)\n",
            "\n",
            "epoch: [63/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.758s / 10iters, (0.076)\tData load 0.072s / 10iters, (0.007219)\n",
            "Loss_D = 0.16560334 (ave = 0.49130678)\n",
            "Loss_G = 4.70181799 (ave = 4.75377060)\n",
            "\n",
            "epoch: [63/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.619s / 10iters, (0.062)\tData load 0.068s / 10iters, (0.006825)\n",
            "Loss_D = 0.30081818 (ave = 0.48235789)\n",
            "Loss_G = 6.30033445 (ave = 4.71113285)\n",
            "\n",
            "epoch: [63/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.610s / 10iters, (0.061)\tData load 0.075s / 10iters, (0.007454)\n",
            "Loss_D = 0.32700944 (ave = 0.48174161)\n",
            "Loss_G = 4.43457127 (ave = 4.71462447)\n",
            "\n",
            "epoch: [63/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.625s / 10iters, (0.062)\tData load 0.110s / 10iters, (0.010989)\n",
            "Loss_D = 0.29882979 (ave = 0.47424268)\n",
            "Loss_G = 5.08449554 (ave = 4.69435339)\n",
            "\n",
            "epoch: [63/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.634s / 10iters, (0.063)\tData load 0.060s / 10iters, (0.006012)\n",
            "Loss_D = 0.51740474 (ave = 0.46725154)\n",
            "Loss_G = 2.47200513 (ave = 4.67791934)\n",
            "\n",
            "epoch: [63/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.663s / 10iters, (0.066)\tData load 0.083s / 10iters, (0.008317)\n",
            "Loss_D = 0.98674214 (ave = 0.46667672)\n",
            "Loss_G = 2.98271537 (ave = 4.67822422)\n",
            "\n",
            "epoch: [63/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.572s / 10iters, (0.057)\tData load 0.075s / 10iters, (0.007536)\n",
            "Loss_D = 0.40330109 (ave = 0.46936089)\n",
            "Loss_G = 5.22414637 (ave = 4.71166563)\n",
            "\n",
            "epoch: [63/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.645s / 10iters, (0.064)\tData load 0.074s / 10iters, (0.007369)\n",
            "Loss_D = 0.26024994 (ave = 0.46593363)\n",
            "Loss_G = 4.74977207 (ave = 4.68984204)\n",
            "\n",
            "epoch: [63/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.619s / 10iters, (0.062)\tData load 0.082s / 10iters, (0.008196)\n",
            "Loss_D = 0.77876961 (ave = 0.46396774)\n",
            "Loss_G = 3.09874201 (ave = 4.68355323)\n",
            "\n",
            "epoch: [63/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.644s / 10iters, (0.064)\tData load 0.097s / 10iters, (0.009723)\n",
            "Loss_D = 0.62376273 (ave = 0.46415014)\n",
            "Loss_G = 4.26446438 (ave = 4.68033039)\n",
            "\n",
            "epoch: [63/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.596s / 10iters, (0.060)\tData load 0.085s / 10iters, (0.008539)\n",
            "Loss_D = 0.31028330 (ave = 0.45497740)\n",
            "Loss_G = 4.60339546 (ave = 4.67629083)\n",
            "\n",
            "epoch: [63/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.330s / 10iters, (0.033)\tData load 0.067s / 10iters, (0.006685)\n",
            "Loss_D = 0.36713982 (ave = 0.45344078)\n",
            "Loss_G = 5.16666698 (ave = 4.66851662)\n",
            "\n",
            "epoch: [63/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.066s / 3iters, (0.022)\tData load 0.016s / 3iters, (0.005280)\n",
            "Loss_D = 0.70954973 (ave = 0.45366299)\n",
            "Loss_G = 2.72803736 (ave = 4.65614203)\n",
            "\n",
            "Real Accuracy : 90.10261502813638\n",
            "Fake Accuracy : 3.5749751737835154\n",
            "epoch: [64/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.037s / 10iters, (0.504)\tData load 4.389s / 10iters, (0.438895)\n",
            "Loss_D = 0.57554650 (ave = 0.43076748)\n",
            "Loss_G = 4.47771406 (ave = 5.25795615)\n",
            "\n",
            "epoch: [64/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.764s / 10iters, (0.076)\tData load 0.087s / 10iters, (0.008738)\n",
            "Loss_D = 0.27304232 (ave = 0.38369956)\n",
            "Loss_G = 2.66938996 (ave = 4.53330268)\n",
            "\n",
            "epoch: [64/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.605s / 10iters, (0.060)\tData load 0.063s / 10iters, (0.006253)\n",
            "Loss_D = 0.64777589 (ave = 0.41526468)\n",
            "Loss_G = 5.17883539 (ave = 4.41811596)\n",
            "\n",
            "epoch: [64/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.660s / 10iters, (0.066)\tData load 0.080s / 10iters, (0.007965)\n",
            "Loss_D = 0.48536360 (ave = 0.40757229)\n",
            "Loss_G = 6.85838366 (ave = 4.49231244)\n",
            "\n",
            "epoch: [64/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.658s / 10iters, (0.066)\tData load 0.084s / 10iters, (0.008433)\n",
            "Loss_D = 0.48038581 (ave = 0.46257142)\n",
            "Loss_G = 6.62469196 (ave = 4.67402443)\n",
            "\n",
            "epoch: [64/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.701s / 10iters, (0.070)\tData load 0.087s / 10iters, (0.008710)\n",
            "Loss_D = 0.72323143 (ave = 0.44925105)\n",
            "Loss_G = 3.34787989 (ave = 4.78480304)\n",
            "\n",
            "epoch: [64/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.531s / 10iters, (0.053)\tData load 0.081s / 10iters, (0.008091)\n",
            "Loss_D = 0.21964152 (ave = 0.43940507)\n",
            "Loss_G = 3.70429778 (ave = 4.84556042)\n",
            "\n",
            "epoch: [64/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.598s / 10iters, (0.060)\tData load 0.071s / 10iters, (0.007142)\n",
            "Loss_D = 0.13411972 (ave = 0.44262807)\n",
            "Loss_G = 3.43692303 (ave = 4.84917685)\n",
            "\n",
            "epoch: [64/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.648s / 10iters, (0.065)\tData load 0.101s / 10iters, (0.010106)\n",
            "Loss_D = 0.70355135 (ave = 0.43640263)\n",
            "Loss_G = 4.05004215 (ave = 4.85427288)\n",
            "\n",
            "epoch: [64/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.673s / 10iters, (0.067)\tData load 0.164s / 10iters, (0.016386)\n",
            "Loss_D = 0.08175511 (ave = 0.43999425)\n",
            "Loss_G = 5.20748043 (ave = 4.88614241)\n",
            "\n",
            "epoch: [64/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.664s / 10iters, (0.066)\tData load 0.098s / 10iters, (0.009782)\n",
            "Loss_D = 0.34326816 (ave = 0.44293127)\n",
            "Loss_G = 6.16284990 (ave = 4.86484699)\n",
            "\n",
            "epoch: [64/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.699s / 10iters, (0.070)\tData load 0.075s / 10iters, (0.007467)\n",
            "Loss_D = 0.32058772 (ave = 0.46369452)\n",
            "Loss_G = 6.38804436 (ave = 4.89763521)\n",
            "\n",
            "epoch: [64/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.657s / 10iters, (0.066)\tData load 0.070s / 10iters, (0.007025)\n",
            "Loss_D = 0.66106832 (ave = 0.46372511)\n",
            "Loss_G = 3.92698908 (ave = 4.87057775)\n",
            "\n",
            "epoch: [64/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.623s / 10iters, (0.062)\tData load 0.074s / 10iters, (0.007406)\n",
            "Loss_D = 0.25832710 (ave = 0.45406857)\n",
            "Loss_G = 3.42799640 (ave = 4.83471285)\n",
            "\n",
            "epoch: [64/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.688s / 10iters, (0.069)\tData load 0.072s / 10iters, (0.007196)\n",
            "Loss_D = 0.25121847 (ave = 0.45032153)\n",
            "Loss_G = 4.86369658 (ave = 4.79833154)\n",
            "\n",
            "epoch: [64/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.656s / 10iters, (0.066)\tData load 0.114s / 10iters, (0.011415)\n",
            "Loss_D = 0.29457653 (ave = 0.44479132)\n",
            "Loss_G = 6.50946379 (ave = 4.79876801)\n",
            "\n",
            "epoch: [64/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.581s / 10iters, (0.058)\tData load 0.083s / 10iters, (0.008277)\n",
            "Loss_D = 0.21148184 (ave = 0.44050519)\n",
            "Loss_G = 5.22046423 (ave = 4.77350203)\n",
            "\n",
            "epoch: [64/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.708s / 10iters, (0.071)\tData load 0.074s / 10iters, (0.007351)\n",
            "Loss_D = 0.52500129 (ave = 0.44095243)\n",
            "Loss_G = 3.34060788 (ave = 4.76976366)\n",
            "\n",
            "epoch: [64/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.561s / 10iters, (0.056)\tData load 0.069s / 10iters, (0.006948)\n",
            "Loss_D = 0.29339221 (ave = 0.43935908)\n",
            "Loss_G = 4.19462681 (ave = 4.75990988)\n",
            "\n",
            "epoch: [64/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.615s / 10iters, (0.062)\tData load 0.096s / 10iters, (0.009555)\n",
            "Loss_D = 0.69733500 (ave = 0.43916640)\n",
            "Loss_G = 3.02843475 (ave = 4.75044281)\n",
            "\n",
            "epoch: [64/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.616s / 10iters, (0.062)\tData load 0.075s / 10iters, (0.007512)\n",
            "Loss_D = 0.36398312 (ave = 0.44121035)\n",
            "Loss_G = 5.76967812 (ave = 4.78772194)\n",
            "\n",
            "epoch: [64/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.648s / 10iters, (0.065)\tData load 0.087s / 10iters, (0.008721)\n",
            "Loss_D = 0.52182901 (ave = 0.44265941)\n",
            "Loss_G = 4.08636236 (ave = 4.77372192)\n",
            "\n",
            "epoch: [64/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.341s / 10iters, (0.034)\tData load 0.061s / 10iters, (0.006094)\n",
            "Loss_D = 0.42705217 (ave = 0.44362076)\n",
            "Loss_G = 3.37012219 (ave = 4.77907014)\n",
            "\n",
            "epoch: [64/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.067s / 3iters, (0.022)\tData load 0.017s / 3iters, (0.005512)\n",
            "Loss_D = 0.11649920 (ave = 0.44666782)\n",
            "Loss_G = 3.93922424 (ave = 4.79507747)\n",
            "\n",
            "Real Accuracy : 90.93015557762331\n",
            "Fake Accuracy : 3.0122476001324063\n",
            "epoch: [65/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.167s / 10iters, (0.517)\tData load 4.428s / 10iters, (0.442767)\n",
            "Loss_D = 0.10750885 (ave = 0.32291350)\n",
            "Loss_G = 6.29035187 (ave = 4.43364780)\n",
            "\n",
            "epoch: [65/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.683s / 10iters, (0.068)\tData load 0.093s / 10iters, (0.009288)\n",
            "Loss_D = 0.49461979 (ave = 0.40808488)\n",
            "Loss_G = 4.47347212 (ave = 4.73060776)\n",
            "\n",
            "epoch: [65/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.632s / 10iters, (0.063)\tData load 0.093s / 10iters, (0.009272)\n",
            "Loss_D = 0.34514043 (ave = 0.39171211)\n",
            "Loss_G = 2.65937304 (ave = 4.68436955)\n",
            "\n",
            "epoch: [65/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.633s / 10iters, (0.063)\tData load 0.085s / 10iters, (0.008484)\n",
            "Loss_D = 0.63079977 (ave = 0.38592412)\n",
            "Loss_G = 2.93719721 (ave = 4.72454333)\n",
            "\n",
            "epoch: [65/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.595s / 10iters, (0.059)\tData load 0.080s / 10iters, (0.008044)\n",
            "Loss_D = 1.49100924 (ave = 0.41882560)\n",
            "Loss_G = 3.94760108 (ave = 4.78674858)\n",
            "\n",
            "epoch: [65/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.635s / 10iters, (0.063)\tData load 0.083s / 10iters, (0.008333)\n",
            "Loss_D = 0.17220250 (ave = 0.40361455)\n",
            "Loss_G = 3.34972596 (ave = 4.75388494)\n",
            "\n",
            "epoch: [65/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.630s / 10iters, (0.063)\tData load 0.072s / 10iters, (0.007190)\n",
            "Loss_D = 0.27809072 (ave = 0.38866176)\n",
            "Loss_G = 3.96683145 (ave = 4.67122455)\n",
            "\n",
            "epoch: [65/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.599s / 10iters, (0.060)\tData load 0.092s / 10iters, (0.009225)\n",
            "Loss_D = 0.55433798 (ave = 0.39783367)\n",
            "Loss_G = 4.82307482 (ave = 4.73613257)\n",
            "\n",
            "epoch: [65/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.601s / 10iters, (0.060)\tData load 0.081s / 10iters, (0.008139)\n",
            "Loss_D = 0.31308693 (ave = 0.40895461)\n",
            "Loss_G = 5.10625505 (ave = 4.77761511)\n",
            "\n",
            "epoch: [65/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.513s / 10iters, (0.051)\tData load 0.057s / 10iters, (0.005741)\n",
            "Loss_D = 0.20720729 (ave = 0.39836163)\n",
            "Loss_G = 4.35714817 (ave = 4.77914590)\n",
            "\n",
            "epoch: [65/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.668s / 10iters, (0.067)\tData load 0.109s / 10iters, (0.010910)\n",
            "Loss_D = 0.85791427 (ave = 0.40988775)\n",
            "Loss_G = 4.17588472 (ave = 4.81671521)\n",
            "\n",
            "epoch: [65/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.699s / 10iters, (0.070)\tData load 0.092s / 10iters, (0.009199)\n",
            "Loss_D = 0.18267107 (ave = 0.40619628)\n",
            "Loss_G = 5.02610588 (ave = 4.85429816)\n",
            "\n",
            "epoch: [65/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.632s / 10iters, (0.063)\tData load 0.064s / 10iters, (0.006420)\n",
            "Loss_D = 0.37695229 (ave = 0.39937331)\n",
            "Loss_G = 3.92904949 (ave = 4.82009256)\n",
            "\n",
            "epoch: [65/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.688s / 10iters, (0.069)\tData load 0.071s / 10iters, (0.007058)\n",
            "Loss_D = 0.12228752 (ave = 0.41406784)\n",
            "Loss_G = 1.35290730 (ave = 4.78732762)\n",
            "\n",
            "epoch: [65/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.632s / 10iters, (0.063)\tData load 0.062s / 10iters, (0.006184)\n",
            "Loss_D = 0.55039167 (ave = 0.43539622)\n",
            "Loss_G = 4.24078941 (ave = 4.81132468)\n",
            "\n",
            "epoch: [65/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.577s / 10iters, (0.058)\tData load 0.090s / 10iters, (0.009011)\n",
            "Loss_D = 0.35535887 (ave = 0.42946197)\n",
            "Loss_G = 6.07498837 (ave = 4.80591900)\n",
            "\n",
            "epoch: [65/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.639s / 10iters, (0.064)\tData load 0.098s / 10iters, (0.009806)\n",
            "Loss_D = 0.51608020 (ave = 0.43574658)\n",
            "Loss_G = 7.72614956 (ave = 4.79125870)\n",
            "\n",
            "epoch: [65/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.595s / 10iters, (0.059)\tData load 0.081s / 10iters, (0.008113)\n",
            "Loss_D = 0.29087028 (ave = 0.44025696)\n",
            "Loss_G = 3.83638024 (ave = 4.77933616)\n",
            "\n",
            "epoch: [65/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.593s / 10iters, (0.059)\tData load 0.094s / 10iters, (0.009421)\n",
            "Loss_D = 0.25934088 (ave = 0.43251686)\n",
            "Loss_G = 5.16313601 (ave = 4.78474596)\n",
            "\n",
            "epoch: [65/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.637s / 10iters, (0.064)\tData load 0.074s / 10iters, (0.007354)\n",
            "Loss_D = 0.13974138 (ave = 0.43484205)\n",
            "Loss_G = 4.27426100 (ave = 4.80865937)\n",
            "\n",
            "epoch: [65/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.639s / 10iters, (0.064)\tData load 0.064s / 10iters, (0.006431)\n",
            "Loss_D = 0.86254197 (ave = 0.43590390)\n",
            "Loss_G = 2.09328818 (ave = 4.79918705)\n",
            "\n",
            "epoch: [65/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.584s / 10iters, (0.058)\tData load 0.074s / 10iters, (0.007435)\n",
            "Loss_D = 0.24582115 (ave = 0.44551104)\n",
            "Loss_G = 4.79795837 (ave = 4.82428035)\n",
            "\n",
            "epoch: [65/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.375s / 10iters, (0.038)\tData load 0.063s / 10iters, (0.006285)\n",
            "Loss_D = 0.74193066 (ave = 0.45285768)\n",
            "Loss_G = 8.07169247 (ave = 4.85107614)\n",
            "\n",
            "epoch: [65/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.066s / 3iters, (0.022)\tData load 0.014s / 3iters, (0.004722)\n",
            "Loss_D = 0.10026567 (ave = 0.44872267)\n",
            "Loss_G = 4.04772854 (ave = 4.85734593)\n",
            "\n",
            "Real Accuracy : 90.4998344918901\n",
            "Fake Accuracy : 4.005296259516716\n",
            "epoch: [66/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.000s / 10iters, (0.500)\tData load 4.401s / 10iters, (0.440132)\n",
            "Loss_D = 0.28642249 (ave = 0.64704919)\n",
            "Loss_G = 6.65883923 (ave = 5.08962283)\n",
            "\n",
            "epoch: [66/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.664s / 10iters, (0.066)\tData load 0.096s / 10iters, (0.009597)\n",
            "Loss_D = 0.94200838 (ave = 0.60396792)\n",
            "Loss_G = 6.64833641 (ave = 4.80929149)\n",
            "\n",
            "epoch: [66/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.640s / 10iters, (0.064)\tData load 0.117s / 10iters, (0.011725)\n",
            "Loss_D = 0.51881278 (ave = 0.54061692)\n",
            "Loss_G = 5.07612658 (ave = 4.78073955)\n",
            "\n",
            "epoch: [66/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.588s / 10iters, (0.059)\tData load 0.082s / 10iters, (0.008234)\n",
            "Loss_D = 0.15641010 (ave = 0.51227133)\n",
            "Loss_G = 3.92778039 (ave = 4.70951779)\n",
            "\n",
            "epoch: [66/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.643s / 10iters, (0.064)\tData load 0.081s / 10iters, (0.008051)\n",
            "Loss_D = 0.19882360 (ave = 0.47363902)\n",
            "Loss_G = 3.36383605 (ave = 4.62344138)\n",
            "\n",
            "epoch: [66/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.672s / 10iters, (0.067)\tData load 0.082s / 10iters, (0.008152)\n",
            "Loss_D = 0.39627898 (ave = 0.45447108)\n",
            "Loss_G = 5.07910872 (ave = 4.71641121)\n",
            "\n",
            "epoch: [66/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.516s / 10iters, (0.052)\tData load 0.060s / 10iters, (0.005997)\n",
            "Loss_D = 0.87269002 (ave = 0.45103790)\n",
            "Loss_G = 6.87940311 (ave = 4.69668687)\n",
            "\n",
            "epoch: [66/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.692s / 10iters, (0.069)\tData load 0.089s / 10iters, (0.008885)\n",
            "Loss_D = 0.27465725 (ave = 0.44808427)\n",
            "Loss_G = 3.93302369 (ave = 4.72587804)\n",
            "\n",
            "epoch: [66/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.633s / 10iters, (0.063)\tData load 0.084s / 10iters, (0.008386)\n",
            "Loss_D = 1.25913990 (ave = 0.46733677)\n",
            "Loss_G = 2.83992743 (ave = 4.74736537)\n",
            "\n",
            "epoch: [66/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.565s / 10iters, (0.057)\tData load 0.085s / 10iters, (0.008527)\n",
            "Loss_D = 0.54071075 (ave = 0.45777808)\n",
            "Loss_G = 4.41507292 (ave = 4.69627101)\n",
            "\n",
            "epoch: [66/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.679s / 10iters, (0.068)\tData load 0.098s / 10iters, (0.009773)\n",
            "Loss_D = 0.18494444 (ave = 0.45230488)\n",
            "Loss_G = 3.88064671 (ave = 4.74582727)\n",
            "\n",
            "epoch: [66/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.702s / 10iters, (0.070)\tData load 0.085s / 10iters, (0.008464)\n",
            "Loss_D = 0.51885808 (ave = 0.45450078)\n",
            "Loss_G = 6.22469521 (ave = 4.75823454)\n",
            "\n",
            "epoch: [66/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.574s / 10iters, (0.057)\tData load 0.093s / 10iters, (0.009282)\n",
            "Loss_D = 1.14560032 (ave = 0.45973663)\n",
            "Loss_G = 4.60566950 (ave = 4.77625205)\n",
            "\n",
            "epoch: [66/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.674s / 10iters, (0.067)\tData load 0.108s / 10iters, (0.010787)\n",
            "Loss_D = 0.51580518 (ave = 0.45397312)\n",
            "Loss_G = 3.19081998 (ave = 4.77170340)\n",
            "\n",
            "epoch: [66/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.755s / 10iters, (0.076)\tData load 0.087s / 10iters, (0.008684)\n",
            "Loss_D = 0.32540777 (ave = 0.45565668)\n",
            "Loss_G = 5.11959934 (ave = 4.74446100)\n",
            "\n",
            "epoch: [66/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.572s / 10iters, (0.057)\tData load 0.045s / 10iters, (0.004455)\n",
            "Loss_D = 0.55996680 (ave = 0.44735307)\n",
            "Loss_G = 2.71504760 (ave = 4.70980910)\n",
            "\n",
            "epoch: [66/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.611s / 10iters, (0.061)\tData load 0.085s / 10iters, (0.008533)\n",
            "Loss_D = 0.20901860 (ave = 0.44324848)\n",
            "Loss_G = 4.48055935 (ave = 4.67749510)\n",
            "\n",
            "epoch: [66/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.620s / 10iters, (0.062)\tData load 0.111s / 10iters, (0.011068)\n",
            "Loss_D = 0.28203273 (ave = 0.43768123)\n",
            "Loss_G = 4.88023090 (ave = 4.66119426)\n",
            "\n",
            "epoch: [66/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.587s / 10iters, (0.059)\tData load 0.091s / 10iters, (0.009148)\n",
            "Loss_D = 0.43778169 (ave = 0.43434854)\n",
            "Loss_G = 5.76001167 (ave = 4.62470238)\n",
            "\n",
            "epoch: [66/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.603s / 10iters, (0.060)\tData load 0.059s / 10iters, (0.005854)\n",
            "Loss_D = 0.38478720 (ave = 0.42759500)\n",
            "Loss_G = 4.61125994 (ave = 4.63110473)\n",
            "\n",
            "epoch: [66/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.714s / 10iters, (0.071)\tData load 0.065s / 10iters, (0.006526)\n",
            "Loss_D = 1.51521778 (ave = 0.42738111)\n",
            "Loss_G = 7.89404774 (ave = 4.62486138)\n",
            "\n",
            "epoch: [66/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.675s / 10iters, (0.068)\tData load 0.073s / 10iters, (0.007329)\n",
            "Loss_D = 0.47839093 (ave = 0.42171692)\n",
            "Loss_G = 5.24838781 (ave = 4.60938683)\n",
            "\n",
            "epoch: [66/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.289s / 10iters, (0.029)\tData load 0.049s / 10iters, (0.004938)\n",
            "Loss_D = 0.54777819 (ave = 0.42040329)\n",
            "Loss_G = 4.71358442 (ave = 4.60845936)\n",
            "\n",
            "epoch: [66/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.073s / 3iters, (0.024)\tData load 0.015s / 3iters, (0.005156)\n",
            "Loss_D = 0.29938442 (ave = 0.42013103)\n",
            "Loss_G = 1.92573678 (ave = 4.59291766)\n",
            "\n",
            "Real Accuracy : 91.19496855345912\n",
            "Fake Accuracy : 3.4756703078450846\n",
            "epoch: [67/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.148s / 10iters, (0.515)\tData load 4.319s / 10iters, (0.431901)\n",
            "Loss_D = 0.25084817 (ave = 0.54068913)\n",
            "Loss_G = 4.68175554 (ave = 5.45454931)\n",
            "\n",
            "epoch: [67/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.642s / 10iters, (0.064)\tData load 0.081s / 10iters, (0.008069)\n",
            "Loss_D = 0.93561071 (ave = 0.56013622)\n",
            "Loss_G = 7.45179939 (ave = 5.24921737)\n",
            "\n",
            "epoch: [67/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.577s / 10iters, (0.058)\tData load 0.093s / 10iters, (0.009348)\n",
            "Loss_D = 0.07798176 (ave = 0.52793252)\n",
            "Loss_G = 5.91172123 (ave = 5.07229706)\n",
            "\n",
            "epoch: [67/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.694s / 10iters, (0.069)\tData load 0.082s / 10iters, (0.008181)\n",
            "Loss_D = 0.54584444 (ave = 0.51175849)\n",
            "Loss_G = 2.36610746 (ave = 4.96182131)\n",
            "\n",
            "epoch: [67/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.634s / 10iters, (0.063)\tData load 0.071s / 10iters, (0.007149)\n",
            "Loss_D = 0.14505780 (ave = 0.49689488)\n",
            "Loss_G = 3.99526215 (ave = 4.95461115)\n",
            "\n",
            "epoch: [67/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.606s / 10iters, (0.061)\tData load 0.088s / 10iters, (0.008831)\n",
            "Loss_D = 0.22701831 (ave = 0.46405635)\n",
            "Loss_G = 4.79014111 (ave = 4.88129073)\n",
            "\n",
            "epoch: [67/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.609s / 10iters, (0.061)\tData load 0.083s / 10iters, (0.008260)\n",
            "Loss_D = 0.17039917 (ave = 0.45726382)\n",
            "Loss_G = 4.92561102 (ave = 4.90815337)\n",
            "\n",
            "epoch: [67/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.585s / 10iters, (0.058)\tData load 0.101s / 10iters, (0.010052)\n",
            "Loss_D = 0.18670063 (ave = 0.46524658)\n",
            "Loss_G = 4.01648760 (ave = 4.87929361)\n",
            "\n",
            "epoch: [67/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.639s / 10iters, (0.064)\tData load 0.086s / 10iters, (0.008625)\n",
            "Loss_D = 0.38393116 (ave = 0.44748626)\n",
            "Loss_G = 5.76177645 (ave = 4.86683264)\n",
            "\n",
            "epoch: [67/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.680s / 10iters, (0.068)\tData load 0.079s / 10iters, (0.007918)\n",
            "Loss_D = 0.39309666 (ave = 0.44319310)\n",
            "Loss_G = 5.55218792 (ave = 4.89168000)\n",
            "\n",
            "epoch: [67/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.625s / 10iters, (0.062)\tData load 0.090s / 10iters, (0.009038)\n",
            "Loss_D = 0.15749794 (ave = 0.44704992)\n",
            "Loss_G = 4.19621611 (ave = 4.84248790)\n",
            "\n",
            "epoch: [67/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.676s / 10iters, (0.068)\tData load 0.085s / 10iters, (0.008501)\n",
            "Loss_D = 0.75060856 (ave = 0.44210442)\n",
            "Loss_G = 4.00327873 (ave = 4.80407389)\n",
            "\n",
            "epoch: [67/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.574s / 10iters, (0.057)\tData load 0.088s / 10iters, (0.008753)\n",
            "Loss_D = 0.21982950 (ave = 0.43936726)\n",
            "Loss_G = 3.95895815 (ave = 4.79598610)\n",
            "\n",
            "epoch: [67/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.610s / 10iters, (0.061)\tData load 0.083s / 10iters, (0.008282)\n",
            "Loss_D = 0.82566756 (ave = 0.43415144)\n",
            "Loss_G = 8.19472599 (ave = 4.77767620)\n",
            "\n",
            "epoch: [67/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.661s / 10iters, (0.066)\tData load 0.077s / 10iters, (0.007705)\n",
            "Loss_D = 0.21305755 (ave = 0.42748380)\n",
            "Loss_G = 4.34435558 (ave = 4.75275619)\n",
            "\n",
            "epoch: [67/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.498s / 10iters, (0.050)\tData load 0.061s / 10iters, (0.006092)\n",
            "Loss_D = 0.67609859 (ave = 0.42385265)\n",
            "Loss_G = 7.39910793 (ave = 4.77108844)\n",
            "\n",
            "epoch: [67/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.665s / 10iters, (0.067)\tData load 0.105s / 10iters, (0.010452)\n",
            "Loss_D = 0.26783422 (ave = 0.42505193)\n",
            "Loss_G = 5.98488951 (ave = 4.82103862)\n",
            "\n",
            "epoch: [67/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.667s / 10iters, (0.067)\tData load 0.041s / 10iters, (0.004100)\n",
            "Loss_D = 0.43563628 (ave = 0.43771338)\n",
            "Loss_G = 3.79770136 (ave = 4.78835383)\n",
            "\n",
            "epoch: [67/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.641s / 10iters, (0.064)\tData load 0.077s / 10iters, (0.007737)\n",
            "Loss_D = 1.08041167 (ave = 0.44048597)\n",
            "Loss_G = 6.90867281 (ave = 4.80188496)\n",
            "\n",
            "epoch: [67/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.610s / 10iters, (0.061)\tData load 0.078s / 10iters, (0.007800)\n",
            "Loss_D = 0.32091755 (ave = 0.43675730)\n",
            "Loss_G = 6.13104534 (ave = 4.77771315)\n",
            "\n",
            "epoch: [67/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.658s / 10iters, (0.066)\tData load 0.074s / 10iters, (0.007436)\n",
            "Loss_D = 0.10166319 (ave = 0.43705429)\n",
            "Loss_G = 7.84059095 (ave = 4.82590325)\n",
            "\n",
            "epoch: [67/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.601s / 10iters, (0.060)\tData load 0.112s / 10iters, (0.011176)\n",
            "Loss_D = 0.22888234 (ave = 0.43069684)\n",
            "Loss_G = 4.61456680 (ave = 4.82558046)\n",
            "\n",
            "epoch: [67/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.298s / 10iters, (0.030)\tData load 0.059s / 10iters, (0.005905)\n",
            "Loss_D = 0.34798890 (ave = 0.42992154)\n",
            "Loss_G = 4.58731413 (ave = 4.79600268)\n",
            "\n",
            "epoch: [67/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.067s / 3iters, (0.022)\tData load 0.016s / 3iters, (0.005413)\n",
            "Loss_D = 0.78359997 (ave = 0.43604047)\n",
            "Loss_G = 3.19641471 (ave = 4.79717992)\n",
            "\n",
            "Real Accuracy : 91.6583912611718\n",
            "Fake Accuracy : 3.4756703078450846\n",
            "epoch: [68/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.026s / 10iters, (0.503)\tData load 4.330s / 10iters, (0.432954)\n",
            "Loss_D = 0.30526161 (ave = 0.37185766)\n",
            "Loss_G = 2.84888077 (ave = 5.30952742)\n",
            "\n",
            "epoch: [68/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.611s / 10iters, (0.061)\tData load 0.088s / 10iters, (0.008788)\n",
            "Loss_D = 0.35805762 (ave = 0.42677447)\n",
            "Loss_G = 4.88871002 (ave = 5.36629328)\n",
            "\n",
            "epoch: [68/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.639s / 10iters, (0.064)\tData load 0.089s / 10iters, (0.008899)\n",
            "Loss_D = 0.37163833 (ave = 0.38364409)\n",
            "Loss_G = 5.55463982 (ave = 5.24366961)\n",
            "\n",
            "epoch: [68/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.680s / 10iters, (0.068)\tData load 0.093s / 10iters, (0.009347)\n",
            "Loss_D = 0.63019276 (ave = 0.36049472)\n",
            "Loss_G = 2.56730008 (ave = 5.09890093)\n",
            "\n",
            "epoch: [68/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.592s / 10iters, (0.059)\tData load 0.083s / 10iters, (0.008336)\n",
            "Loss_D = 0.63610220 (ave = 0.40130525)\n",
            "Loss_G = 6.71985865 (ave = 5.09548372)\n",
            "\n",
            "epoch: [68/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.636s / 10iters, (0.064)\tData load 0.083s / 10iters, (0.008346)\n",
            "Loss_D = 0.25773871 (ave = 0.39522158)\n",
            "Loss_G = 4.57670021 (ave = 5.03083701)\n",
            "\n",
            "epoch: [68/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.668s / 10iters, (0.067)\tData load 0.066s / 10iters, (0.006574)\n",
            "Loss_D = 0.11715725 (ave = 0.39804275)\n",
            "Loss_G = 6.32987738 (ave = 5.00156420)\n",
            "\n",
            "epoch: [68/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.570s / 10iters, (0.057)\tData load 0.069s / 10iters, (0.006893)\n",
            "Loss_D = 0.23358440 (ave = 0.39552811)\n",
            "Loss_G = 5.47876024 (ave = 4.95519165)\n",
            "\n",
            "epoch: [68/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.587s / 10iters, (0.059)\tData load 0.097s / 10iters, (0.009712)\n",
            "Loss_D = 0.22247006 (ave = 0.38509357)\n",
            "Loss_G = 4.86510181 (ave = 4.92580135)\n",
            "\n",
            "epoch: [68/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.699s / 10iters, (0.070)\tData load 0.092s / 10iters, (0.009180)\n",
            "Loss_D = 0.44732797 (ave = 0.39873821)\n",
            "Loss_G = 3.59687185 (ave = 4.91544822)\n",
            "\n",
            "epoch: [68/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.630s / 10iters, (0.063)\tData load 0.073s / 10iters, (0.007345)\n",
            "Loss_D = 0.31409615 (ave = 0.38735568)\n",
            "Loss_G = 5.40448713 (ave = 4.92684066)\n",
            "\n",
            "epoch: [68/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.744s / 10iters, (0.074)\tData load 0.067s / 10iters, (0.006695)\n",
            "Loss_D = 0.21327440 (ave = 0.38314730)\n",
            "Loss_G = 2.59754777 (ave = 4.91014095)\n",
            "\n",
            "epoch: [68/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.616s / 10iters, (0.062)\tData load 0.088s / 10iters, (0.008774)\n",
            "Loss_D = 0.51477385 (ave = 0.38450722)\n",
            "Loss_G = 7.77509499 (ave = 4.91227992)\n",
            "\n",
            "epoch: [68/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.634s / 10iters, (0.063)\tData load 0.103s / 10iters, (0.010312)\n",
            "Loss_D = 0.11530250 (ave = 0.40156727)\n",
            "Loss_G = 8.00857735 (ave = 4.96184456)\n",
            "\n",
            "epoch: [68/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.594s / 10iters, (0.059)\tData load 0.069s / 10iters, (0.006946)\n",
            "Loss_D = 0.84040838 (ave = 0.41725472)\n",
            "Loss_G = 7.27804375 (ave = 4.93476436)\n",
            "\n",
            "epoch: [68/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.456s / 10iters, (0.046)\tData load 0.076s / 10iters, (0.007578)\n",
            "Loss_D = 0.16140410 (ave = 0.41864079)\n",
            "Loss_G = 3.19295239 (ave = 4.93317932)\n",
            "\n",
            "epoch: [68/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.719s / 10iters, (0.072)\tData load 0.105s / 10iters, (0.010509)\n",
            "Loss_D = 0.22361715 (ave = 0.41759735)\n",
            "Loss_G = 5.65035009 (ave = 4.96186468)\n",
            "\n",
            "epoch: [68/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.712s / 10iters, (0.071)\tData load 0.071s / 10iters, (0.007111)\n",
            "Loss_D = 0.48217362 (ave = 0.41475944)\n",
            "Loss_G = 3.58896852 (ave = 4.94307356)\n",
            "\n",
            "epoch: [68/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.667s / 10iters, (0.067)\tData load 0.077s / 10iters, (0.007732)\n",
            "Loss_D = 2.14519978 (ave = 0.42772013)\n",
            "Loss_G = 5.14203548 (ave = 4.93982383)\n",
            "\n",
            "epoch: [68/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.626s / 10iters, (0.063)\tData load 0.065s / 10iters, (0.006487)\n",
            "Loss_D = 0.90357792 (ave = 0.43113697)\n",
            "Loss_G = 3.42932105 (ave = 4.95476086)\n",
            "\n",
            "epoch: [68/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.670s / 10iters, (0.067)\tData load 0.080s / 10iters, (0.008000)\n",
            "Loss_D = 0.30707222 (ave = 0.43736596)\n",
            "Loss_G = 4.18885517 (ave = 4.95540450)\n",
            "\n",
            "epoch: [68/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.648s / 10iters, (0.065)\tData load 0.066s / 10iters, (0.006640)\n",
            "Loss_D = 1.74514842 (ave = 0.45145591)\n",
            "Loss_G = 10.46335888 (ave = 4.99603746)\n",
            "\n",
            "epoch: [68/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.355s / 10iters, (0.035)\tData load 0.066s / 10iters, (0.006566)\n",
            "Loss_D = 0.55288064 (ave = 0.46008225)\n",
            "Loss_G = 1.86910391 (ave = 4.98968738)\n",
            "\n",
            "epoch: [68/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.070s / 3iters, (0.023)\tData load 0.013s / 3iters, (0.004380)\n",
            "Loss_D = 2.83943486 (ave = 0.47162587)\n",
            "Loss_G = 3.41264725 (ave = 5.00577232)\n",
            "\n",
            "Real Accuracy : 90.63224097980802\n",
            "Fake Accuracy : 3.7735849056603774\n",
            "epoch: [69/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.092s / 10iters, (0.509)\tData load 4.420s / 10iters, (0.441997)\n",
            "Loss_D = 1.96014166 (ave = 0.75223897)\n",
            "Loss_G = 9.99302578 (ave = 5.63879943)\n",
            "\n",
            "epoch: [69/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.641s / 10iters, (0.064)\tData load 0.092s / 10iters, (0.009207)\n",
            "Loss_D = 1.63922191 (ave = 0.72441470)\n",
            "Loss_G = 8.58353138 (ave = 5.40950887)\n",
            "\n",
            "epoch: [69/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.630s / 10iters, (0.063)\tData load 0.077s / 10iters, (0.007671)\n",
            "Loss_D = 0.54681391 (ave = 0.64620010)\n",
            "Loss_G = 4.93928480 (ave = 5.50845048)\n",
            "\n",
            "epoch: [69/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.674s / 10iters, (0.067)\tData load 0.080s / 10iters, (0.007956)\n",
            "Loss_D = 0.47076079 (ave = 0.64028679)\n",
            "Loss_G = 4.37840891 (ave = 5.46072294)\n",
            "\n",
            "epoch: [69/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.664s / 10iters, (0.066)\tData load 0.095s / 10iters, (0.009495)\n",
            "Loss_D = 0.23520391 (ave = 0.61964078)\n",
            "Loss_G = 3.97764921 (ave = 5.51837630)\n",
            "\n",
            "epoch: [69/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.621s / 10iters, (0.062)\tData load 0.091s / 10iters, (0.009105)\n",
            "Loss_D = 0.94484222 (ave = 0.58311231)\n",
            "Loss_G = 4.32049465 (ave = 5.35651807)\n",
            "\n",
            "epoch: [69/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.603s / 10iters, (0.060)\tData load 0.089s / 10iters, (0.008922)\n",
            "Loss_D = 0.58314025 (ave = 0.55983578)\n",
            "Loss_G = 4.68466997 (ave = 5.34174161)\n",
            "\n",
            "epoch: [69/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.695s / 10iters, (0.070)\tData load 0.112s / 10iters, (0.011246)\n",
            "Loss_D = 0.24469282 (ave = 0.52441694)\n",
            "Loss_G = 4.88945103 (ave = 5.24196660)\n",
            "\n",
            "epoch: [69/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.585s / 10iters, (0.059)\tData load 0.068s / 10iters, (0.006763)\n",
            "Loss_D = 0.43272588 (ave = 0.52127714)\n",
            "Loss_G = 5.10060883 (ave = 5.19673685)\n",
            "\n",
            "epoch: [69/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.627s / 10iters, (0.063)\tData load 0.083s / 10iters, (0.008349)\n",
            "Loss_D = 0.29990244 (ave = 0.50871045)\n",
            "Loss_G = 3.05536652 (ave = 5.15914453)\n",
            "\n",
            "epoch: [69/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.620s / 10iters, (0.062)\tData load 0.084s / 10iters, (0.008413)\n",
            "Loss_D = 0.77388918 (ave = 0.49571935)\n",
            "Loss_G = 8.09967232 (ave = 5.11866345)\n",
            "\n",
            "epoch: [69/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.690s / 10iters, (0.069)\tData load 0.097s / 10iters, (0.009688)\n",
            "Loss_D = 0.53664380 (ave = 0.49017282)\n",
            "Loss_G = 3.90366507 (ave = 5.13476224)\n",
            "\n",
            "epoch: [69/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.672s / 10iters, (0.067)\tData load 0.100s / 10iters, (0.010012)\n",
            "Loss_D = 0.37401134 (ave = 0.47968102)\n",
            "Loss_G = 5.59919310 (ave = 5.13623292)\n",
            "\n",
            "epoch: [69/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.611s / 10iters, (0.061)\tData load 0.082s / 10iters, (0.008153)\n",
            "Loss_D = 0.29022384 (ave = 0.46530945)\n",
            "Loss_G = 4.98095131 (ave = 5.10875522)\n",
            "\n",
            "epoch: [69/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.653s / 10iters, (0.065)\tData load 0.075s / 10iters, (0.007539)\n",
            "Loss_D = 0.26313394 (ave = 0.45355158)\n",
            "Loss_G = 6.01497984 (ave = 5.04137735)\n",
            "\n",
            "epoch: [69/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.706s / 10iters, (0.071)\tData load 0.091s / 10iters, (0.009103)\n",
            "Loss_D = 1.08655500 (ave = 0.45796147)\n",
            "Loss_G = 3.97530651 (ave = 5.00818346)\n",
            "\n",
            "epoch: [69/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.630s / 10iters, (0.063)\tData load 0.072s / 10iters, (0.007240)\n",
            "Loss_D = 0.26653153 (ave = 0.45259983)\n",
            "Loss_G = 4.92076349 (ave = 4.98742745)\n",
            "\n",
            "epoch: [69/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.590s / 10iters, (0.059)\tData load 0.066s / 10iters, (0.006619)\n",
            "Loss_D = 0.66355562 (ave = 0.44762664)\n",
            "Loss_G = 4.50001669 (ave = 5.00119919)\n",
            "\n",
            "epoch: [69/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.637s / 10iters, (0.064)\tData load 0.090s / 10iters, (0.009001)\n",
            "Loss_D = 0.29276031 (ave = 0.44656693)\n",
            "Loss_G = 6.14940166 (ave = 5.00386498)\n",
            "\n",
            "epoch: [69/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.655s / 10iters, (0.066)\tData load 0.101s / 10iters, (0.010149)\n",
            "Loss_D = 0.44621620 (ave = 0.44516809)\n",
            "Loss_G = 5.56894636 (ave = 5.00215550)\n",
            "\n",
            "epoch: [69/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.615s / 10iters, (0.062)\tData load 0.091s / 10iters, (0.009062)\n",
            "Loss_D = 0.72035599 (ave = 0.44954238)\n",
            "Loss_G = 6.02515078 (ave = 5.02227577)\n",
            "\n",
            "epoch: [69/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.598s / 10iters, (0.060)\tData load 0.080s / 10iters, (0.008022)\n",
            "Loss_D = 0.69257623 (ave = 0.44601586)\n",
            "Loss_G = 7.28360653 (ave = 5.02652981)\n",
            "\n",
            "epoch: [69/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.336s / 10iters, (0.034)\tData load 0.062s / 10iters, (0.006193)\n",
            "Loss_D = 0.67995709 (ave = 0.44727737)\n",
            "Loss_G = 4.62668324 (ave = 5.02998360)\n",
            "\n",
            "epoch: [69/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.066s / 3iters, (0.022)\tData load 0.016s / 3iters, (0.005306)\n",
            "Loss_D = 0.20658574 (ave = 0.44569052)\n",
            "Loss_G = 4.23120403 (ave = 5.01424214)\n",
            "\n",
            "Real Accuracy : 90.79774908970539\n",
            "Fake Accuracy : 3.1777557100297913\n",
            "epoch: [70/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.120s / 10iters, (0.512)\tData load 4.347s / 10iters, (0.434724)\n",
            "Loss_D = 0.46850511 (ave = 0.31195255)\n",
            "Loss_G = 4.02653742 (ave = 5.01960492)\n",
            "\n",
            "epoch: [70/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.683s / 10iters, (0.068)\tData load 0.088s / 10iters, (0.008777)\n",
            "Loss_D = 0.10574304 (ave = 0.30570444)\n",
            "Loss_G = 4.37725782 (ave = 4.78185915)\n",
            "\n",
            "epoch: [70/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.624s / 10iters, (0.062)\tData load 0.091s / 10iters, (0.009116)\n",
            "Loss_D = 0.25170502 (ave = 0.32624306)\n",
            "Loss_G = 5.18024349 (ave = 4.85134506)\n",
            "\n",
            "epoch: [70/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.639s / 10iters, (0.064)\tData load 0.081s / 10iters, (0.008113)\n",
            "Loss_D = 0.06946310 (ave = 0.35058833)\n",
            "Loss_G = 4.79335880 (ave = 4.82012594)\n",
            "\n",
            "epoch: [70/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.625s / 10iters, (0.063)\tData load 0.113s / 10iters, (0.011284)\n",
            "Loss_D = 0.14866941 (ave = 0.34801384)\n",
            "Loss_G = 4.88886595 (ave = 4.92401418)\n",
            "\n",
            "epoch: [70/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.643s / 10iters, (0.064)\tData load 0.096s / 10iters, (0.009614)\n",
            "Loss_D = 0.11184231 (ave = 0.33809785)\n",
            "Loss_G = 4.00917864 (ave = 4.88665189)\n",
            "\n",
            "epoch: [70/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.635s / 10iters, (0.064)\tData load 0.084s / 10iters, (0.008367)\n",
            "Loss_D = 0.49129105 (ave = 0.34702015)\n",
            "Loss_G = 7.17322779 (ave = 4.91691344)\n",
            "\n",
            "epoch: [70/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.663s / 10iters, (0.066)\tData load 0.096s / 10iters, (0.009581)\n",
            "Loss_D = 0.63455671 (ave = 0.33745448)\n",
            "Loss_G = 2.91748452 (ave = 4.81536084)\n",
            "\n",
            "epoch: [70/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.654s / 10iters, (0.065)\tData load 0.084s / 10iters, (0.008429)\n",
            "Loss_D = 0.43176839 (ave = 0.33882393)\n",
            "Loss_G = 5.78713179 (ave = 4.81910529)\n",
            "\n",
            "epoch: [70/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.662s / 10iters, (0.066)\tData load 0.087s / 10iters, (0.008733)\n",
            "Loss_D = 0.54481405 (ave = 0.33178802)\n",
            "Loss_G = 5.39088535 (ave = 4.80413037)\n",
            "\n",
            "epoch: [70/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.647s / 10iters, (0.065)\tData load 0.085s / 10iters, (0.008496)\n",
            "Loss_D = 0.29695398 (ave = 0.35173847)\n",
            "Loss_G = 3.03515387 (ave = 4.81608909)\n",
            "\n",
            "epoch: [70/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.645s / 10iters, (0.065)\tData load 0.075s / 10iters, (0.007507)\n",
            "Loss_D = 1.10908258 (ave = 0.35194183)\n",
            "Loss_G = 5.39878798 (ave = 4.78047235)\n",
            "\n",
            "epoch: [70/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.648s / 10iters, (0.065)\tData load 0.082s / 10iters, (0.008210)\n",
            "Loss_D = 1.01784635 (ave = 0.36629104)\n",
            "Loss_G = 6.14148760 (ave = 4.78894698)\n",
            "\n",
            "epoch: [70/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.648s / 10iters, (0.065)\tData load 0.071s / 10iters, (0.007120)\n",
            "Loss_D = 0.19964442 (ave = 0.37516337)\n",
            "Loss_G = 4.86479044 (ave = 4.82868934)\n",
            "\n",
            "epoch: [70/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.542s / 10iters, (0.054)\tData load 0.066s / 10iters, (0.006589)\n",
            "Loss_D = 0.47991306 (ave = 0.37464398)\n",
            "Loss_G = 6.50566435 (ave = 4.87285468)\n",
            "\n",
            "epoch: [70/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.753s / 10iters, (0.075)\tData load 0.096s / 10iters, (0.009596)\n",
            "Loss_D = 0.76150477 (ave = 0.37065033)\n",
            "Loss_G = 7.45561552 (ave = 4.91652682)\n",
            "\n",
            "epoch: [70/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.615s / 10iters, (0.062)\tData load 0.061s / 10iters, (0.006088)\n",
            "Loss_D = 0.18267535 (ave = 0.37008286)\n",
            "Loss_G = 5.62765789 (ave = 4.93393624)\n",
            "\n",
            "epoch: [70/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.590s / 10iters, (0.059)\tData load 0.076s / 10iters, (0.007633)\n",
            "Loss_D = 0.49158540 (ave = 0.36704154)\n",
            "Loss_G = 2.81196260 (ave = 4.90872476)\n",
            "\n",
            "epoch: [70/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.639s / 10iters, (0.064)\tData load 0.107s / 10iters, (0.010662)\n",
            "Loss_D = 0.14036641 (ave = 0.36442318)\n",
            "Loss_G = 5.39566278 (ave = 4.89725621)\n",
            "\n",
            "epoch: [70/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.610s / 10iters, (0.061)\tData load 0.074s / 10iters, (0.007383)\n",
            "Loss_D = 0.70537764 (ave = 0.36763018)\n",
            "Loss_G = 4.04264402 (ave = 4.89477063)\n",
            "\n",
            "epoch: [70/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.584s / 10iters, (0.058)\tData load 0.093s / 10iters, (0.009327)\n",
            "Loss_D = 0.52492476 (ave = 0.36834853)\n",
            "Loss_G = 4.00637722 (ave = 4.87878544)\n",
            "\n",
            "epoch: [70/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.674s / 10iters, (0.067)\tData load 0.102s / 10iters, (0.010195)\n",
            "Loss_D = 0.85269344 (ave = 0.36770728)\n",
            "Loss_G = 4.10513401 (ave = 4.87955562)\n",
            "\n",
            "epoch: [70/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.314s / 10iters, (0.031)\tData load 0.059s / 10iters, (0.005870)\n",
            "Loss_D = 0.15363444 (ave = 0.37019949)\n",
            "Loss_G = 3.86117435 (ave = 4.89054958)\n",
            "\n",
            "epoch: [70/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.068s / 3iters, (0.023)\tData load 0.017s / 3iters, (0.005786)\n",
            "Loss_D = 0.04689079 (ave = 0.36821358)\n",
            "Loss_G = 6.34453964 (ave = 4.89649550)\n",
            "\n",
            "Real Accuracy : 92.91625289639192\n",
            "Fake Accuracy : 3.2108573320092684\n",
            "epoch: [71/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.256s / 10iters, (0.526)\tData load 4.433s / 10iters, (0.443277)\n",
            "Loss_D = 0.47629544 (ave = 0.26710478)\n",
            "Loss_G = 3.57019067 (ave = 4.51633983)\n",
            "\n",
            "epoch: [71/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.634s / 10iters, (0.063)\tData load 0.083s / 10iters, (0.008291)\n",
            "Loss_D = 0.74210262 (ave = 0.30310005)\n",
            "Loss_G = 5.90516567 (ave = 4.68926942)\n",
            "\n",
            "epoch: [71/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.603s / 10iters, (0.060)\tData load 0.100s / 10iters, (0.010025)\n",
            "Loss_D = 0.68947953 (ave = 0.28144134)\n",
            "Loss_G = 5.80949926 (ave = 4.67047697)\n",
            "\n",
            "epoch: [71/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.559s / 10iters, (0.056)\tData load 0.096s / 10iters, (0.009635)\n",
            "Loss_D = 0.45698121 (ave = 0.29381095)\n",
            "Loss_G = 6.89491081 (ave = 4.83571394)\n",
            "\n",
            "epoch: [71/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.663s / 10iters, (0.066)\tData load 0.083s / 10iters, (0.008349)\n",
            "Loss_D = 0.52322984 (ave = 0.30924732)\n",
            "Loss_G = 6.17661524 (ave = 4.87618347)\n",
            "\n",
            "epoch: [71/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.640s / 10iters, (0.064)\tData load 0.083s / 10iters, (0.008310)\n",
            "Loss_D = 0.10038547 (ave = 0.30210020)\n",
            "Loss_G = 2.89267325 (ave = 4.86376168)\n",
            "\n",
            "epoch: [71/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.623s / 10iters, (0.062)\tData load 0.114s / 10iters, (0.011438)\n",
            "Loss_D = 0.08304960 (ave = 0.30054989)\n",
            "Loss_G = 4.73787642 (ave = 4.94410753)\n",
            "\n",
            "epoch: [71/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.642s / 10iters, (0.064)\tData load 0.070s / 10iters, (0.007044)\n",
            "Loss_D = 0.47133812 (ave = 0.31121825)\n",
            "Loss_G = 7.26776314 (ave = 4.93223813)\n",
            "\n",
            "epoch: [71/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.495s / 10iters, (0.049)\tData load 0.068s / 10iters, (0.006848)\n",
            "Loss_D = 0.72128242 (ave = 0.32886195)\n",
            "Loss_G = 3.76044869 (ave = 4.99666015)\n",
            "\n",
            "epoch: [71/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.611s / 10iters, (0.061)\tData load 0.078s / 10iters, (0.007760)\n",
            "Loss_D = 0.63107657 (ave = 0.34723495)\n",
            "Loss_G = 7.32777643 (ave = 5.03293916)\n",
            "\n",
            "epoch: [71/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.747s / 10iters, (0.075)\tData load 0.080s / 10iters, (0.008001)\n",
            "Loss_D = 0.28773090 (ave = 0.34384670)\n",
            "Loss_G = 3.79068470 (ave = 5.09436127)\n",
            "\n",
            "epoch: [71/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.720s / 10iters, (0.072)\tData load 0.083s / 10iters, (0.008295)\n",
            "Loss_D = 0.18216518 (ave = 0.35973449)\n",
            "Loss_G = 4.78261852 (ave = 5.11410818)\n",
            "\n",
            "epoch: [71/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.615s / 10iters, (0.061)\tData load 0.097s / 10iters, (0.009656)\n",
            "Loss_D = 0.51414621 (ave = 0.37549588)\n",
            "Loss_G = 4.91889000 (ave = 5.14913703)\n",
            "\n",
            "epoch: [71/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.618s / 10iters, (0.062)\tData load 0.049s / 10iters, (0.004875)\n",
            "Loss_D = 0.37034670 (ave = 0.37613560)\n",
            "Loss_G = 4.35752010 (ave = 5.10616991)\n",
            "\n",
            "epoch: [71/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.669s / 10iters, (0.067)\tData load 0.057s / 10iters, (0.005670)\n",
            "Loss_D = 0.12112845 (ave = 0.37001232)\n",
            "Loss_G = 5.19533348 (ave = 5.12105615)\n",
            "\n",
            "epoch: [71/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.607s / 10iters, (0.061)\tData load 0.078s / 10iters, (0.007816)\n",
            "Loss_D = 0.07783524 (ave = 0.37539780)\n",
            "Loss_G = 3.19194818 (ave = 5.08049048)\n",
            "\n",
            "epoch: [71/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.606s / 10iters, (0.061)\tData load 0.088s / 10iters, (0.008802)\n",
            "Loss_D = 0.14741097 (ave = 0.38477268)\n",
            "Loss_G = 6.60808134 (ave = 5.11259504)\n",
            "\n",
            "epoch: [71/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.542s / 10iters, (0.054)\tData load 0.062s / 10iters, (0.006176)\n",
            "Loss_D = 0.51641399 (ave = 0.38521723)\n",
            "Loss_G = 5.68095970 (ave = 5.12332036)\n",
            "\n",
            "epoch: [71/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.647s / 10iters, (0.065)\tData load 0.081s / 10iters, (0.008104)\n",
            "Loss_D = 0.11262001 (ave = 0.37738133)\n",
            "Loss_G = 3.55473733 (ave = 5.10103387)\n",
            "\n",
            "epoch: [71/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.605s / 10iters, (0.061)\tData load 0.067s / 10iters, (0.006713)\n",
            "Loss_D = 0.38189331 (ave = 0.38299482)\n",
            "Loss_G = 4.11109781 (ave = 5.08962425)\n",
            "\n",
            "epoch: [71/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.630s / 10iters, (0.063)\tData load 0.076s / 10iters, (0.007609)\n",
            "Loss_D = 0.21597497 (ave = 0.39308631)\n",
            "Loss_G = 3.73319125 (ave = 5.12231792)\n",
            "\n",
            "epoch: [71/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.583s / 10iters, (0.058)\tData load 0.117s / 10iters, (0.011718)\n",
            "Loss_D = 0.38299215 (ave = 0.40378063)\n",
            "Loss_G = 5.94988203 (ave = 5.11994632)\n",
            "\n",
            "epoch: [71/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.308s / 10iters, (0.031)\tData load 0.063s / 10iters, (0.006266)\n",
            "Loss_D = 0.93886304 (ave = 0.40471255)\n",
            "Loss_G = 2.59212255 (ave = 5.09672715)\n",
            "\n",
            "epoch: [71/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.071s / 3iters, (0.024)\tData load 0.014s / 3iters, (0.004727)\n",
            "Loss_D = 0.77196163 (ave = 0.40884060)\n",
            "Loss_G = 5.66273642 (ave = 5.11757172)\n",
            "\n",
            "Real Accuracy : 91.72459450513075\n",
            "Fake Accuracy : 3.2439589539887455\n",
            "epoch: [72/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 4.841s / 10iters, (0.484)\tData load 4.244s / 10iters, (0.424399)\n",
            "Loss_D = 0.19276986 (ave = 0.36167267)\n",
            "Loss_G = 4.15410471 (ave = 4.03480487)\n",
            "\n",
            "epoch: [72/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.728s / 10iters, (0.073)\tData load 0.093s / 10iters, (0.009293)\n",
            "Loss_D = 0.18016198 (ave = 0.29172579)\n",
            "Loss_G = 4.10526085 (ave = 4.16340961)\n",
            "\n",
            "epoch: [72/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.695s / 10iters, (0.070)\tData load 0.062s / 10iters, (0.006158)\n",
            "Loss_D = 0.10120487 (ave = 0.31986966)\n",
            "Loss_G = 5.29731560 (ave = 4.47077148)\n",
            "\n",
            "epoch: [72/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.569s / 10iters, (0.057)\tData load 0.080s / 10iters, (0.008022)\n",
            "Loss_D = 0.22556771 (ave = 0.33988561)\n",
            "Loss_G = 5.30260515 (ave = 4.70748902)\n",
            "\n",
            "epoch: [72/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.647s / 10iters, (0.065)\tData load 0.094s / 10iters, (0.009373)\n",
            "Loss_D = 0.15501383 (ave = 0.36033201)\n",
            "Loss_G = 4.99007225 (ave = 4.78143447)\n",
            "\n",
            "epoch: [72/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.630s / 10iters, (0.063)\tData load 0.072s / 10iters, (0.007225)\n",
            "Loss_D = 0.25150579 (ave = 0.36393663)\n",
            "Loss_G = 4.40311050 (ave = 4.77263850)\n",
            "\n",
            "epoch: [72/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.490s / 10iters, (0.049)\tData load 0.065s / 10iters, (0.006545)\n",
            "Loss_D = 0.15538828 (ave = 0.35247530)\n",
            "Loss_G = 3.98420763 (ave = 4.73992252)\n",
            "\n",
            "epoch: [72/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.720s / 10iters, (0.072)\tData load 0.102s / 10iters, (0.010205)\n",
            "Loss_D = 0.44660789 (ave = 0.37732200)\n",
            "Loss_G = 7.52205229 (ave = 4.79315502)\n",
            "\n",
            "epoch: [72/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.611s / 10iters, (0.061)\tData load 0.054s / 10iters, (0.005380)\n",
            "Loss_D = 0.08824591 (ave = 0.37609270)\n",
            "Loss_G = 4.52419329 (ave = 4.70602984)\n",
            "\n",
            "epoch: [72/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.617s / 10iters, (0.062)\tData load 0.077s / 10iters, (0.007654)\n",
            "Loss_D = 0.47854272 (ave = 0.37750793)\n",
            "Loss_G = 4.83811855 (ave = 4.76140360)\n",
            "\n",
            "epoch: [72/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.564s / 10iters, (0.056)\tData load 0.075s / 10iters, (0.007460)\n",
            "Loss_D = 0.60020441 (ave = 0.37668159)\n",
            "Loss_G = 6.10811090 (ave = 4.73249861)\n",
            "\n",
            "epoch: [72/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.538s / 10iters, (0.054)\tData load 0.069s / 10iters, (0.006878)\n",
            "Loss_D = 0.08777718 (ave = 0.39377770)\n",
            "Loss_G = 3.51421499 (ave = 4.75644317)\n",
            "\n",
            "epoch: [72/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.728s / 10iters, (0.073)\tData load 0.068s / 10iters, (0.006783)\n",
            "Loss_D = 0.45337093 (ave = 0.38491002)\n",
            "Loss_G = 8.75250435 (ave = 4.76845253)\n",
            "\n",
            "epoch: [72/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.706s / 10iters, (0.071)\tData load 0.097s / 10iters, (0.009731)\n",
            "Loss_D = 1.84817195 (ave = 0.39815343)\n",
            "Loss_G = 3.74788928 (ave = 4.75668298)\n",
            "\n",
            "epoch: [72/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.488s / 10iters, (0.049)\tData load 0.070s / 10iters, (0.006952)\n",
            "Loss_D = 0.29461917 (ave = 0.38903297)\n",
            "Loss_G = 4.02929401 (ave = 4.76468221)\n",
            "\n",
            "epoch: [72/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.693s / 10iters, (0.069)\tData load 0.124s / 10iters, (0.012351)\n",
            "Loss_D = 0.34239978 (ave = 0.38362692)\n",
            "Loss_G = 4.23504305 (ave = 4.73511901)\n",
            "\n",
            "epoch: [72/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.691s / 10iters, (0.069)\tData load 0.100s / 10iters, (0.009994)\n",
            "Loss_D = 0.62785840 (ave = 0.39021473)\n",
            "Loss_G = 5.80412388 (ave = 4.76131315)\n",
            "\n",
            "epoch: [72/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.647s / 10iters, (0.065)\tData load 0.051s / 10iters, (0.005148)\n",
            "Loss_D = 0.23192780 (ave = 0.38480333)\n",
            "Loss_G = 3.78585196 (ave = 4.76711790)\n",
            "\n",
            "epoch: [72/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.585s / 10iters, (0.058)\tData load 0.068s / 10iters, (0.006764)\n",
            "Loss_D = 0.53643233 (ave = 0.38086921)\n",
            "Loss_G = 7.30820560 (ave = 4.78215660)\n",
            "\n",
            "epoch: [72/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.651s / 10iters, (0.065)\tData load 0.103s / 10iters, (0.010300)\n",
            "Loss_D = 0.43321621 (ave = 0.39361207)\n",
            "Loss_G = 4.18426561 (ave = 4.80085501)\n",
            "\n",
            "epoch: [72/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.615s / 10iters, (0.061)\tData load 0.084s / 10iters, (0.008351)\n",
            "Loss_D = 0.48370624 (ave = 0.38704339)\n",
            "Loss_G = 4.84664297 (ave = 4.80743674)\n",
            "\n",
            "epoch: [72/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.658s / 10iters, (0.066)\tData load 0.091s / 10iters, (0.009080)\n",
            "Loss_D = 0.13343312 (ave = 0.38765892)\n",
            "Loss_G = 2.71065521 (ave = 4.80669194)\n",
            "\n",
            "epoch: [72/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.294s / 10iters, (0.029)\tData load 0.064s / 10iters, (0.006424)\n",
            "Loss_D = 0.20604959 (ave = 0.39532696)\n",
            "Loss_G = 4.26916265 (ave = 4.82572405)\n",
            "\n",
            "epoch: [72/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.066s / 3iters, (0.022)\tData load 0.015s / 3iters, (0.005011)\n",
            "Loss_D = 0.45607597 (ave = 0.39351143)\n",
            "Loss_G = 4.78461599 (ave = 4.81717856)\n",
            "\n",
            "Real Accuracy : 92.02250910294605\n",
            "Fake Accuracy : 3.839788149619331\n",
            "epoch: [73/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.015s / 10iters, (0.502)\tData load 4.281s / 10iters, (0.428090)\n",
            "Loss_D = 0.19947787 (ave = 0.41229770)\n",
            "Loss_G = 2.19015384 (ave = 5.28865051)\n",
            "\n",
            "epoch: [73/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.638s / 10iters, (0.064)\tData load 0.105s / 10iters, (0.010508)\n",
            "Loss_D = 0.57844496 (ave = 0.57174641)\n",
            "Loss_G = 4.72613525 (ave = 5.56676499)\n",
            "\n",
            "epoch: [73/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.511s / 10iters, (0.051)\tData load 0.062s / 10iters, (0.006192)\n",
            "Loss_D = 0.49245000 (ave = 0.48381366)\n",
            "Loss_G = 7.08811855 (ave = 5.47899489)\n",
            "\n",
            "epoch: [73/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.771s / 10iters, (0.077)\tData load 0.115s / 10iters, (0.011537)\n",
            "Loss_D = 0.24023002 (ave = 0.46448227)\n",
            "Loss_G = 4.14530659 (ave = 5.42978495)\n",
            "\n",
            "epoch: [73/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.599s / 10iters, (0.060)\tData load 0.075s / 10iters, (0.007458)\n",
            "Loss_D = 0.17641595 (ave = 0.42265894)\n",
            "Loss_G = 3.01407528 (ave = 5.28245743)\n",
            "\n",
            "epoch: [73/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.673s / 10iters, (0.067)\tData load 0.096s / 10iters, (0.009598)\n",
            "Loss_D = 0.14679140 (ave = 0.39386969)\n",
            "Loss_G = 7.34209013 (ave = 5.22084762)\n",
            "\n",
            "epoch: [73/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.613s / 10iters, (0.061)\tData load 0.104s / 10iters, (0.010392)\n",
            "Loss_D = 0.40438077 (ave = 0.41690395)\n",
            "Loss_G = 2.50398302 (ave = 5.07291227)\n",
            "\n",
            "epoch: [73/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.646s / 10iters, (0.065)\tData load 0.084s / 10iters, (0.008422)\n",
            "Loss_D = 0.27441767 (ave = 0.43400439)\n",
            "Loss_G = 6.20273256 (ave = 5.04233760)\n",
            "\n",
            "epoch: [73/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.610s / 10iters, (0.061)\tData load 0.104s / 10iters, (0.010380)\n",
            "Loss_D = 0.06603792 (ave = 0.41352393)\n",
            "Loss_G = 4.03798580 (ave = 5.06059437)\n",
            "\n",
            "epoch: [73/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.618s / 10iters, (0.062)\tData load 0.110s / 10iters, (0.011018)\n",
            "Loss_D = 0.17093226 (ave = 0.40874539)\n",
            "Loss_G = 5.32954931 (ave = 5.07903853)\n",
            "\n",
            "epoch: [73/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.603s / 10iters, (0.060)\tData load 0.098s / 10iters, (0.009807)\n",
            "Loss_D = 0.66084760 (ave = 0.41039900)\n",
            "Loss_G = 6.83442736 (ave = 5.09165637)\n",
            "\n",
            "epoch: [73/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.716s / 10iters, (0.072)\tData load 0.109s / 10iters, (0.010866)\n",
            "Loss_D = 0.40092301 (ave = 0.41266406)\n",
            "Loss_G = 6.78088379 (ave = 5.12463800)\n",
            "\n",
            "epoch: [73/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.654s / 10iters, (0.065)\tData load 0.099s / 10iters, (0.009879)\n",
            "Loss_D = 0.78761822 (ave = 0.40677740)\n",
            "Loss_G = 6.24444675 (ave = 5.12945417)\n",
            "\n",
            "epoch: [73/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.545s / 10iters, (0.055)\tData load 0.070s / 10iters, (0.006958)\n",
            "Loss_D = 1.03929949 (ave = 0.41007053)\n",
            "Loss_G = 8.96364212 (ave = 5.13910394)\n",
            "\n",
            "epoch: [73/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.763s / 10iters, (0.076)\tData load 0.082s / 10iters, (0.008168)\n",
            "Loss_D = 0.47120726 (ave = 0.41203057)\n",
            "Loss_G = 4.34501076 (ave = 5.17896202)\n",
            "\n",
            "epoch: [73/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.594s / 10iters, (0.059)\tData load 0.082s / 10iters, (0.008231)\n",
            "Loss_D = 0.16726811 (ave = 0.41285212)\n",
            "Loss_G = 5.54978180 (ave = 5.19738070)\n",
            "\n",
            "epoch: [73/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.602s / 10iters, (0.060)\tData load 0.095s / 10iters, (0.009480)\n",
            "Loss_D = 1.28545964 (ave = 0.43120179)\n",
            "Loss_G = 4.10307789 (ave = 5.23069885)\n",
            "\n",
            "epoch: [73/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.638s / 10iters, (0.064)\tData load 0.109s / 10iters, (0.010905)\n",
            "Loss_D = 0.41432214 (ave = 0.43037596)\n",
            "Loss_G = 5.12357998 (ave = 5.22618272)\n",
            "\n",
            "epoch: [73/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.650s / 10iters, (0.065)\tData load 0.101s / 10iters, (0.010081)\n",
            "Loss_D = 0.57925391 (ave = 0.43021097)\n",
            "Loss_G = 3.07848644 (ave = 5.18945637)\n",
            "\n",
            "epoch: [73/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.633s / 10iters, (0.063)\tData load 0.065s / 10iters, (0.006463)\n",
            "Loss_D = 0.15175515 (ave = 0.42924998)\n",
            "Loss_G = 2.93525529 (ave = 5.16450446)\n",
            "\n",
            "epoch: [73/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.622s / 10iters, (0.062)\tData load 0.102s / 10iters, (0.010212)\n",
            "Loss_D = 0.24635175 (ave = 0.42504368)\n",
            "Loss_G = 5.36631441 (ave = 5.15847471)\n",
            "\n",
            "epoch: [73/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.636s / 10iters, (0.064)\tData load 0.084s / 10iters, (0.008361)\n",
            "Loss_D = 0.48146671 (ave = 0.43028616)\n",
            "Loss_G = 3.92307305 (ave = 5.15577271)\n",
            "\n",
            "epoch: [73/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.343s / 10iters, (0.034)\tData load 0.076s / 10iters, (0.007648)\n",
            "Loss_D = 0.13993818 (ave = 0.43419827)\n",
            "Loss_G = 5.83235168 (ave = 5.16797395)\n",
            "\n",
            "epoch: [73/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.067s / 3iters, (0.022)\tData load 0.014s / 3iters, (0.004796)\n",
            "Loss_D = 0.58543557 (ave = 0.43313355)\n",
            "Loss_G = 4.94049931 (ave = 5.16330502)\n",
            "\n",
            "Real Accuracy : 90.99635882158226\n",
            "Fake Accuracy : 2.9791459781529297\n",
            "epoch: [74/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.095s / 10iters, (0.509)\tData load 4.323s / 10iters, (0.432322)\n",
            "Loss_D = 0.60513633 (ave = 0.42043851)\n",
            "Loss_G = 4.05664349 (ave = 4.99559617)\n",
            "\n",
            "epoch: [74/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.702s / 10iters, (0.070)\tData load 0.086s / 10iters, (0.008595)\n",
            "Loss_D = 0.53311276 (ave = 0.43965362)\n",
            "Loss_G = 3.69619918 (ave = 4.65623082)\n",
            "\n",
            "epoch: [74/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.692s / 10iters, (0.069)\tData load 0.105s / 10iters, (0.010547)\n",
            "Loss_D = 0.46092126 (ave = 0.44601349)\n",
            "Loss_G = 6.70034552 (ave = 4.82429100)\n",
            "\n",
            "epoch: [74/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.595s / 10iters, (0.059)\tData load 0.093s / 10iters, (0.009280)\n",
            "Loss_D = 0.18263429 (ave = 0.41355804)\n",
            "Loss_G = 3.64904356 (ave = 4.95592024)\n",
            "\n",
            "epoch: [74/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.642s / 10iters, (0.064)\tData load 0.103s / 10iters, (0.010261)\n",
            "Loss_D = 0.82600975 (ave = 0.42900065)\n",
            "Loss_G = 6.07605076 (ave = 5.06013013)\n",
            "\n",
            "epoch: [74/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.640s / 10iters, (0.064)\tData load 0.122s / 10iters, (0.012173)\n",
            "Loss_D = 0.76580840 (ave = 0.41841801)\n",
            "Loss_G = 5.88642311 (ave = 5.16037310)\n",
            "\n",
            "epoch: [74/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.650s / 10iters, (0.065)\tData load 0.100s / 10iters, (0.009978)\n",
            "Loss_D = 0.15943913 (ave = 0.41819265)\n",
            "Loss_G = 3.65094018 (ave = 5.13453623)\n",
            "\n",
            "epoch: [74/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.646s / 10iters, (0.065)\tData load 0.090s / 10iters, (0.009040)\n",
            "Loss_D = 0.53101474 (ave = 0.42519150)\n",
            "Loss_G = 4.85211897 (ave = 5.14584627)\n",
            "\n",
            "epoch: [74/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.653s / 10iters, (0.065)\tData load 0.091s / 10iters, (0.009108)\n",
            "Loss_D = 0.57350749 (ave = 0.41830592)\n",
            "Loss_G = 2.93011141 (ave = 5.11227615)\n",
            "\n",
            "epoch: [74/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.577s / 10iters, (0.058)\tData load 0.096s / 10iters, (0.009611)\n",
            "Loss_D = 0.26522651 (ave = 0.41781478)\n",
            "Loss_G = 6.20055056 (ave = 5.15416951)\n",
            "\n",
            "epoch: [74/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.674s / 10iters, (0.067)\tData load 0.081s / 10iters, (0.008091)\n",
            "Loss_D = 0.23410247 (ave = 0.41963974)\n",
            "Loss_G = 2.97665906 (ave = 5.12491398)\n",
            "\n",
            "epoch: [74/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.733s / 10iters, (0.073)\tData load 0.082s / 10iters, (0.008210)\n",
            "Loss_D = 0.26973978 (ave = 0.42380931)\n",
            "Loss_G = 8.24400997 (ave = 5.13542229)\n",
            "\n",
            "epoch: [74/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.633s / 10iters, (0.063)\tData load 0.094s / 10iters, (0.009357)\n",
            "Loss_D = 0.41515344 (ave = 0.41162461)\n",
            "Loss_G = 5.49309778 (ave = 5.13306234)\n",
            "\n",
            "epoch: [74/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.633s / 10iters, (0.063)\tData load 0.082s / 10iters, (0.008205)\n",
            "Loss_D = 1.50207758 (ave = 0.41674917)\n",
            "Loss_G = 2.19607353 (ave = 5.09426538)\n",
            "\n",
            "epoch: [74/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.670s / 10iters, (0.067)\tData load 0.094s / 10iters, (0.009411)\n",
            "Loss_D = 0.18903400 (ave = 0.40795462)\n",
            "Loss_G = 4.34351969 (ave = 5.09265411)\n",
            "\n",
            "epoch: [74/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.649s / 10iters, (0.065)\tData load 0.080s / 10iters, (0.007979)\n",
            "Loss_D = 0.71073997 (ave = 0.40278564)\n",
            "Loss_G = 3.46585822 (ave = 5.07127219)\n",
            "\n",
            "epoch: [74/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.642s / 10iters, (0.064)\tData load 0.058s / 10iters, (0.005835)\n",
            "Loss_D = 0.60239673 (ave = 0.39653134)\n",
            "Loss_G = 3.59911442 (ave = 5.06965835)\n",
            "\n",
            "epoch: [74/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.674s / 10iters, (0.067)\tData load 0.064s / 10iters, (0.006414)\n",
            "Loss_D = 0.64298666 (ave = 0.40722308)\n",
            "Loss_G = 7.21207380 (ave = 5.12442517)\n",
            "\n",
            "epoch: [74/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.670s / 10iters, (0.067)\tData load 0.077s / 10iters, (0.007727)\n",
            "Loss_D = 0.31279516 (ave = 0.41445009)\n",
            "Loss_G = 5.45652866 (ave = 5.18051727)\n",
            "\n",
            "epoch: [74/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.655s / 10iters, (0.065)\tData load 0.084s / 10iters, (0.008432)\n",
            "Loss_D = 0.11620565 (ave = 0.41138452)\n",
            "Loss_G = 5.81232500 (ave = 5.19262989)\n",
            "\n",
            "epoch: [74/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.573s / 10iters, (0.057)\tData load 0.067s / 10iters, (0.006706)\n",
            "Loss_D = 2.80906224 (ave = 0.42363075)\n",
            "Loss_G = 4.38503885 (ave = 5.19892858)\n",
            "\n",
            "epoch: [74/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.706s / 10iters, (0.071)\tData load 0.084s / 10iters, (0.008364)\n",
            "Loss_D = 0.33363330 (ave = 0.42545232)\n",
            "Loss_G = 5.89005327 (ave = 5.21255423)\n",
            "\n",
            "epoch: [74/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.321s / 10iters, (0.032)\tData load 0.056s / 10iters, (0.005648)\n",
            "Loss_D = 0.36464727 (ave = 0.42122181)\n",
            "Loss_G = 2.68340683 (ave = 5.17538456)\n",
            "\n",
            "epoch: [74/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.077s / 3iters, (0.026)\tData load 0.012s / 3iters, (0.004082)\n",
            "Loss_D = 1.07712257 (ave = 0.42352420)\n",
            "Loss_G = 1.80066133 (ave = 5.16272999)\n",
            "\n",
            "Real Accuracy : 91.29427341939756\n",
            "Fake Accuracy : 3.4094670638861304\n",
            "epoch: [75/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.065s / 10iters, (0.507)\tData load 4.417s / 10iters, (0.441691)\n",
            "Loss_D = 0.99411762 (ave = 0.58360832)\n",
            "Loss_G = 7.72049522 (ave = 5.81783137)\n",
            "\n",
            "epoch: [75/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.683s / 10iters, (0.068)\tData load 0.128s / 10iters, (0.012805)\n",
            "Loss_D = 1.00540209 (ave = 0.57169262)\n",
            "Loss_G = 4.94165325 (ave = 5.56353259)\n",
            "\n",
            "epoch: [75/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.607s / 10iters, (0.061)\tData load 0.084s / 10iters, (0.008397)\n",
            "Loss_D = 0.21394256 (ave = 0.50992355)\n",
            "Loss_G = 5.45832729 (ave = 5.70347173)\n",
            "\n",
            "epoch: [75/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.666s / 10iters, (0.067)\tData load 0.078s / 10iters, (0.007769)\n",
            "Loss_D = 0.53428447 (ave = 0.50643284)\n",
            "Loss_G = 6.03704834 (ave = 5.58028123)\n",
            "\n",
            "epoch: [75/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.643s / 10iters, (0.064)\tData load 0.088s / 10iters, (0.008808)\n",
            "Loss_D = 0.12852168 (ave = 0.47181684)\n",
            "Loss_G = 4.99652195 (ave = 5.53772278)\n",
            "\n",
            "epoch: [75/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.604s / 10iters, (0.060)\tData load 0.068s / 10iters, (0.006800)\n",
            "Loss_D = 0.41066504 (ave = 0.44591801)\n",
            "Loss_G = 3.77721548 (ave = 5.50130080)\n",
            "\n",
            "epoch: [75/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.630s / 10iters, (0.063)\tData load 0.084s / 10iters, (0.008391)\n",
            "Loss_D = 0.46268433 (ave = 0.46203579)\n",
            "Loss_G = 3.97077060 (ave = 5.43706713)\n",
            "\n",
            "epoch: [75/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.615s / 10iters, (0.061)\tData load 0.085s / 10iters, (0.008501)\n",
            "Loss_D = 0.32692862 (ave = 0.43837036)\n",
            "Loss_G = 6.20762587 (ave = 5.37767628)\n",
            "\n",
            "epoch: [75/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.622s / 10iters, (0.062)\tData load 0.097s / 10iters, (0.009680)\n",
            "Loss_D = 0.57697016 (ave = 0.41563057)\n",
            "Loss_G = 4.82793808 (ave = 5.30751846)\n",
            "\n",
            "epoch: [75/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.575s / 10iters, (0.058)\tData load 0.086s / 10iters, (0.008621)\n",
            "Loss_D = 0.50613582 (ave = 0.39820419)\n",
            "Loss_G = 2.84657454 (ave = 5.30393783)\n",
            "\n",
            "epoch: [75/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.578s / 10iters, (0.058)\tData load 0.099s / 10iters, (0.009877)\n",
            "Loss_D = 0.70739454 (ave = 0.39070097)\n",
            "Loss_G = 6.27558994 (ave = 5.32653995)\n",
            "\n",
            "epoch: [75/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.706s / 10iters, (0.071)\tData load 0.077s / 10iters, (0.007731)\n",
            "Loss_D = 0.34069473 (ave = 0.38314124)\n",
            "Loss_G = 2.61944366 (ave = 5.26663992)\n",
            "\n",
            "epoch: [75/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.579s / 10iters, (0.058)\tData load 0.071s / 10iters, (0.007128)\n",
            "Loss_D = 0.34745261 (ave = 0.38936011)\n",
            "Loss_G = 4.75635576 (ave = 5.27011174)\n",
            "\n",
            "epoch: [75/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.576s / 10iters, (0.058)\tData load 0.078s / 10iters, (0.007796)\n",
            "Loss_D = 0.23510063 (ave = 0.38398507)\n",
            "Loss_G = 5.56481647 (ave = 5.25546909)\n",
            "\n",
            "epoch: [75/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.637s / 10iters, (0.064)\tData load 0.072s / 10iters, (0.007193)\n",
            "Loss_D = 0.32641375 (ave = 0.37484758)\n",
            "Loss_G = 4.46715069 (ave = 5.22924986)\n",
            "\n",
            "epoch: [75/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.636s / 10iters, (0.064)\tData load 0.080s / 10iters, (0.007959)\n",
            "Loss_D = 0.13930145 (ave = 0.36895871)\n",
            "Loss_G = 6.65250826 (ave = 5.22921435)\n",
            "\n",
            "epoch: [75/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.560s / 10iters, (0.056)\tData load 0.044s / 10iters, (0.004405)\n",
            "Loss_D = 0.10631105 (ave = 0.36022998)\n",
            "Loss_G = 5.36335802 (ave = 5.18615931)\n",
            "\n",
            "epoch: [75/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.688s / 10iters, (0.069)\tData load 0.089s / 10iters, (0.008893)\n",
            "Loss_D = 0.33639213 (ave = 0.35706014)\n",
            "Loss_G = 3.05414200 (ave = 5.16039533)\n",
            "\n",
            "epoch: [75/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.640s / 10iters, (0.064)\tData load 0.068s / 10iters, (0.006806)\n",
            "Loss_D = 0.27307612 (ave = 0.36300130)\n",
            "Loss_G = 5.29967928 (ave = 5.16741974)\n",
            "\n",
            "epoch: [75/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.639s / 10iters, (0.064)\tData load 0.087s / 10iters, (0.008730)\n",
            "Loss_D = 0.34963048 (ave = 0.36086110)\n",
            "Loss_G = 5.14791822 (ave = 5.17499598)\n",
            "\n",
            "epoch: [75/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.650s / 10iters, (0.065)\tData load 0.081s / 10iters, (0.008148)\n",
            "Loss_D = 0.28484449 (ave = 0.35845636)\n",
            "Loss_G = 3.03550959 (ave = 5.15448094)\n",
            "\n",
            "epoch: [75/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.538s / 10iters, (0.054)\tData load 0.094s / 10iters, (0.009434)\n",
            "Loss_D = 0.17881981 (ave = 0.36032540)\n",
            "Loss_G = 4.28490686 (ave = 5.15300717)\n",
            "\n",
            "epoch: [75/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.370s / 10iters, (0.037)\tData load 0.060s / 10iters, (0.006004)\n",
            "Loss_D = 0.43703654 (ave = 0.36218941)\n",
            "Loss_G = 4.99869967 (ave = 5.15411471)\n",
            "\n",
            "epoch: [75/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.064s / 3iters, (0.021)\tData load 0.015s / 3iters, (0.004880)\n",
            "Loss_D = 0.04194961 (ave = 0.36268766)\n",
            "Loss_G = 3.88856316 (ave = 5.14482812)\n",
            "\n",
            "Real Accuracy : 92.58523667659715\n",
            "Fake Accuracy : 3.4425686858656075\n",
            "epoch: [76/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.010s / 10iters, (0.501)\tData load 4.290s / 10iters, (0.428975)\n",
            "Loss_D = 0.16338134 (ave = 0.33944108)\n",
            "Loss_G = 6.70071316 (ave = 5.62830944)\n",
            "\n",
            "epoch: [76/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.665s / 10iters, (0.067)\tData load 0.090s / 10iters, (0.009041)\n",
            "Loss_D = 0.44254565 (ave = 0.35402138)\n",
            "Loss_G = 6.07691193 (ave = 5.48743525)\n",
            "\n",
            "epoch: [76/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.633s / 10iters, (0.063)\tData load 0.070s / 10iters, (0.007036)\n",
            "Loss_D = 1.00857425 (ave = 0.35719560)\n",
            "Loss_G = 9.56638718 (ave = 5.51545771)\n",
            "\n",
            "epoch: [76/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.600s / 10iters, (0.060)\tData load 0.077s / 10iters, (0.007659)\n",
            "Loss_D = 0.36637309 (ave = 0.35640932)\n",
            "Loss_G = 6.53335142 (ave = 5.39762434)\n",
            "\n",
            "epoch: [76/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.550s / 10iters, (0.055)\tData load 0.082s / 10iters, (0.008200)\n",
            "Loss_D = 0.49807519 (ave = 0.34206883)\n",
            "Loss_G = 4.67585802 (ave = 5.43494372)\n",
            "\n",
            "epoch: [76/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.687s / 10iters, (0.069)\tData load 0.127s / 10iters, (0.012693)\n",
            "Loss_D = 0.74325198 (ave = 0.35850293)\n",
            "Loss_G = 2.83420897 (ave = 5.34654596)\n",
            "\n",
            "epoch: [76/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.605s / 10iters, (0.061)\tData load 0.101s / 10iters, (0.010140)\n",
            "Loss_D = 0.10268638 (ave = 0.36839140)\n",
            "Loss_G = 6.79002142 (ave = 5.36293424)\n",
            "\n",
            "epoch: [76/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.594s / 10iters, (0.059)\tData load 0.104s / 10iters, (0.010402)\n",
            "Loss_D = 0.63585222 (ave = 0.36798179)\n",
            "Loss_G = 6.13805199 (ave = 5.37910097)\n",
            "\n",
            "epoch: [76/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.644s / 10iters, (0.064)\tData load 0.109s / 10iters, (0.010869)\n",
            "Loss_D = 0.12359450 (ave = 0.35725438)\n",
            "Loss_G = 3.92296004 (ave = 5.33767646)\n",
            "\n",
            "epoch: [76/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.649s / 10iters, (0.065)\tData load 0.079s / 10iters, (0.007878)\n",
            "Loss_D = 0.22233590 (ave = 0.34853032)\n",
            "Loss_G = 4.42357826 (ave = 5.23395328)\n",
            "\n",
            "epoch: [76/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.628s / 10iters, (0.063)\tData load 0.110s / 10iters, (0.010979)\n",
            "Loss_D = 0.11256140 (ave = 0.35797088)\n",
            "Loss_G = 7.97167253 (ave = 5.25756853)\n",
            "\n",
            "epoch: [76/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.661s / 10iters, (0.066)\tData load 0.098s / 10iters, (0.009787)\n",
            "Loss_D = 0.55657744 (ave = 0.35846920)\n",
            "Loss_G = 7.11437654 (ave = 5.20111739)\n",
            "\n",
            "epoch: [76/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.658s / 10iters, (0.066)\tData load 0.093s / 10iters, (0.009257)\n",
            "Loss_D = 0.09761124 (ave = 0.36454248)\n",
            "Loss_G = 4.93311405 (ave = 5.18146652)\n",
            "\n",
            "epoch: [76/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.605s / 10iters, (0.060)\tData load 0.085s / 10iters, (0.008469)\n",
            "Loss_D = 0.30987996 (ave = 0.37128293)\n",
            "Loss_G = 4.54749298 (ave = 5.15244151)\n",
            "\n",
            "epoch: [76/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.605s / 10iters, (0.060)\tData load 0.092s / 10iters, (0.009230)\n",
            "Loss_D = 0.46767449 (ave = 0.37430786)\n",
            "Loss_G = 6.89869404 (ave = 5.15861713)\n",
            "\n",
            "epoch: [76/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.609s / 10iters, (0.061)\tData load 0.083s / 10iters, (0.008343)\n",
            "Loss_D = 0.40922597 (ave = 0.38676550)\n",
            "Loss_G = 6.38969135 (ave = 5.20962300)\n",
            "\n",
            "epoch: [76/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.602s / 10iters, (0.060)\tData load 0.080s / 10iters, (0.007953)\n",
            "Loss_D = 0.46918932 (ave = 0.39000060)\n",
            "Loss_G = 3.92697859 (ave = 5.20425674)\n",
            "\n",
            "epoch: [76/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.610s / 10iters, (0.061)\tData load 0.083s / 10iters, (0.008340)\n",
            "Loss_D = 0.08473055 (ave = 0.38003222)\n",
            "Loss_G = 4.20910740 (ave = 5.18039664)\n",
            "\n",
            "epoch: [76/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.653s / 10iters, (0.065)\tData load 0.063s / 10iters, (0.006271)\n",
            "Loss_D = 0.27937791 (ave = 0.38004758)\n",
            "Loss_G = 4.96751165 (ave = 5.19008848)\n",
            "\n",
            "epoch: [76/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.592s / 10iters, (0.059)\tData load 0.054s / 10iters, (0.005396)\n",
            "Loss_D = 0.35888797 (ave = 0.37796050)\n",
            "Loss_G = 5.34670162 (ave = 5.20581728)\n",
            "\n",
            "epoch: [76/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.639s / 10iters, (0.064)\tData load 0.076s / 10iters, (0.007623)\n",
            "Loss_D = 0.37659469 (ave = 0.37271013)\n",
            "Loss_G = 5.74873543 (ave = 5.19329788)\n",
            "\n",
            "epoch: [76/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.634s / 10iters, (0.063)\tData load 0.062s / 10iters, (0.006160)\n",
            "Loss_D = 0.07671568 (ave = 0.37151384)\n",
            "Loss_G = 4.67225170 (ave = 5.20532322)\n",
            "\n",
            "epoch: [76/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.323s / 10iters, (0.032)\tData load 0.065s / 10iters, (0.006546)\n",
            "Loss_D = 0.13330634 (ave = 0.36634172)\n",
            "Loss_G = 6.49928856 (ave = 5.17479993)\n",
            "\n",
            "epoch: [76/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.066s / 3iters, (0.022)\tData load 0.015s / 3iters, (0.005125)\n",
            "Loss_D = 0.16349943 (ave = 0.36477469)\n",
            "Loss_G = 4.67445707 (ave = 5.16828839)\n",
            "\n",
            "Real Accuracy : 93.31347236014565\n",
            "Fake Accuracy : 3.0453492221118834\n",
            "epoch: [77/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 4.862s / 10iters, (0.486)\tData load 4.223s / 10iters, (0.422298)\n",
            "Loss_D = 0.15877600 (ave = 0.31192347)\n",
            "Loss_G = 5.07240534 (ave = 5.05791636)\n",
            "\n",
            "epoch: [77/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.716s / 10iters, (0.072)\tData load 0.098s / 10iters, (0.009780)\n",
            "Loss_D = 0.30082667 (ave = 0.36961109)\n",
            "Loss_G = 5.13341331 (ave = 5.09479407)\n",
            "\n",
            "epoch: [77/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.633s / 10iters, (0.063)\tData load 0.061s / 10iters, (0.006141)\n",
            "Loss_D = 0.20437475 (ave = 0.34402217)\n",
            "Loss_G = 5.74990606 (ave = 4.94522792)\n",
            "\n",
            "epoch: [77/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.699s / 10iters, (0.070)\tData load 0.089s / 10iters, (0.008851)\n",
            "Loss_D = 0.44515955 (ave = 0.32505861)\n",
            "Loss_G = 5.44308805 (ave = 5.06746521)\n",
            "\n",
            "epoch: [77/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.637s / 10iters, (0.064)\tData load 0.059s / 10iters, (0.005900)\n",
            "Loss_D = 0.83404982 (ave = 0.33230262)\n",
            "Loss_G = 3.51334167 (ave = 4.96028228)\n",
            "\n",
            "epoch: [77/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.580s / 10iters, (0.058)\tData load 0.082s / 10iters, (0.008165)\n",
            "Loss_D = 0.08093800 (ave = 0.32148070)\n",
            "Loss_G = 4.96268511 (ave = 4.97256567)\n",
            "\n",
            "epoch: [77/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.644s / 10iters, (0.064)\tData load 0.057s / 10iters, (0.005721)\n",
            "Loss_D = 0.20689887 (ave = 0.32263360)\n",
            "Loss_G = 6.83505487 (ave = 4.98857049)\n",
            "\n",
            "epoch: [77/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.650s / 10iters, (0.065)\tData load 0.058s / 10iters, (0.005818)\n",
            "Loss_D = 0.36632347 (ave = 0.31725105)\n",
            "Loss_G = 5.19307470 (ave = 4.93537118)\n",
            "\n",
            "epoch: [77/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.593s / 10iters, (0.059)\tData load 0.053s / 10iters, (0.005303)\n",
            "Loss_D = 0.22164759 (ave = 0.30496429)\n",
            "Loss_G = 5.04448414 (ave = 4.92686396)\n",
            "\n",
            "epoch: [77/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.603s / 10iters, (0.060)\tData load 0.067s / 10iters, (0.006652)\n",
            "Loss_D = 0.18916599 (ave = 0.31016724)\n",
            "Loss_G = 4.35247850 (ave = 4.96029678)\n",
            "\n",
            "epoch: [77/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.576s / 10iters, (0.058)\tData load 0.078s / 10iters, (0.007776)\n",
            "Loss_D = 0.51813149 (ave = 0.31332949)\n",
            "Loss_G = 6.88084316 (ave = 4.99827830)\n",
            "\n",
            "epoch: [77/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.743s / 10iters, (0.074)\tData load 0.093s / 10iters, (0.009347)\n",
            "Loss_D = 0.16366267 (ave = 0.31440610)\n",
            "Loss_G = 4.67985582 (ave = 4.99417650)\n",
            "\n",
            "epoch: [77/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.611s / 10iters, (0.061)\tData load 0.063s / 10iters, (0.006283)\n",
            "Loss_D = 0.53075838 (ave = 0.32178715)\n",
            "Loss_G = 7.15362835 (ave = 5.03993353)\n",
            "\n",
            "epoch: [77/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.613s / 10iters, (0.061)\tData load 0.084s / 10iters, (0.008436)\n",
            "Loss_D = 0.21658216 (ave = 0.31097126)\n",
            "Loss_G = 2.54032516 (ave = 4.98957470)\n",
            "\n",
            "epoch: [77/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.667s / 10iters, (0.067)\tData load 0.064s / 10iters, (0.006415)\n",
            "Loss_D = 0.22870448 (ave = 0.31091161)\n",
            "Loss_G = 4.27638245 (ave = 4.96503796)\n",
            "\n",
            "epoch: [77/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.622s / 10iters, (0.062)\tData load 0.081s / 10iters, (0.008058)\n",
            "Loss_D = 0.28819394 (ave = 0.31336418)\n",
            "Loss_G = 6.04968166 (ave = 5.01563662)\n",
            "\n",
            "epoch: [77/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.569s / 10iters, (0.057)\tData load 0.061s / 10iters, (0.006107)\n",
            "Loss_D = 0.46823570 (ave = 0.30630705)\n",
            "Loss_G = 5.23708296 (ave = 5.02212924)\n",
            "\n",
            "epoch: [77/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.728s / 10iters, (0.073)\tData load 0.102s / 10iters, (0.010159)\n",
            "Loss_D = 0.25937748 (ave = 0.30409328)\n",
            "Loss_G = 4.79842949 (ave = 5.01908715)\n",
            "\n",
            "epoch: [77/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.609s / 10iters, (0.061)\tData load 0.055s / 10iters, (0.005513)\n",
            "Loss_D = 0.18143263 (ave = 0.30739918)\n",
            "Loss_G = 5.28172255 (ave = 5.02238297)\n",
            "\n",
            "epoch: [77/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.626s / 10iters, (0.063)\tData load 0.092s / 10iters, (0.009178)\n",
            "Loss_D = 0.33663726 (ave = 0.31206502)\n",
            "Loss_G = 4.84866667 (ave = 5.02622008)\n",
            "\n",
            "epoch: [77/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.644s / 10iters, (0.064)\tData load 0.082s / 10iters, (0.008215)\n",
            "Loss_D = 0.42172420 (ave = 0.32210334)\n",
            "Loss_G = 5.55540466 (ave = 5.03173874)\n",
            "\n",
            "epoch: [77/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.589s / 10iters, (0.059)\tData load 0.074s / 10iters, (0.007355)\n",
            "Loss_D = 0.21040937 (ave = 0.32714392)\n",
            "Loss_G = 4.67746067 (ave = 5.04593798)\n",
            "\n",
            "epoch: [77/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.345s / 10iters, (0.035)\tData load 0.069s / 10iters, (0.006934)\n",
            "Loss_D = 0.75637400 (ave = 0.33287573)\n",
            "Loss_G = 4.26419640 (ave = 5.03446793)\n",
            "\n",
            "epoch: [77/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.069s / 3iters, (0.023)\tData load 0.017s / 3iters, (0.005813)\n",
            "Loss_D = 0.75605792 (ave = 0.33449932)\n",
            "Loss_G = 5.93015194 (ave = 5.05779337)\n",
            "\n",
            "Real Accuracy : 93.61138695796095\n",
            "Fake Accuracy : 3.0453492221118834\n",
            "epoch: [78/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.045s / 10iters, (0.504)\tData load 4.375s / 10iters, (0.437545)\n",
            "Loss_D = 0.20912375 (ave = 0.32197471)\n",
            "Loss_G = 4.07440901 (ave = 5.27606432)\n",
            "\n",
            "epoch: [78/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.711s / 10iters, (0.071)\tData load 0.084s / 10iters, (0.008446)\n",
            "Loss_D = 0.13777018 (ave = 0.31383219)\n",
            "Loss_G = 4.51159191 (ave = 5.31034014)\n",
            "\n",
            "epoch: [78/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.736s / 10iters, (0.074)\tData load 0.076s / 10iters, (0.007613)\n",
            "Loss_D = 0.52549410 (ave = 0.28739553)\n",
            "Loss_G = 4.34637403 (ave = 5.27336435)\n",
            "\n",
            "epoch: [78/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.642s / 10iters, (0.064)\tData load 0.073s / 10iters, (0.007254)\n",
            "Loss_D = 0.26536876 (ave = 0.27781363)\n",
            "Loss_G = 5.56036615 (ave = 5.15516267)\n",
            "\n",
            "epoch: [78/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.605s / 10iters, (0.061)\tData load 0.058s / 10iters, (0.005767)\n",
            "Loss_D = 0.11248954 (ave = 0.28738809)\n",
            "Loss_G = 4.82386971 (ave = 5.06809979)\n",
            "\n",
            "epoch: [78/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.665s / 10iters, (0.066)\tData load 0.114s / 10iters, (0.011390)\n",
            "Loss_D = 0.43582320 (ave = 0.35838378)\n",
            "Loss_G = 2.50917482 (ave = 5.10620857)\n",
            "\n",
            "epoch: [78/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.634s / 10iters, (0.063)\tData load 0.062s / 10iters, (0.006197)\n",
            "Loss_D = 0.11224762 (ave = 0.34972611)\n",
            "Loss_G = 7.45839977 (ave = 5.14631602)\n",
            "\n",
            "epoch: [78/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.642s / 10iters, (0.064)\tData load 0.065s / 10iters, (0.006482)\n",
            "Loss_D = 0.15734574 (ave = 0.33698040)\n",
            "Loss_G = 6.02558661 (ave = 5.17235014)\n",
            "\n",
            "epoch: [78/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.579s / 10iters, (0.058)\tData load 0.108s / 10iters, (0.010821)\n",
            "Loss_D = 0.10360874 (ave = 0.31980816)\n",
            "Loss_G = 5.65172863 (ave = 5.12868902)\n",
            "\n",
            "epoch: [78/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.626s / 10iters, (0.063)\tData load 0.067s / 10iters, (0.006727)\n",
            "Loss_D = 0.56810260 (ave = 0.32549600)\n",
            "Loss_G = 5.49431801 (ave = 5.22784321)\n",
            "\n",
            "epoch: [78/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.569s / 10iters, (0.057)\tData load 0.082s / 10iters, (0.008186)\n",
            "Loss_D = 0.14558987 (ave = 0.32602312)\n",
            "Loss_G = 4.64639997 (ave = 5.22775734)\n",
            "\n",
            "epoch: [78/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.649s / 10iters, (0.065)\tData load 0.079s / 10iters, (0.007858)\n",
            "Loss_D = 0.63260174 (ave = 0.32643266)\n",
            "Loss_G = 3.69007540 (ave = 5.23138756)\n",
            "\n",
            "epoch: [78/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.734s / 10iters, (0.073)\tData load 0.119s / 10iters, (0.011918)\n",
            "Loss_D = 0.56782913 (ave = 0.32632100)\n",
            "Loss_G = 5.08375978 (ave = 5.22751078)\n",
            "\n",
            "epoch: [78/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.617s / 10iters, (0.062)\tData load 0.099s / 10iters, (0.009920)\n",
            "Loss_D = 0.39272547 (ave = 0.32753455)\n",
            "Loss_G = 6.09862089 (ave = 5.22074696)\n",
            "\n",
            "epoch: [78/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.688s / 10iters, (0.069)\tData load 0.081s / 10iters, (0.008111)\n",
            "Loss_D = 0.27148205 (ave = 0.33196900)\n",
            "Loss_G = 4.25041389 (ave = 5.20902438)\n",
            "\n",
            "epoch: [78/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.588s / 10iters, (0.059)\tData load 0.067s / 10iters, (0.006684)\n",
            "Loss_D = 0.17428291 (ave = 0.32645708)\n",
            "Loss_G = 5.49029493 (ave = 5.21209976)\n",
            "\n",
            "epoch: [78/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.692s / 10iters, (0.069)\tData load 0.054s / 10iters, (0.005356)\n",
            "Loss_D = 0.15230311 (ave = 0.32282011)\n",
            "Loss_G = 6.13364744 (ave = 5.19082468)\n",
            "\n",
            "epoch: [78/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.598s / 10iters, (0.060)\tData load 0.104s / 10iters, (0.010428)\n",
            "Loss_D = 0.62494826 (ave = 0.33257101)\n",
            "Loss_G = 5.11219788 (ave = 5.21876800)\n",
            "\n",
            "epoch: [78/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.635s / 10iters, (0.064)\tData load 0.097s / 10iters, (0.009723)\n",
            "Loss_D = 0.23569974 (ave = 0.32849610)\n",
            "Loss_G = 4.78701735 (ave = 5.19800810)\n",
            "\n",
            "epoch: [78/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.625s / 10iters, (0.062)\tData load 0.087s / 10iters, (0.008692)\n",
            "Loss_D = 0.18430004 (ave = 0.33073049)\n",
            "Loss_G = 3.78199768 (ave = 5.18996624)\n",
            "\n",
            "epoch: [78/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.673s / 10iters, (0.067)\tData load 0.066s / 10iters, (0.006568)\n",
            "Loss_D = 0.26864845 (ave = 0.34034280)\n",
            "Loss_G = 6.63826418 (ave = 5.22677746)\n",
            "\n",
            "epoch: [78/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.661s / 10iters, (0.066)\tData load 0.058s / 10iters, (0.005820)\n",
            "Loss_D = 0.55924559 (ave = 0.34354484)\n",
            "Loss_G = 4.92072248 (ave = 5.23228737)\n",
            "\n",
            "epoch: [78/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.333s / 10iters, (0.033)\tData load 0.070s / 10iters, (0.006955)\n",
            "Loss_D = 0.65431380 (ave = 0.34738128)\n",
            "Loss_G = 7.15214252 (ave = 5.22782958)\n",
            "\n",
            "epoch: [78/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.068s / 3iters, (0.023)\tData load 0.017s / 3iters, (0.005588)\n",
            "Loss_D = 0.23746398 (ave = 0.34702531)\n",
            "Loss_G = 4.93212986 (ave = 5.23116326)\n",
            "\n",
            "Real Accuracy : 93.04865938430983\n",
            "Fake Accuracy : 3.4094670638861304\n",
            "epoch: [79/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.113s / 10iters, (0.511)\tData load 4.368s / 10iters, (0.436849)\n",
            "Loss_D = 0.20001955 (ave = 0.51980021)\n",
            "Loss_G = 5.39291716 (ave = 5.66576252)\n",
            "\n",
            "epoch: [79/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.685s / 10iters, (0.068)\tData load 0.111s / 10iters, (0.011067)\n",
            "Loss_D = 0.12000094 (ave = 0.49330330)\n",
            "Loss_G = 4.01422501 (ave = 5.68426635)\n",
            "\n",
            "epoch: [79/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.586s / 10iters, (0.059)\tData load 0.094s / 10iters, (0.009412)\n",
            "Loss_D = 0.86567801 (ave = 0.45985579)\n",
            "Loss_G = 6.92246437 (ave = 5.40183053)\n",
            "\n",
            "epoch: [79/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.637s / 10iters, (0.064)\tData load 0.080s / 10iters, (0.007985)\n",
            "Loss_D = 0.04249691 (ave = 0.42519862)\n",
            "Loss_G = 3.73425531 (ave = 5.36219127)\n",
            "\n",
            "epoch: [79/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.640s / 10iters, (0.064)\tData load 0.069s / 10iters, (0.006870)\n",
            "Loss_D = 0.33773643 (ave = 0.41639362)\n",
            "Loss_G = 5.03378296 (ave = 5.37294102)\n",
            "\n",
            "epoch: [79/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.632s / 10iters, (0.063)\tData load 0.104s / 10iters, (0.010415)\n",
            "Loss_D = 0.09805719 (ave = 0.42603415)\n",
            "Loss_G = 5.92128420 (ave = 5.35211396)\n",
            "\n",
            "epoch: [79/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.630s / 10iters, (0.063)\tData load 0.091s / 10iters, (0.009142)\n",
            "Loss_D = 0.40195405 (ave = 0.42289515)\n",
            "Loss_G = 5.11678505 (ave = 5.31643392)\n",
            "\n",
            "epoch: [79/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.625s / 10iters, (0.062)\tData load 0.081s / 10iters, (0.008069)\n",
            "Loss_D = 0.07658629 (ave = 0.40387208)\n",
            "Loss_G = 5.31193018 (ave = 5.33874703)\n",
            "\n",
            "epoch: [79/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.579s / 10iters, (0.058)\tData load 0.081s / 10iters, (0.008140)\n",
            "Loss_D = 0.15223514 (ave = 0.40253572)\n",
            "Loss_G = 4.26243162 (ave = 5.27600526)\n",
            "\n",
            "epoch: [79/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.709s / 10iters, (0.071)\tData load 0.080s / 10iters, (0.008001)\n",
            "Loss_D = 0.29021198 (ave = 0.39932133)\n",
            "Loss_G = 7.58539534 (ave = 5.23127156)\n",
            "\n",
            "epoch: [79/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.605s / 10iters, (0.061)\tData load 0.108s / 10iters, (0.010808)\n",
            "Loss_D = 0.35840026 (ave = 0.40801203)\n",
            "Loss_G = 4.18051577 (ave = 5.21037526)\n",
            "\n",
            "epoch: [79/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.711s / 10iters, (0.071)\tData load 0.112s / 10iters, (0.011237)\n",
            "Loss_D = 0.65411043 (ave = 0.40244738)\n",
            "Loss_G = 7.38382483 (ave = 5.22360886)\n",
            "\n",
            "epoch: [79/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.593s / 10iters, (0.059)\tData load 0.069s / 10iters, (0.006883)\n",
            "Loss_D = 0.57288164 (ave = 0.39931112)\n",
            "Loss_G = 4.56773853 (ave = 5.26837047)\n",
            "\n",
            "epoch: [79/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.635s / 10iters, (0.064)\tData load 0.086s / 10iters, (0.008639)\n",
            "Loss_D = 0.18464696 (ave = 0.38800367)\n",
            "Loss_G = 4.96116400 (ave = 5.27638343)\n",
            "\n",
            "epoch: [79/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.572s / 10iters, (0.057)\tData load 0.062s / 10iters, (0.006201)\n",
            "Loss_D = 0.08123988 (ave = 0.38252789)\n",
            "Loss_G = 4.01430035 (ave = 5.27126805)\n",
            "\n",
            "epoch: [79/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.644s / 10iters, (0.064)\tData load 0.081s / 10iters, (0.008061)\n",
            "Loss_D = 0.23013099 (ave = 0.38505702)\n",
            "Loss_G = 2.80648828 (ave = 5.25829748)\n",
            "\n",
            "epoch: [79/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.651s / 10iters, (0.065)\tData load 0.085s / 10iters, (0.008484)\n",
            "Loss_D = 0.11403787 (ave = 0.38117281)\n",
            "Loss_G = 4.67954493 (ave = 5.24790995)\n",
            "\n",
            "epoch: [79/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.639s / 10iters, (0.064)\tData load 0.088s / 10iters, (0.008800)\n",
            "Loss_D = 0.54114288 (ave = 0.37212376)\n",
            "Loss_G = 5.65606260 (ave = 5.19766772)\n",
            "\n",
            "epoch: [79/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.618s / 10iters, (0.062)\tData load 0.085s / 10iters, (0.008529)\n",
            "Loss_D = 0.56865418 (ave = 0.37040830)\n",
            "Loss_G = 2.48898721 (ave = 5.20460112)\n",
            "\n",
            "epoch: [79/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.616s / 10iters, (0.062)\tData load 0.091s / 10iters, (0.009145)\n",
            "Loss_D = 0.47200078 (ave = 0.36899732)\n",
            "Loss_G = 4.93467140 (ave = 5.17820549)\n",
            "\n",
            "epoch: [79/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.555s / 10iters, (0.055)\tData load 0.085s / 10iters, (0.008481)\n",
            "Loss_D = 0.43656158 (ave = 0.36283557)\n",
            "Loss_G = 6.15956640 (ave = 5.17923668)\n",
            "\n",
            "epoch: [79/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.690s / 10iters, (0.069)\tData load 0.090s / 10iters, (0.008995)\n",
            "Loss_D = 0.17133459 (ave = 0.36811141)\n",
            "Loss_G = 5.82384682 (ave = 5.18960494)\n",
            "\n",
            "epoch: [79/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.334s / 10iters, (0.033)\tData load 0.063s / 10iters, (0.006271)\n",
            "Loss_D = 0.22436576 (ave = 0.36217643)\n",
            "Loss_G = 3.28706145 (ave = 5.15660628)\n",
            "\n",
            "epoch: [79/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.068s / 3iters, (0.023)\tData load 0.017s / 3iters, (0.005661)\n",
            "Loss_D = 0.80982423 (ave = 0.36423188)\n",
            "Loss_G = 12.33019829 (ave = 5.18632004)\n",
            "\n",
            "Real Accuracy : 92.9493545183714\n",
            "Fake Accuracy : 2.6812313803376364\n",
            "epoch: [80/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.062s / 10iters, (0.506)\tData load 4.387s / 10iters, (0.438650)\n",
            "Loss_D = 0.79743248 (ave = 0.58217372)\n",
            "Loss_G = 5.71849823 (ave = 5.84339354)\n",
            "\n",
            "epoch: [80/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.629s / 10iters, (0.063)\tData load 0.085s / 10iters, (0.008493)\n",
            "Loss_D = 0.05675126 (ave = 0.48651651)\n",
            "Loss_G = 6.52294874 (ave = 5.67273254)\n",
            "\n",
            "epoch: [80/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.619s / 10iters, (0.062)\tData load 0.055s / 10iters, (0.005494)\n",
            "Loss_D = 0.44364405 (ave = 0.44613827)\n",
            "Loss_G = 5.78758335 (ave = 5.52362265)\n",
            "\n",
            "epoch: [80/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.673s / 10iters, (0.067)\tData load 0.128s / 10iters, (0.012751)\n",
            "Loss_D = 0.24977118 (ave = 0.39406000)\n",
            "Loss_G = 5.25612831 (ave = 5.51038883)\n",
            "\n",
            "epoch: [80/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.679s / 10iters, (0.068)\tData load 0.064s / 10iters, (0.006425)\n",
            "Loss_D = 0.22761077 (ave = 0.37543789)\n",
            "Loss_G = 4.98217678 (ave = 5.42841331)\n",
            "\n",
            "epoch: [80/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.620s / 10iters, (0.062)\tData load 0.070s / 10iters, (0.007039)\n",
            "Loss_D = 0.15386201 (ave = 0.38247188)\n",
            "Loss_G = 6.94685364 (ave = 5.43319597)\n",
            "\n",
            "epoch: [80/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.642s / 10iters, (0.064)\tData load 0.088s / 10iters, (0.008798)\n",
            "Loss_D = 0.24687269 (ave = 0.42825714)\n",
            "Loss_G = 5.18494081 (ave = 5.44590183)\n",
            "\n",
            "epoch: [80/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.646s / 10iters, (0.065)\tData load 0.068s / 10iters, (0.006789)\n",
            "Loss_D = 0.06204192 (ave = 0.42312191)\n",
            "Loss_G = 4.90539503 (ave = 5.37589682)\n",
            "\n",
            "epoch: [80/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.619s / 10iters, (0.062)\tData load 0.058s / 10iters, (0.005826)\n",
            "Loss_D = 0.62144917 (ave = 0.41810580)\n",
            "Loss_G = 6.45633507 (ave = 5.41294516)\n",
            "\n",
            "epoch: [80/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.605s / 10iters, (0.060)\tData load 0.072s / 10iters, (0.007226)\n",
            "Loss_D = 0.67281389 (ave = 0.42787087)\n",
            "Loss_G = 3.36839581 (ave = 5.36636928)\n",
            "\n",
            "epoch: [80/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.622s / 10iters, (0.062)\tData load 0.105s / 10iters, (0.010498)\n",
            "Loss_D = 0.14986971 (ave = 0.43329436)\n",
            "Loss_G = 4.25719500 (ave = 5.38415868)\n",
            "\n",
            "epoch: [80/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.453s / 10iters, (0.045)\tData load 0.047s / 10iters, (0.004661)\n",
            "Loss_D = 0.62411350 (ave = 0.43763737)\n",
            "Loss_G = 4.31342649 (ave = 5.39168381)\n",
            "\n",
            "epoch: [80/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.642s / 10iters, (0.064)\tData load 0.074s / 10iters, (0.007449)\n",
            "Loss_D = 0.61680967 (ave = 0.44756218)\n",
            "Loss_G = 6.42050362 (ave = 5.38900944)\n",
            "\n",
            "epoch: [80/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.805s / 10iters, (0.080)\tData load 0.098s / 10iters, (0.009750)\n",
            "Loss_D = 0.77705824 (ave = 0.44513886)\n",
            "Loss_G = 3.60188937 (ave = 5.36776720)\n",
            "\n",
            "epoch: [80/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.644s / 10iters, (0.064)\tData load 0.083s / 10iters, (0.008313)\n",
            "Loss_D = 0.15505657 (ave = 0.43363347)\n",
            "Loss_G = 5.95349836 (ave = 5.34869316)\n",
            "\n",
            "epoch: [80/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.613s / 10iters, (0.061)\tData load 0.075s / 10iters, (0.007477)\n",
            "Loss_D = 0.14485802 (ave = 0.42494722)\n",
            "Loss_G = 4.38160658 (ave = 5.29227899)\n",
            "\n",
            "epoch: [80/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.588s / 10iters, (0.059)\tData load 0.059s / 10iters, (0.005894)\n",
            "Loss_D = 0.97705364 (ave = 0.43775263)\n",
            "Loss_G = 5.08738279 (ave = 5.31037789)\n",
            "\n",
            "epoch: [80/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.670s / 10iters, (0.067)\tData load 0.085s / 10iters, (0.008509)\n",
            "Loss_D = 0.25630805 (ave = 0.43615566)\n",
            "Loss_G = 4.45734787 (ave = 5.27742220)\n",
            "\n",
            "epoch: [80/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.627s / 10iters, (0.063)\tData load 0.102s / 10iters, (0.010155)\n",
            "Loss_D = 0.16234170 (ave = 0.43392869)\n",
            "Loss_G = 4.38541222 (ave = 5.28314314)\n",
            "\n",
            "epoch: [80/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.647s / 10iters, (0.065)\tData load 0.080s / 10iters, (0.008013)\n",
            "Loss_D = 0.28339958 (ave = 0.43074555)\n",
            "Loss_G = 5.38394880 (ave = 5.27885716)\n",
            "\n",
            "epoch: [80/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.611s / 10iters, (0.061)\tData load 0.075s / 10iters, (0.007506)\n",
            "Loss_D = 0.38223967 (ave = 0.42416562)\n",
            "Loss_G = 4.50620604 (ave = 5.27177617)\n",
            "\n",
            "epoch: [80/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.616s / 10iters, (0.062)\tData load 0.100s / 10iters, (0.009961)\n",
            "Loss_D = 0.39737019 (ave = 0.42040830)\n",
            "Loss_G = 3.54760695 (ave = 5.27589238)\n",
            "\n",
            "epoch: [80/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.318s / 10iters, (0.032)\tData load 0.070s / 10iters, (0.006955)\n",
            "Loss_D = 0.50598025 (ave = 0.42454887)\n",
            "Loss_G = 5.36852980 (ave = 5.27675326)\n",
            "\n",
            "epoch: [80/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.067s / 3iters, (0.022)\tData load 0.014s / 3iters, (0.004767)\n",
            "Loss_D = 0.08879195 (ave = 0.42166545)\n",
            "Loss_G = 7.90796757 (ave = 5.28071922)\n",
            "\n",
            "Real Accuracy : 91.12876530950017\n",
            "Fake Accuracy : 3.1777557100297913\n",
            "epoch: [81/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.027s / 10iters, (0.503)\tData load 4.323s / 10iters, (0.432347)\n",
            "Loss_D = 0.29090551 (ave = 0.46720038)\n",
            "Loss_G = 5.30459833 (ave = 5.32336836)\n",
            "\n",
            "epoch: [81/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.622s / 10iters, (0.062)\tData load 0.096s / 10iters, (0.009587)\n",
            "Loss_D = 0.24335974 (ave = 0.36791703)\n",
            "Loss_G = 3.90695786 (ave = 5.19398572)\n",
            "\n",
            "epoch: [81/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.599s / 10iters, (0.060)\tData load 0.085s / 10iters, (0.008513)\n",
            "Loss_D = 0.25046366 (ave = 0.33856497)\n",
            "Loss_G = 6.19425297 (ave = 5.23046536)\n",
            "\n",
            "epoch: [81/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.610s / 10iters, (0.061)\tData load 0.089s / 10iters, (0.008926)\n",
            "Loss_D = 0.17910720 (ave = 0.35462466)\n",
            "Loss_G = 3.47341442 (ave = 5.24840506)\n",
            "\n",
            "epoch: [81/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.663s / 10iters, (0.066)\tData load 0.095s / 10iters, (0.009504)\n",
            "Loss_D = 0.57627481 (ave = 0.34993658)\n",
            "Loss_G = 6.37619877 (ave = 5.24471993)\n",
            "\n",
            "epoch: [81/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.656s / 10iters, (0.066)\tData load 0.086s / 10iters, (0.008623)\n",
            "Loss_D = 0.22566485 (ave = 0.33952372)\n",
            "Loss_G = 4.79235601 (ave = 5.25092942)\n",
            "\n",
            "epoch: [81/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.585s / 10iters, (0.058)\tData load 0.082s / 10iters, (0.008195)\n",
            "Loss_D = 1.13167703 (ave = 0.37555877)\n",
            "Loss_G = 6.48641968 (ave = 5.29711912)\n",
            "\n",
            "epoch: [81/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.607s / 10iters, (0.061)\tData load 0.104s / 10iters, (0.010380)\n",
            "Loss_D = 0.11733094 (ave = 0.36386992)\n",
            "Loss_G = 5.90761089 (ave = 5.29597302)\n",
            "\n",
            "epoch: [81/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.586s / 10iters, (0.059)\tData load 0.068s / 10iters, (0.006789)\n",
            "Loss_D = 0.92646003 (ave = 0.38658813)\n",
            "Loss_G = 5.71677160 (ave = 5.27615835)\n",
            "\n",
            "epoch: [81/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.631s / 10iters, (0.063)\tData load 0.097s / 10iters, (0.009659)\n",
            "Loss_D = 0.53823197 (ave = 0.38410179)\n",
            "Loss_G = 2.71964216 (ave = 5.29120684)\n",
            "\n",
            "epoch: [81/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.512s / 10iters, (0.051)\tData load 0.064s / 10iters, (0.006364)\n",
            "Loss_D = 0.09031871 (ave = 0.37273967)\n",
            "Loss_G = 5.84314966 (ave = 5.31105525)\n",
            "\n",
            "epoch: [81/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.728s / 10iters, (0.073)\tData load 0.099s / 10iters, (0.009861)\n",
            "Loss_D = 0.16212502 (ave = 0.36807136)\n",
            "Loss_G = 3.92642593 (ave = 5.27500713)\n",
            "\n",
            "epoch: [81/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.553s / 10iters, (0.055)\tData load 0.065s / 10iters, (0.006466)\n",
            "Loss_D = 0.63188457 (ave = 0.36053643)\n",
            "Loss_G = 4.58084011 (ave = 5.22961677)\n",
            "\n",
            "epoch: [81/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.626s / 10iters, (0.063)\tData load 0.070s / 10iters, (0.007034)\n",
            "Loss_D = 0.83481097 (ave = 0.36881200)\n",
            "Loss_G = 5.02306795 (ave = 5.20498809)\n",
            "\n",
            "epoch: [81/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.544s / 10iters, (0.054)\tData load 0.077s / 10iters, (0.007675)\n",
            "Loss_D = 0.72553319 (ave = 0.36684771)\n",
            "Loss_G = 2.20627642 (ave = 5.20006433)\n",
            "\n",
            "epoch: [81/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.652s / 10iters, (0.065)\tData load 0.097s / 10iters, (0.009677)\n",
            "Loss_D = 0.11963061 (ave = 0.35690748)\n",
            "Loss_G = 4.00624657 (ave = 5.17614447)\n",
            "\n",
            "epoch: [81/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.573s / 10iters, (0.057)\tData load 0.082s / 10iters, (0.008234)\n",
            "Loss_D = 0.29797024 (ave = 0.35876614)\n",
            "Loss_G = 6.32261658 (ave = 5.18407783)\n",
            "\n",
            "epoch: [81/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.626s / 10iters, (0.063)\tData load 0.082s / 10iters, (0.008194)\n",
            "Loss_D = 0.24038859 (ave = 0.35568595)\n",
            "Loss_G = 4.52358055 (ave = 5.16392052)\n",
            "\n",
            "epoch: [81/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.563s / 10iters, (0.056)\tData load 0.074s / 10iters, (0.007370)\n",
            "Loss_D = 0.15537837 (ave = 0.35176607)\n",
            "Loss_G = 3.99917388 (ave = 5.15497709)\n",
            "\n",
            "epoch: [81/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.634s / 10iters, (0.063)\tData load 0.095s / 10iters, (0.009456)\n",
            "Loss_D = 0.16766189 (ave = 0.34975651)\n",
            "Loss_G = 6.14280033 (ave = 5.16182017)\n",
            "\n",
            "epoch: [81/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.589s / 10iters, (0.059)\tData load 0.103s / 10iters, (0.010289)\n",
            "Loss_D = 0.05940983 (ave = 0.35400622)\n",
            "Loss_G = 6.48879433 (ave = 5.18493526)\n",
            "\n",
            "epoch: [81/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.614s / 10iters, (0.061)\tData load 0.077s / 10iters, (0.007656)\n",
            "Loss_D = 0.39680883 (ave = 0.34870197)\n",
            "Loss_G = 3.68823576 (ave = 5.20328485)\n",
            "\n",
            "epoch: [81/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.337s / 10iters, (0.034)\tData load 0.069s / 10iters, (0.006915)\n",
            "Loss_D = 0.78670454 (ave = 0.35729575)\n",
            "Loss_G = 7.14529848 (ave = 5.20246872)\n",
            "\n",
            "epoch: [81/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.069s / 3iters, (0.023)\tData load 0.016s / 3iters, (0.005223)\n",
            "Loss_D = 0.04996353 (ave = 0.35519076)\n",
            "Loss_G = 6.22028971 (ave = 5.21026984)\n",
            "\n",
            "Real Accuracy : 92.88315127441244\n",
            "Fake Accuracy : 2.8798411122144985\n",
            "epoch: [82/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 4.901s / 10iters, (0.490)\tData load 4.229s / 10iters, (0.422932)\n",
            "Loss_D = 0.70967710 (ave = 0.40061319)\n",
            "Loss_G = 7.35351467 (ave = 5.78758774)\n",
            "\n",
            "epoch: [82/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.693s / 10iters, (0.069)\tData load 0.126s / 10iters, (0.012564)\n",
            "Loss_D = 0.66991067 (ave = 0.38606941)\n",
            "Loss_G = 4.35572910 (ave = 5.59280638)\n",
            "\n",
            "epoch: [82/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.630s / 10iters, (0.063)\tData load 0.069s / 10iters, (0.006857)\n",
            "Loss_D = 0.11764874 (ave = 0.33735723)\n",
            "Loss_G = 5.09005785 (ave = 5.56008186)\n",
            "\n",
            "epoch: [82/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.626s / 10iters, (0.063)\tData load 0.104s / 10iters, (0.010400)\n",
            "Loss_D = 0.22202547 (ave = 0.31904537)\n",
            "Loss_G = 5.73307896 (ave = 5.45950276)\n",
            "\n",
            "epoch: [82/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.662s / 10iters, (0.066)\tData load 0.071s / 10iters, (0.007097)\n",
            "Loss_D = 0.26296544 (ave = 0.29815407)\n",
            "Loss_G = 5.09379005 (ave = 5.36872783)\n",
            "\n",
            "epoch: [82/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.610s / 10iters, (0.061)\tData load 0.092s / 10iters, (0.009199)\n",
            "Loss_D = 0.07133009 (ave = 0.29272901)\n",
            "Loss_G = 6.43773746 (ave = 5.29010571)\n",
            "\n",
            "epoch: [82/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.578s / 10iters, (0.058)\tData load 0.098s / 10iters, (0.009754)\n",
            "Loss_D = 0.93725753 (ave = 0.33370304)\n",
            "Loss_G = 5.48011589 (ave = 5.41602146)\n",
            "\n",
            "epoch: [82/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.578s / 10iters, (0.058)\tData load 0.081s / 10iters, (0.008074)\n",
            "Loss_D = 1.21505499 (ave = 0.35907339)\n",
            "Loss_G = 6.35165501 (ave = 5.41370253)\n",
            "\n",
            "epoch: [82/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.611s / 10iters, (0.061)\tData load 0.073s / 10iters, (0.007271)\n",
            "Loss_D = 0.19388528 (ave = 0.33708820)\n",
            "Loss_G = 3.75074148 (ave = 5.31845109)\n",
            "\n",
            "epoch: [82/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.570s / 10iters, (0.057)\tData load 0.076s / 10iters, (0.007649)\n",
            "Loss_D = 0.09334642 (ave = 0.32394103)\n",
            "Loss_G = 5.60913086 (ave = 5.34158537)\n",
            "\n",
            "epoch: [82/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.656s / 10iters, (0.066)\tData load 0.111s / 10iters, (0.011088)\n",
            "Loss_D = 0.19533071 (ave = 0.31807755)\n",
            "Loss_G = 3.59143019 (ave = 5.31610406)\n",
            "\n",
            "epoch: [82/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.618s / 10iters, (0.062)\tData load 0.070s / 10iters, (0.006971)\n",
            "Loss_D = 0.16417161 (ave = 0.32362376)\n",
            "Loss_G = 5.51614952 (ave = 5.31834395)\n",
            "\n",
            "epoch: [82/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.658s / 10iters, (0.066)\tData load 0.101s / 10iters, (0.010082)\n",
            "Loss_D = 0.40964991 (ave = 0.32197703)\n",
            "Loss_G = 5.27613735 (ave = 5.33281450)\n",
            "\n",
            "epoch: [82/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.458s / 10iters, (0.046)\tData load 0.069s / 10iters, (0.006884)\n",
            "Loss_D = 0.38612673 (ave = 0.32527720)\n",
            "Loss_G = 5.39703035 (ave = 5.32098360)\n",
            "\n",
            "epoch: [82/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.741s / 10iters, (0.074)\tData load 0.097s / 10iters, (0.009716)\n",
            "Loss_D = 0.16741771 (ave = 0.31830778)\n",
            "Loss_G = 6.79893446 (ave = 5.29645918)\n",
            "\n",
            "epoch: [82/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.608s / 10iters, (0.061)\tData load 0.083s / 10iters, (0.008272)\n",
            "Loss_D = 0.17561866 (ave = 0.31173350)\n",
            "Loss_G = 3.78976727 (ave = 5.25039880)\n",
            "\n",
            "epoch: [82/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.572s / 10iters, (0.057)\tData load 0.085s / 10iters, (0.008529)\n",
            "Loss_D = 0.30592963 (ave = 0.31242271)\n",
            "Loss_G = 6.23959827 (ave = 5.26343632)\n",
            "\n",
            "epoch: [82/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.654s / 10iters, (0.065)\tData load 0.058s / 10iters, (0.005797)\n",
            "Loss_D = 0.14785135 (ave = 0.31276141)\n",
            "Loss_G = 7.21860695 (ave = 5.26342981)\n",
            "\n",
            "epoch: [82/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.577s / 10iters, (0.058)\tData load 0.063s / 10iters, (0.006259)\n",
            "Loss_D = 0.17710559 (ave = 0.31493314)\n",
            "Loss_G = 6.66007423 (ave = 5.25066214)\n",
            "\n",
            "epoch: [82/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.644s / 10iters, (0.064)\tData load 0.074s / 10iters, (0.007374)\n",
            "Loss_D = 0.85520095 (ave = 0.32491513)\n",
            "Loss_G = 5.87772131 (ave = 5.23955970)\n",
            "\n",
            "epoch: [82/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.621s / 10iters, (0.062)\tData load 0.080s / 10iters, (0.008043)\n",
            "Loss_D = 0.15883672 (ave = 0.33048710)\n",
            "Loss_G = 6.24295712 (ave = 5.24960643)\n",
            "\n",
            "epoch: [82/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.669s / 10iters, (0.067)\tData load 0.059s / 10iters, (0.005904)\n",
            "Loss_D = 0.21362174 (ave = 0.32793287)\n",
            "Loss_G = 4.54139853 (ave = 5.24835594)\n",
            "\n",
            "epoch: [82/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.303s / 10iters, (0.030)\tData load 0.055s / 10iters, (0.005507)\n",
            "Loss_D = 0.85927820 (ave = 0.33001714)\n",
            "Loss_G = 5.79698706 (ave = 5.24099520)\n",
            "\n",
            "epoch: [82/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.067s / 3iters, (0.022)\tData load 0.016s / 3iters, (0.005432)\n",
            "Loss_D = 0.15786789 (ave = 0.32731519)\n",
            "Loss_G = 6.38824034 (ave = 5.25527634)\n",
            "\n",
            "Real Accuracy : 93.71069182389937\n",
            "Fake Accuracy : 2.8798411122144985\n",
            "epoch: [83/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.144s / 10iters, (0.514)\tData load 4.486s / 10iters, (0.448581)\n",
            "Loss_D = 0.10926427 (ave = 0.31508727)\n",
            "Loss_G = 6.04320717 (ave = 5.21298966)\n",
            "\n",
            "epoch: [83/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.707s / 10iters, (0.071)\tData load 0.114s / 10iters, (0.011446)\n",
            "Loss_D = 0.22599597 (ave = 0.26805033)\n",
            "Loss_G = 5.09205866 (ave = 5.38027692)\n",
            "\n",
            "epoch: [83/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.614s / 10iters, (0.061)\tData load 0.090s / 10iters, (0.009034)\n",
            "Loss_D = 0.18646336 (ave = 0.23717916)\n",
            "Loss_G = 3.45183682 (ave = 5.25830057)\n",
            "\n",
            "epoch: [83/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.616s / 10iters, (0.062)\tData load 0.093s / 10iters, (0.009323)\n",
            "Loss_D = 0.15457663 (ave = 0.23133243)\n",
            "Loss_G = 6.43479824 (ave = 5.21929716)\n",
            "\n",
            "epoch: [83/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.650s / 10iters, (0.065)\tData load 0.106s / 10iters, (0.010578)\n",
            "Loss_D = 0.24101429 (ave = 0.27092560)\n",
            "Loss_G = 6.19794703 (ave = 5.24053010)\n",
            "\n",
            "epoch: [83/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.637s / 10iters, (0.064)\tData load 0.071s / 10iters, (0.007097)\n",
            "Loss_D = 0.16940311 (ave = 0.28239111)\n",
            "Loss_G = 6.21641254 (ave = 5.33916245)\n",
            "\n",
            "epoch: [83/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.614s / 10iters, (0.061)\tData load 0.064s / 10iters, (0.006359)\n",
            "Loss_D = 0.43854642 (ave = 0.29769964)\n",
            "Loss_G = 6.01099348 (ave = 5.37338749)\n",
            "\n",
            "epoch: [83/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.618s / 10iters, (0.062)\tData load 0.075s / 10iters, (0.007528)\n",
            "Loss_D = 0.05191831 (ave = 0.30084610)\n",
            "Loss_G = 4.38074112 (ave = 5.30657525)\n",
            "\n",
            "epoch: [83/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.659s / 10iters, (0.066)\tData load 0.084s / 10iters, (0.008396)\n",
            "Loss_D = 0.66816813 (ave = 0.32090367)\n",
            "Loss_G = 3.85861588 (ave = 5.34114703)\n",
            "\n",
            "epoch: [83/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.554s / 10iters, (0.055)\tData load 0.069s / 10iters, (0.006931)\n",
            "Loss_D = 0.39129919 (ave = 0.32145215)\n",
            "Loss_G = 7.98068810 (ave = 5.41006108)\n",
            "\n",
            "epoch: [83/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.673s / 10iters, (0.067)\tData load 0.081s / 10iters, (0.008093)\n",
            "Loss_D = 0.26760030 (ave = 0.31676333)\n",
            "Loss_G = 3.94089913 (ave = 5.37434950)\n",
            "\n",
            "epoch: [83/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.710s / 10iters, (0.071)\tData load 0.079s / 10iters, (0.007895)\n",
            "Loss_D = 0.06330170 (ave = 0.31508805)\n",
            "Loss_G = 4.26523542 (ave = 5.34583484)\n",
            "\n",
            "epoch: [83/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.594s / 10iters, (0.059)\tData load 0.078s / 10iters, (0.007808)\n",
            "Loss_D = 0.32625496 (ave = 0.30742420)\n",
            "Loss_G = 3.95482922 (ave = 5.30780486)\n",
            "\n",
            "epoch: [83/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.631s / 10iters, (0.063)\tData load 0.064s / 10iters, (0.006405)\n",
            "Loss_D = 0.26061085 (ave = 0.32448626)\n",
            "Loss_G = 4.78614330 (ave = 5.32878667)\n",
            "\n",
            "epoch: [83/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.665s / 10iters, (0.066)\tData load 0.107s / 10iters, (0.010713)\n",
            "Loss_D = 0.29974145 (ave = 0.32141346)\n",
            "Loss_G = 5.33245039 (ave = 5.33095236)\n",
            "\n",
            "epoch: [83/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.592s / 10iters, (0.059)\tData load 0.080s / 10iters, (0.007997)\n",
            "Loss_D = 0.41995996 (ave = 0.32883478)\n",
            "Loss_G = 7.35334826 (ave = 5.37809018)\n",
            "\n",
            "epoch: [83/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.618s / 10iters, (0.062)\tData load 0.104s / 10iters, (0.010352)\n",
            "Loss_D = 0.61108023 (ave = 0.32706163)\n",
            "Loss_G = 3.61475968 (ave = 5.37918500)\n",
            "\n",
            "epoch: [83/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.590s / 10iters, (0.059)\tData load 0.082s / 10iters, (0.008167)\n",
            "Loss_D = 0.24640025 (ave = 0.32594813)\n",
            "Loss_G = 6.24289656 (ave = 5.38033320)\n",
            "\n",
            "epoch: [83/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.624s / 10iters, (0.062)\tData load 0.096s / 10iters, (0.009586)\n",
            "Loss_D = 0.14189628 (ave = 0.33874360)\n",
            "Loss_G = 5.85002375 (ave = 5.40552784)\n",
            "\n",
            "epoch: [83/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.581s / 10iters, (0.058)\tData load 0.081s / 10iters, (0.008085)\n",
            "Loss_D = 0.48629957 (ave = 0.34141828)\n",
            "Loss_G = 3.82399750 (ave = 5.39702309)\n",
            "\n",
            "epoch: [83/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.613s / 10iters, (0.061)\tData load 0.063s / 10iters, (0.006304)\n",
            "Loss_D = 0.25121951 (ave = 0.34693487)\n",
            "Loss_G = 6.54592228 (ave = 5.42914764)\n",
            "\n",
            "epoch: [83/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.578s / 10iters, (0.058)\tData load 0.075s / 10iters, (0.007455)\n",
            "Loss_D = 0.51612800 (ave = 0.34960178)\n",
            "Loss_G = 4.17228794 (ave = 5.39224272)\n",
            "\n",
            "epoch: [83/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.303s / 10iters, (0.030)\tData load 0.047s / 10iters, (0.004707)\n",
            "Loss_D = 0.53083771 (ave = 0.34866854)\n",
            "Loss_G = 4.70193052 (ave = 5.40127340)\n",
            "\n",
            "epoch: [83/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.065s / 3iters, (0.022)\tData load 0.015s / 3iters, (0.004956)\n",
            "Loss_D = 0.64670366 (ave = 0.34922017)\n",
            "Loss_G = 11.48195648 (ave = 5.41756681)\n",
            "\n",
            "Real Accuracy : 93.21416749420722\n",
            "Fake Accuracy : 2.8467394902350214\n",
            "epoch: [84/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.066s / 10iters, (0.507)\tData load 4.361s / 10iters, (0.436071)\n",
            "Loss_D = 0.32742661 (ave = 0.44911995)\n",
            "Loss_G = 7.48586512 (ave = 6.14488966)\n",
            "\n",
            "epoch: [84/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.708s / 10iters, (0.071)\tData load 0.080s / 10iters, (0.007976)\n",
            "Loss_D = 0.17865287 (ave = 0.40076532)\n",
            "Loss_G = 3.52469015 (ave = 5.48795505)\n",
            "\n",
            "epoch: [84/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.645s / 10iters, (0.065)\tData load 0.065s / 10iters, (0.006479)\n",
            "Loss_D = 0.95410347 (ave = 0.43158669)\n",
            "Loss_G = 5.26533222 (ave = 5.55316626)\n",
            "\n",
            "epoch: [84/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.647s / 10iters, (0.065)\tData load 0.112s / 10iters, (0.011203)\n",
            "Loss_D = 0.05419477 (ave = 0.40648866)\n",
            "Loss_G = 3.36670065 (ave = 5.59768181)\n",
            "\n",
            "epoch: [84/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.685s / 10iters, (0.068)\tData load 0.054s / 10iters, (0.005442)\n",
            "Loss_D = 0.24108069 (ave = 0.43071551)\n",
            "Loss_G = 6.29574251 (ave = 5.62130505)\n",
            "\n",
            "epoch: [84/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.618s / 10iters, (0.062)\tData load 0.085s / 10iters, (0.008509)\n",
            "Loss_D = 0.26796272 (ave = 0.41946050)\n",
            "Loss_G = 4.05386782 (ave = 5.52689094)\n",
            "\n",
            "epoch: [84/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.714s / 10iters, (0.071)\tData load 0.079s / 10iters, (0.007909)\n",
            "Loss_D = 0.45156324 (ave = 0.40596595)\n",
            "Loss_G = 5.57866955 (ave = 5.42158314)\n",
            "\n",
            "epoch: [84/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.701s / 10iters, (0.070)\tData load 0.089s / 10iters, (0.008851)\n",
            "Loss_D = 1.41048443 (ave = 0.44304531)\n",
            "Loss_G = 4.28898954 (ave = 5.39048515)\n",
            "\n",
            "epoch: [84/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.753s / 10iters, (0.075)\tData load 0.114s / 10iters, (0.011386)\n",
            "Loss_D = 0.08894743 (ave = 0.42334263)\n",
            "Loss_G = 4.15911579 (ave = 5.45931713)\n",
            "\n",
            "epoch: [84/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.633s / 10iters, (0.063)\tData load 0.069s / 10iters, (0.006933)\n",
            "Loss_D = 0.61050916 (ave = 0.43192748)\n",
            "Loss_G = 7.47641850 (ave = 5.47904613)\n",
            "\n",
            "epoch: [84/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.665s / 10iters, (0.067)\tData load 0.075s / 10iters, (0.007491)\n",
            "Loss_D = 0.45494550 (ave = 0.45300248)\n",
            "Loss_G = 7.30860853 (ave = 5.48619312)\n",
            "\n",
            "epoch: [84/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.651s / 10iters, (0.065)\tData load 0.099s / 10iters, (0.009905)\n",
            "Loss_D = 0.68792534 (ave = 0.44165715)\n",
            "Loss_G = 7.68597412 (ave = 5.50209450)\n",
            "\n",
            "epoch: [84/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.643s / 10iters, (0.064)\tData load 0.071s / 10iters, (0.007098)\n",
            "Loss_D = 0.18910198 (ave = 0.42440983)\n",
            "Loss_G = 5.19614649 (ave = 5.51380864)\n",
            "\n",
            "epoch: [84/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.586s / 10iters, (0.059)\tData load 0.069s / 10iters, (0.006934)\n",
            "Loss_D = 0.21331513 (ave = 0.41670096)\n",
            "Loss_G = 2.59136057 (ave = 5.43548026)\n",
            "\n",
            "epoch: [84/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.607s / 10iters, (0.061)\tData load 0.097s / 10iters, (0.009678)\n",
            "Loss_D = 0.10859451 (ave = 0.41583831)\n",
            "Loss_G = 3.76155090 (ave = 5.44159452)\n",
            "\n",
            "epoch: [84/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.635s / 10iters, (0.063)\tData load 0.096s / 10iters, (0.009571)\n",
            "Loss_D = 0.72375536 (ave = 0.41436963)\n",
            "Loss_G = 5.23499489 (ave = 5.41139918)\n",
            "\n",
            "epoch: [84/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.699s / 10iters, (0.070)\tData load 0.072s / 10iters, (0.007207)\n",
            "Loss_D = 0.22890905 (ave = 0.41716756)\n",
            "Loss_G = 4.55333757 (ave = 5.41271808)\n",
            "\n",
            "epoch: [84/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.636s / 10iters, (0.064)\tData load 0.073s / 10iters, (0.007305)\n",
            "Loss_D = 1.33093953 (ave = 0.41237046)\n",
            "Loss_G = 8.53991604 (ave = 5.37474543)\n",
            "\n",
            "epoch: [84/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.624s / 10iters, (0.062)\tData load 0.129s / 10iters, (0.012907)\n",
            "Loss_D = 0.63984710 (ave = 0.41413914)\n",
            "Loss_G = 3.75716996 (ave = 5.40249614)\n",
            "\n",
            "epoch: [84/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.639s / 10iters, (0.064)\tData load 0.083s / 10iters, (0.008337)\n",
            "Loss_D = 0.39223561 (ave = 0.41503018)\n",
            "Loss_G = 5.36830711 (ave = 5.39255880)\n",
            "\n",
            "epoch: [84/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.615s / 10iters, (0.061)\tData load 0.089s / 10iters, (0.008878)\n",
            "Loss_D = 0.25893965 (ave = 0.40580004)\n",
            "Loss_G = 4.22851515 (ave = 5.37614564)\n",
            "\n",
            "epoch: [84/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.658s / 10iters, (0.066)\tData load 0.069s / 10iters, (0.006916)\n",
            "Loss_D = 0.57715571 (ave = 0.40745759)\n",
            "Loss_G = 5.85894775 (ave = 5.38882168)\n",
            "\n",
            "epoch: [84/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.350s / 10iters, (0.035)\tData load 0.057s / 10iters, (0.005694)\n",
            "Loss_D = 0.56031239 (ave = 0.41216951)\n",
            "Loss_G = 7.08228588 (ave = 5.40510020)\n",
            "\n",
            "epoch: [84/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.079s / 3iters, (0.026)\tData load 0.014s / 3iters, (0.004584)\n",
            "Loss_D = 0.59841156 (ave = 0.41118989)\n",
            "Loss_G = 6.40742350 (ave = 5.40302588)\n",
            "\n",
            "Real Accuracy : 91.49288315127441\n",
            "Fake Accuracy : 3.4094670638861304\n",
            "epoch: [85/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.053s / 10iters, (0.505)\tData load 4.391s / 10iters, (0.439103)\n",
            "Loss_D = 1.04624557 (ave = 0.74432693)\n",
            "Loss_G = 8.92693520 (ave = 5.40037453)\n",
            "\n",
            "epoch: [85/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.751s / 10iters, (0.075)\tData load 0.124s / 10iters, (0.012412)\n",
            "Loss_D = 0.27250931 (ave = 0.53037976)\n",
            "Loss_G = 4.64749479 (ave = 5.17000778)\n",
            "\n",
            "epoch: [85/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.642s / 10iters, (0.064)\tData load 0.078s / 10iters, (0.007790)\n",
            "Loss_D = 0.32173997 (ave = 0.45804624)\n",
            "Loss_G = 5.27406216 (ave = 5.27829784)\n",
            "\n",
            "epoch: [85/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.670s / 10iters, (0.067)\tData load 0.091s / 10iters, (0.009111)\n",
            "Loss_D = 0.10453938 (ave = 0.42172732)\n",
            "Loss_G = 3.75570703 (ave = 5.18579034)\n",
            "\n",
            "epoch: [85/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.644s / 10iters, (0.064)\tData load 0.060s / 10iters, (0.005979)\n",
            "Loss_D = 0.13459131 (ave = 0.38894306)\n",
            "Loss_G = 3.04874587 (ave = 5.05239194)\n",
            "\n",
            "epoch: [85/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.642s / 10iters, (0.064)\tData load 0.081s / 10iters, (0.008095)\n",
            "Loss_D = 0.28479600 (ave = 0.36889784)\n",
            "Loss_G = 5.92815590 (ave = 4.99013913)\n",
            "\n",
            "epoch: [85/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.671s / 10iters, (0.067)\tData load 0.086s / 10iters, (0.008607)\n",
            "Loss_D = 0.04817627 (ave = 0.35715188)\n",
            "Loss_G = 7.06554699 (ave = 4.96556300)\n",
            "\n",
            "epoch: [85/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.630s / 10iters, (0.063)\tData load 0.076s / 10iters, (0.007565)\n",
            "Loss_D = 0.71460348 (ave = 0.35459415)\n",
            "Loss_G = 4.68051147 (ave = 5.04709646)\n",
            "\n",
            "epoch: [85/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.594s / 10iters, (0.059)\tData load 0.079s / 10iters, (0.007901)\n",
            "Loss_D = 0.46944481 (ave = 0.35287381)\n",
            "Loss_G = 3.82772303 (ave = 5.09414261)\n",
            "\n",
            "epoch: [85/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.566s / 10iters, (0.057)\tData load 0.093s / 10iters, (0.009315)\n",
            "Loss_D = 0.33640736 (ave = 0.34825928)\n",
            "Loss_G = 4.79243326 (ave = 5.09441084)\n",
            "\n",
            "epoch: [85/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.628s / 10iters, (0.063)\tData load 0.084s / 10iters, (0.008412)\n",
            "Loss_D = 0.24581248 (ave = 0.34309103)\n",
            "Loss_G = 6.37085009 (ave = 5.12910490)\n",
            "\n",
            "epoch: [85/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.752s / 10iters, (0.075)\tData load 0.096s / 10iters, (0.009576)\n",
            "Loss_D = 0.45496342 (ave = 0.33539313)\n",
            "Loss_G = 6.52375555 (ave = 5.11275968)\n",
            "\n",
            "epoch: [85/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.659s / 10iters, (0.066)\tData load 0.078s / 10iters, (0.007811)\n",
            "Loss_D = 0.12741457 (ave = 0.32556396)\n",
            "Loss_G = 5.48626614 (ave = 5.08669653)\n",
            "\n",
            "epoch: [85/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.627s / 10iters, (0.063)\tData load 0.082s / 10iters, (0.008205)\n",
            "Loss_D = 0.84289175 (ave = 0.33565047)\n",
            "Loss_G = 4.75464582 (ave = 5.11701380)\n",
            "\n",
            "epoch: [85/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.689s / 10iters, (0.069)\tData load 0.076s / 10iters, (0.007602)\n",
            "Loss_D = 0.10277727 (ave = 0.33311105)\n",
            "Loss_G = 5.54273319 (ave = 5.13041988)\n",
            "\n",
            "epoch: [85/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.594s / 10iters, (0.059)\tData load 0.070s / 10iters, (0.007049)\n",
            "Loss_D = 0.38439190 (ave = 0.32720292)\n",
            "Loss_G = 6.21526241 (ave = 5.15758179)\n",
            "\n",
            "epoch: [85/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.600s / 10iters, (0.060)\tData load 0.079s / 10iters, (0.007868)\n",
            "Loss_D = 0.54540080 (ave = 0.32960913)\n",
            "Loss_G = 3.99393034 (ave = 5.13826486)\n",
            "\n",
            "epoch: [85/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.620s / 10iters, (0.062)\tData load 0.088s / 10iters, (0.008818)\n",
            "Loss_D = 0.14471796 (ave = 0.33130764)\n",
            "Loss_G = 4.09831953 (ave = 5.16162631)\n",
            "\n",
            "epoch: [85/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.643s / 10iters, (0.064)\tData load 0.091s / 10iters, (0.009128)\n",
            "Loss_D = 0.05522883 (ave = 0.33852241)\n",
            "Loss_G = 4.27349186 (ave = 5.17037406)\n",
            "\n",
            "epoch: [85/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.609s / 10iters, (0.061)\tData load 0.083s / 10iters, (0.008259)\n",
            "Loss_D = 0.10788456 (ave = 0.33561216)\n",
            "Loss_G = 4.65192461 (ave = 5.15361454)\n",
            "\n",
            "epoch: [85/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.634s / 10iters, (0.063)\tData load 0.097s / 10iters, (0.009684)\n",
            "Loss_D = 0.19463083 (ave = 0.32866163)\n",
            "Loss_G = 4.00369740 (ave = 5.16413385)\n",
            "\n",
            "epoch: [85/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.641s / 10iters, (0.064)\tData load 0.098s / 10iters, (0.009772)\n",
            "Loss_D = 0.93498844 (ave = 0.32445909)\n",
            "Loss_G = 6.33631229 (ave = 5.14175993)\n",
            "\n",
            "epoch: [85/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.311s / 10iters, (0.031)\tData load 0.055s / 10iters, (0.005515)\n",
            "Loss_D = 0.16984391 (ave = 0.32184913)\n",
            "Loss_G = 5.46211147 (ave = 5.15903863)\n",
            "\n",
            "epoch: [85/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.069s / 3iters, (0.023)\tData load 0.017s / 3iters, (0.005805)\n",
            "Loss_D = 0.11249246 (ave = 0.31969948)\n",
            "Loss_G = 5.54471111 (ave = 5.15980697)\n",
            "\n",
            "Real Accuracy : 93.6775902019199\n",
            "Fake Accuracy : 2.6481297583581593\n",
            "epoch: [86/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.081s / 10iters, (0.508)\tData load 4.409s / 10iters, (0.440887)\n",
            "Loss_D = 0.11726990 (ave = 0.31771806)\n",
            "Loss_G = 3.96176410 (ave = 5.35761938)\n",
            "\n",
            "epoch: [86/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.674s / 10iters, (0.067)\tData load 0.076s / 10iters, (0.007635)\n",
            "Loss_D = 0.37121445 (ave = 0.31386861)\n",
            "Loss_G = 5.00539589 (ave = 5.16936325)\n",
            "\n",
            "epoch: [86/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.650s / 10iters, (0.065)\tData load 0.098s / 10iters, (0.009817)\n",
            "Loss_D = 0.16537975 (ave = 0.31999761)\n",
            "Loss_G = 2.89946914 (ave = 5.02627033)\n",
            "\n",
            "epoch: [86/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.604s / 10iters, (0.060)\tData load 0.081s / 10iters, (0.008058)\n",
            "Loss_D = 0.13478653 (ave = 0.36131111)\n",
            "Loss_G = 4.46063042 (ave = 5.24192581)\n",
            "\n",
            "epoch: [86/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.648s / 10iters, (0.065)\tData load 0.092s / 10iters, (0.009201)\n",
            "Loss_D = 0.24483874 (ave = 0.33228048)\n",
            "Loss_G = 4.95907068 (ave = 5.32217671)\n",
            "\n",
            "epoch: [86/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.610s / 10iters, (0.061)\tData load 0.081s / 10iters, (0.008055)\n",
            "Loss_D = 0.14076504 (ave = 0.32202458)\n",
            "Loss_G = 4.90210056 (ave = 5.41886300)\n",
            "\n",
            "epoch: [86/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.670s / 10iters, (0.067)\tData load 0.073s / 10iters, (0.007346)\n",
            "Loss_D = 0.02551233 (ave = 0.32691969)\n",
            "Loss_G = 3.54186368 (ave = 5.39846349)\n",
            "\n",
            "epoch: [86/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.588s / 10iters, (0.059)\tData load 0.092s / 10iters, (0.009248)\n",
            "Loss_D = 0.14672442 (ave = 0.32121556)\n",
            "Loss_G = 3.63226056 (ave = 5.39931175)\n",
            "\n",
            "epoch: [86/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.624s / 10iters, (0.062)\tData load 0.105s / 10iters, (0.010472)\n",
            "Loss_D = 0.14648111 (ave = 0.32319671)\n",
            "Loss_G = 5.06927919 (ave = 5.40728110)\n",
            "\n",
            "epoch: [86/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.687s / 10iters, (0.069)\tData load 0.094s / 10iters, (0.009400)\n",
            "Loss_D = 0.08960877 (ave = 0.30742344)\n",
            "Loss_G = 2.91496372 (ave = 5.31933853)\n",
            "\n",
            "epoch: [86/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.601s / 10iters, (0.060)\tData load 0.093s / 10iters, (0.009333)\n",
            "Loss_D = 0.19700268 (ave = 0.30776724)\n",
            "Loss_G = 6.74148512 (ave = 5.36412937)\n",
            "\n",
            "epoch: [86/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.662s / 10iters, (0.066)\tData load 0.090s / 10iters, (0.009011)\n",
            "Loss_D = 0.50605518 (ave = 0.30711804)\n",
            "Loss_G = 7.82751274 (ave = 5.34497508)\n",
            "\n",
            "epoch: [86/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.616s / 10iters, (0.062)\tData load 0.083s / 10iters, (0.008250)\n",
            "Loss_D = 0.23843277 (ave = 0.30302611)\n",
            "Loss_G = 4.03186512 (ave = 5.33885730)\n",
            "\n",
            "epoch: [86/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.733s / 10iters, (0.073)\tData load 0.076s / 10iters, (0.007618)\n",
            "Loss_D = 0.49637377 (ave = 0.30772181)\n",
            "Loss_G = 6.39418221 (ave = 5.37081380)\n",
            "\n",
            "epoch: [86/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.618s / 10iters, (0.062)\tData load 0.065s / 10iters, (0.006508)\n",
            "Loss_D = 0.16609633 (ave = 0.30934980)\n",
            "Loss_G = 6.11982441 (ave = 5.38734164)\n",
            "\n",
            "epoch: [86/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.619s / 10iters, (0.062)\tData load 0.082s / 10iters, (0.008234)\n",
            "Loss_D = 0.66046655 (ave = 0.30734176)\n",
            "Loss_G = 5.17301846 (ave = 5.36404585)\n",
            "\n",
            "epoch: [86/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.668s / 10iters, (0.067)\tData load 0.080s / 10iters, (0.007981)\n",
            "Loss_D = 0.39878714 (ave = 0.31246636)\n",
            "Loss_G = 6.72264194 (ave = 5.39582704)\n",
            "\n",
            "epoch: [86/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.606s / 10iters, (0.061)\tData load 0.065s / 10iters, (0.006513)\n",
            "Loss_D = 0.30232456 (ave = 0.31582383)\n",
            "Loss_G = 6.07233906 (ave = 5.42919915)\n",
            "\n",
            "epoch: [86/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.695s / 10iters, (0.070)\tData load 0.067s / 10iters, (0.006651)\n",
            "Loss_D = 0.13928834 (ave = 0.31498840)\n",
            "Loss_G = 3.66520095 (ave = 5.42571353)\n",
            "\n",
            "epoch: [86/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.551s / 10iters, (0.055)\tData load 0.083s / 10iters, (0.008305)\n",
            "Loss_D = 0.19168127 (ave = 0.31766315)\n",
            "Loss_G = 5.10549068 (ave = 5.42823051)\n",
            "\n",
            "epoch: [86/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.593s / 10iters, (0.059)\tData load 0.074s / 10iters, (0.007374)\n",
            "Loss_D = 0.60558558 (ave = 0.31839102)\n",
            "Loss_G = 3.57170391 (ave = 5.45531031)\n",
            "\n",
            "epoch: [86/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.707s / 10iters, (0.071)\tData load 0.072s / 10iters, (0.007167)\n",
            "Loss_D = 0.24658340 (ave = 0.32254532)\n",
            "Loss_G = 4.35113192 (ave = 5.47194972)\n",
            "\n",
            "epoch: [86/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.338s / 10iters, (0.034)\tData load 0.052s / 10iters, (0.005199)\n",
            "Loss_D = 0.49345377 (ave = 0.31951989)\n",
            "Loss_G = 6.44287920 (ave = 5.44132558)\n",
            "\n",
            "epoch: [86/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.066s / 3iters, (0.022)\tData load 0.017s / 3iters, (0.005549)\n",
            "Loss_D = 0.25757754 (ave = 0.31863227)\n",
            "Loss_G = 3.37869334 (ave = 5.43874709)\n",
            "\n",
            "Real Accuracy : 93.87619993379676\n",
            "Fake Accuracy : 2.5488248924197285\n",
            "epoch: [87/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.014s / 10iters, (0.501)\tData load 4.308s / 10iters, (0.430791)\n",
            "Loss_D = 0.14599870 (ave = 0.29168679)\n",
            "Loss_G = 4.09781218 (ave = 5.22876110)\n",
            "\n",
            "epoch: [87/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.742s / 10iters, (0.074)\tData load 0.085s / 10iters, (0.008533)\n",
            "Loss_D = 0.41931155 (ave = 0.29242972)\n",
            "Loss_G = 5.92218876 (ave = 5.31534312)\n",
            "\n",
            "epoch: [87/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.563s / 10iters, (0.056)\tData load 0.073s / 10iters, (0.007290)\n",
            "Loss_D = 0.25784490 (ave = 0.33154039)\n",
            "Loss_G = 4.60770845 (ave = 5.27318583)\n",
            "\n",
            "epoch: [87/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.640s / 10iters, (0.064)\tData load 0.100s / 10iters, (0.010005)\n",
            "Loss_D = 0.25775075 (ave = 0.34840754)\n",
            "Loss_G = 5.63154030 (ave = 5.43031379)\n",
            "\n",
            "epoch: [87/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.663s / 10iters, (0.066)\tData load 0.114s / 10iters, (0.011378)\n",
            "Loss_D = 0.24954787 (ave = 0.33732553)\n",
            "Loss_G = 6.53882504 (ave = 5.49716717)\n",
            "\n",
            "epoch: [87/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.630s / 10iters, (0.063)\tData load 0.075s / 10iters, (0.007528)\n",
            "Loss_D = 0.23193644 (ave = 0.32810342)\n",
            "Loss_G = 4.56850290 (ave = 5.40288672)\n",
            "\n",
            "epoch: [87/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.707s / 10iters, (0.071)\tData load 0.066s / 10iters, (0.006643)\n",
            "Loss_D = 0.10485359 (ave = 0.31413117)\n",
            "Loss_G = 4.13141012 (ave = 5.24915336)\n",
            "\n",
            "epoch: [87/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.685s / 10iters, (0.068)\tData load 0.083s / 10iters, (0.008253)\n",
            "Loss_D = 0.32736871 (ave = 0.30733937)\n",
            "Loss_G = 6.48831701 (ave = 5.30820479)\n",
            "\n",
            "epoch: [87/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.679s / 10iters, (0.068)\tData load 0.078s / 10iters, (0.007759)\n",
            "Loss_D = 0.12369455 (ave = 0.29665617)\n",
            "Loss_G = 4.95855808 (ave = 5.27964611)\n",
            "\n",
            "epoch: [87/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.632s / 10iters, (0.063)\tData load 0.077s / 10iters, (0.007715)\n",
            "Loss_D = 0.22755897 (ave = 0.28721333)\n",
            "Loss_G = 4.54512167 (ave = 5.24506014)\n",
            "\n",
            "epoch: [87/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.660s / 10iters, (0.066)\tData load 0.076s / 10iters, (0.007615)\n",
            "Loss_D = 0.15324624 (ave = 0.27813179)\n",
            "Loss_G = 5.62830925 (ave = 5.24320616)\n",
            "\n",
            "epoch: [87/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.689s / 10iters, (0.069)\tData load 0.076s / 10iters, (0.007642)\n",
            "Loss_D = 0.24271667 (ave = 0.27537321)\n",
            "Loss_G = 5.25334930 (ave = 5.24374029)\n",
            "\n",
            "epoch: [87/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.619s / 10iters, (0.062)\tData load 0.082s / 10iters, (0.008178)\n",
            "Loss_D = 0.08698528 (ave = 0.26708969)\n",
            "Loss_G = 3.80904675 (ave = 5.17980536)\n",
            "\n",
            "epoch: [87/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.634s / 10iters, (0.063)\tData load 0.056s / 10iters, (0.005616)\n",
            "Loss_D = 0.10566801 (ave = 0.26224256)\n",
            "Loss_G = 4.52026844 (ave = 5.18247646)\n",
            "\n",
            "epoch: [87/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.663s / 10iters, (0.066)\tData load 0.061s / 10iters, (0.006052)\n",
            "Loss_D = 0.07219178 (ave = 0.25635055)\n",
            "Loss_G = 4.62278461 (ave = 5.15310771)\n",
            "\n",
            "epoch: [87/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.700s / 10iters, (0.070)\tData load 0.087s / 10iters, (0.008674)\n",
            "Loss_D = 0.22944981 (ave = 0.25619810)\n",
            "Loss_G = 5.26100111 (ave = 5.17551364)\n",
            "\n",
            "epoch: [87/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.595s / 10iters, (0.060)\tData load 0.055s / 10iters, (0.005531)\n",
            "Loss_D = 0.45789844 (ave = 0.26616720)\n",
            "Loss_G = 4.16316700 (ave = 5.19783000)\n",
            "\n",
            "epoch: [87/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.641s / 10iters, (0.064)\tData load 0.066s / 10iters, (0.006580)\n",
            "Loss_D = 0.16443615 (ave = 0.27694838)\n",
            "Loss_G = 6.16159487 (ave = 5.24199673)\n",
            "\n",
            "epoch: [87/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.665s / 10iters, (0.066)\tData load 0.089s / 10iters, (0.008922)\n",
            "Loss_D = 0.60135561 (ave = 0.31509591)\n",
            "Loss_G = 6.11172962 (ave = 5.28308687)\n",
            "\n",
            "epoch: [87/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.598s / 10iters, (0.060)\tData load 0.073s / 10iters, (0.007333)\n",
            "Loss_D = 1.02440977 (ave = 0.32686405)\n",
            "Loss_G = 7.18348503 (ave = 5.36476417)\n",
            "\n",
            "epoch: [87/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.576s / 10iters, (0.058)\tData load 0.065s / 10iters, (0.006526)\n",
            "Loss_D = 0.42292988 (ave = 0.33223209)\n",
            "Loss_G = 5.40713072 (ave = 5.39019263)\n",
            "\n",
            "epoch: [87/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.658s / 10iters, (0.066)\tData load 0.052s / 10iters, (0.005214)\n",
            "Loss_D = 0.26318547 (ave = 0.32990309)\n",
            "Loss_G = 4.69407749 (ave = 5.39121514)\n",
            "\n",
            "epoch: [87/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.287s / 10iters, (0.029)\tData load 0.056s / 10iters, (0.005633)\n",
            "Loss_D = 0.37986249 (ave = 0.33454682)\n",
            "Loss_G = 7.41292095 (ave = 5.39974307)\n",
            "\n",
            "epoch: [87/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.069s / 3iters, (0.023)\tData load 0.013s / 3iters, (0.004196)\n",
            "Loss_D = 0.03435586 (ave = 0.33385605)\n",
            "Loss_G = 6.80796719 (ave = 5.40547976)\n",
            "\n",
            "Real Accuracy : 93.51208209202251\n",
            "Fake Accuracy : 2.7474346242965906\n",
            "epoch: [88/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.053s / 10iters, (0.505)\tData load 4.353s / 10iters, (0.435273)\n",
            "Loss_D = 0.47974810 (ave = 0.29832288)\n",
            "Loss_G = 7.05301714 (ave = 5.04420788)\n",
            "\n",
            "epoch: [88/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.713s / 10iters, (0.071)\tData load 0.064s / 10iters, (0.006430)\n",
            "Loss_D = 0.88613129 (ave = 0.37035797)\n",
            "Loss_G = 8.67317772 (ave = 5.18360763)\n",
            "\n",
            "epoch: [88/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.591s / 10iters, (0.059)\tData load 0.099s / 10iters, (0.009929)\n",
            "Loss_D = 0.14493939 (ave = 0.40870252)\n",
            "Loss_G = 4.06615543 (ave = 5.40135062)\n",
            "\n",
            "epoch: [88/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.591s / 10iters, (0.059)\tData load 0.088s / 10iters, (0.008751)\n",
            "Loss_D = 0.24259621 (ave = 0.38847713)\n",
            "Loss_G = 5.36681652 (ave = 5.46107528)\n",
            "\n",
            "epoch: [88/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.626s / 10iters, (0.063)\tData load 0.075s / 10iters, (0.007509)\n",
            "Loss_D = 0.07116622 (ave = 0.36525318)\n",
            "Loss_G = 4.13858080 (ave = 5.48515043)\n",
            "\n",
            "epoch: [88/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.665s / 10iters, (0.066)\tData load 0.084s / 10iters, (0.008395)\n",
            "Loss_D = 0.16484043 (ave = 0.36373902)\n",
            "Loss_G = 6.18884230 (ave = 5.48558110)\n",
            "\n",
            "epoch: [88/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.601s / 10iters, (0.060)\tData load 0.113s / 10iters, (0.011292)\n",
            "Loss_D = 0.03446691 (ave = 0.35572600)\n",
            "Loss_G = 6.44067478 (ave = 5.53805543)\n",
            "\n",
            "epoch: [88/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.563s / 10iters, (0.056)\tData load 0.066s / 10iters, (0.006636)\n",
            "Loss_D = 0.18864998 (ave = 0.33382056)\n",
            "Loss_G = 4.78550482 (ave = 5.52105660)\n",
            "\n",
            "epoch: [88/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.642s / 10iters, (0.064)\tData load 0.082s / 10iters, (0.008205)\n",
            "Loss_D = 0.28529161 (ave = 0.33602816)\n",
            "Loss_G = 4.25969172 (ave = 5.50948277)\n",
            "\n",
            "epoch: [88/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.592s / 10iters, (0.059)\tData load 0.071s / 10iters, (0.007088)\n",
            "Loss_D = 0.43840957 (ave = 0.33174701)\n",
            "Loss_G = 6.01866913 (ave = 5.50118800)\n",
            "\n",
            "epoch: [88/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.669s / 10iters, (0.067)\tData load 0.078s / 10iters, (0.007769)\n",
            "Loss_D = 0.28747991 (ave = 0.33299662)\n",
            "Loss_G = 5.64073372 (ave = 5.51982803)\n",
            "\n",
            "epoch: [88/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.608s / 10iters, (0.061)\tData load 0.082s / 10iters, (0.008227)\n",
            "Loss_D = 0.38393214 (ave = 0.32761446)\n",
            "Loss_G = 5.70097256 (ave = 5.46704970)\n",
            "\n",
            "epoch: [88/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.687s / 10iters, (0.069)\tData load 0.102s / 10iters, (0.010231)\n",
            "Loss_D = 0.24205866 (ave = 0.32634014)\n",
            "Loss_G = 5.89196062 (ave = 5.47831405)\n",
            "\n",
            "epoch: [88/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.642s / 10iters, (0.064)\tData load 0.068s / 10iters, (0.006751)\n",
            "Loss_D = 0.33122981 (ave = 0.32630618)\n",
            "Loss_G = 6.01409578 (ave = 5.44271672)\n",
            "\n",
            "epoch: [88/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.661s / 10iters, (0.066)\tData load 0.078s / 10iters, (0.007775)\n",
            "Loss_D = 0.06043913 (ave = 0.32618483)\n",
            "Loss_G = 7.58467293 (ave = 5.48726827)\n",
            "\n",
            "epoch: [88/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.563s / 10iters, (0.056)\tData load 0.077s / 10iters, (0.007718)\n",
            "Loss_D = 0.40413225 (ave = 0.33031804)\n",
            "Loss_G = 5.47140408 (ave = 5.50813939)\n",
            "\n",
            "epoch: [88/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.635s / 10iters, (0.064)\tData load 0.081s / 10iters, (0.008135)\n",
            "Loss_D = 0.22786844 (ave = 0.33165182)\n",
            "Loss_G = 3.91839552 (ave = 5.49637254)\n",
            "\n",
            "epoch: [88/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.701s / 10iters, (0.070)\tData load 0.065s / 10iters, (0.006485)\n",
            "Loss_D = 0.40164346 (ave = 0.33103961)\n",
            "Loss_G = 5.25121403 (ave = 5.50132611)\n",
            "\n",
            "epoch: [88/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.577s / 10iters, (0.058)\tData load 0.075s / 10iters, (0.007517)\n",
            "Loss_D = 0.47769701 (ave = 0.32805305)\n",
            "Loss_G = 7.96721840 (ave = 5.49824271)\n",
            "\n",
            "epoch: [88/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.632s / 10iters, (0.063)\tData load 0.074s / 10iters, (0.007360)\n",
            "Loss_D = 0.59558773 (ave = 0.32322270)\n",
            "Loss_G = 6.95984650 (ave = 5.49536409)\n",
            "\n",
            "epoch: [88/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.556s / 10iters, (0.056)\tData load 0.080s / 10iters, (0.008003)\n",
            "Loss_D = 0.07489333 (ave = 0.31705984)\n",
            "Loss_G = 5.20572758 (ave = 5.46948432)\n",
            "\n",
            "epoch: [88/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.579s / 10iters, (0.058)\tData load 0.088s / 10iters, (0.008772)\n",
            "Loss_D = 0.18788701 (ave = 0.31306525)\n",
            "Loss_G = 7.29550600 (ave = 5.49602451)\n",
            "\n",
            "epoch: [88/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.344s / 10iters, (0.034)\tData load 0.055s / 10iters, (0.005521)\n",
            "Loss_D = 0.30390686 (ave = 0.31348301)\n",
            "Loss_G = 5.64295387 (ave = 5.47187039)\n",
            "\n",
            "epoch: [88/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.068s / 3iters, (0.023)\tData load 0.017s / 3iters, (0.005729)\n",
            "Loss_D = 0.17474174 (ave = 0.31183455)\n",
            "Loss_G = 6.73705435 (ave = 5.48224632)\n",
            "\n",
            "Real Accuracy : 93.77689506785832\n",
            "Fake Accuracy : 2.8136378682555447\n",
            "epoch: [89/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.319s / 10iters, (0.532)\tData load 4.684s / 10iters, (0.468429)\n",
            "Loss_D = 0.21270715 (ave = 0.25140523)\n",
            "Loss_G = 5.23856258 (ave = 5.89388151)\n",
            "\n",
            "epoch: [89/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.570s / 10iters, (0.057)\tData load 0.081s / 10iters, (0.008063)\n",
            "Loss_D = 0.15135661 (ave = 0.25673179)\n",
            "Loss_G = 6.69793510 (ave = 5.61597620)\n",
            "\n",
            "epoch: [89/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.823s / 10iters, (0.082)\tData load 0.118s / 10iters, (0.011846)\n",
            "Loss_D = 0.31478849 (ave = 0.25264281)\n",
            "Loss_G = 8.00719547 (ave = 5.51100512)\n",
            "\n",
            "epoch: [89/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.644s / 10iters, (0.064)\tData load 0.081s / 10iters, (0.008112)\n",
            "Loss_D = 0.70828211 (ave = 0.25886767)\n",
            "Loss_G = 7.94883299 (ave = 5.59276581)\n",
            "\n",
            "epoch: [89/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.602s / 10iters, (0.060)\tData load 0.073s / 10iters, (0.007268)\n",
            "Loss_D = 0.64542323 (ave = 0.28312038)\n",
            "Loss_G = 7.96899986 (ave = 5.59367446)\n",
            "\n",
            "epoch: [89/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.699s / 10iters, (0.070)\tData load 0.113s / 10iters, (0.011314)\n",
            "Loss_D = 0.46213871 (ave = 0.29099294)\n",
            "Loss_G = 6.36002874 (ave = 5.64228262)\n",
            "\n",
            "epoch: [89/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.613s / 10iters, (0.061)\tData load 0.084s / 10iters, (0.008392)\n",
            "Loss_D = 0.33134332 (ave = 0.28385283)\n",
            "Loss_G = 7.12640381 (ave = 5.73039753)\n",
            "\n",
            "epoch: [89/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.632s / 10iters, (0.063)\tData load 0.071s / 10iters, (0.007118)\n",
            "Loss_D = 0.20581621 (ave = 0.30066791)\n",
            "Loss_G = 5.17910671 (ave = 5.66905963)\n",
            "\n",
            "epoch: [89/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.661s / 10iters, (0.066)\tData load 0.095s / 10iters, (0.009534)\n",
            "Loss_D = 0.14273494 (ave = 0.29873559)\n",
            "Loss_G = 4.94853783 (ave = 5.65958382)\n",
            "\n",
            "epoch: [89/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.715s / 10iters, (0.072)\tData load 0.090s / 10iters, (0.009035)\n",
            "Loss_D = 0.45497262 (ave = 0.29560386)\n",
            "Loss_G = 5.63748217 (ave = 5.62223723)\n",
            "\n",
            "epoch: [89/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.726s / 10iters, (0.073)\tData load 0.081s / 10iters, (0.008147)\n",
            "Loss_D = 0.30291638 (ave = 0.30094910)\n",
            "Loss_G = 6.94158077 (ave = 5.65967383)\n",
            "\n",
            "epoch: [89/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.647s / 10iters, (0.065)\tData load 0.087s / 10iters, (0.008694)\n",
            "Loss_D = 0.12050047 (ave = 0.29759054)\n",
            "Loss_G = 5.21635962 (ave = 5.64747620)\n",
            "\n",
            "epoch: [89/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.649s / 10iters, (0.065)\tData load 0.082s / 10iters, (0.008249)\n",
            "Loss_D = 0.75470275 (ave = 0.29189930)\n",
            "Loss_G = 6.41171360 (ave = 5.64494567)\n",
            "\n",
            "epoch: [89/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.679s / 10iters, (0.068)\tData load 0.108s / 10iters, (0.010839)\n",
            "Loss_D = 0.14845118 (ave = 0.28598907)\n",
            "Loss_G = 5.21180439 (ave = 5.61627821)\n",
            "\n",
            "epoch: [89/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.649s / 10iters, (0.065)\tData load 0.072s / 10iters, (0.007158)\n",
            "Loss_D = 0.27855849 (ave = 0.28636335)\n",
            "Loss_G = 4.52987003 (ave = 5.59106459)\n",
            "\n",
            "epoch: [89/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.611s / 10iters, (0.061)\tData load 0.080s / 10iters, (0.008033)\n",
            "Loss_D = 0.50017607 (ave = 0.28741610)\n",
            "Loss_G = 7.75895786 (ave = 5.59419359)\n",
            "\n",
            "epoch: [89/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.613s / 10iters, (0.061)\tData load 0.083s / 10iters, (0.008302)\n",
            "Loss_D = 0.40895098 (ave = 0.28805982)\n",
            "Loss_G = 5.96320677 (ave = 5.61029483)\n",
            "\n",
            "epoch: [89/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.639s / 10iters, (0.064)\tData load 0.055s / 10iters, (0.005486)\n",
            "Loss_D = 0.48633859 (ave = 0.28440469)\n",
            "Loss_G = 4.71247721 (ave = 5.61748523)\n",
            "\n",
            "epoch: [89/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.685s / 10iters, (0.069)\tData load 0.083s / 10iters, (0.008257)\n",
            "Loss_D = 0.30736515 (ave = 0.29080345)\n",
            "Loss_G = 4.86103535 (ave = 5.62304690)\n",
            "\n",
            "epoch: [89/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.579s / 10iters, (0.058)\tData load 0.069s / 10iters, (0.006869)\n",
            "Loss_D = 0.47520167 (ave = 0.29163061)\n",
            "Loss_G = 4.46528196 (ave = 5.61598427)\n",
            "\n",
            "epoch: [89/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.639s / 10iters, (0.064)\tData load 0.098s / 10iters, (0.009763)\n",
            "Loss_D = 0.25129613 (ave = 0.29131385)\n",
            "Loss_G = 5.40903997 (ave = 5.61401636)\n",
            "\n",
            "epoch: [89/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.611s / 10iters, (0.061)\tData load 0.090s / 10iters, (0.008958)\n",
            "Loss_D = 1.08754551 (ave = 0.29905603)\n",
            "Loss_G = 3.73007417 (ave = 5.61810528)\n",
            "\n",
            "epoch: [89/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.373s / 10iters, (0.037)\tData load 0.058s / 10iters, (0.005778)\n",
            "Loss_D = 0.28922397 (ave = 0.29524008)\n",
            "Loss_G = 6.85074520 (ave = 5.58034698)\n",
            "\n",
            "epoch: [89/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.064s / 3iters, (0.021)\tData load 0.015s / 3iters, (0.005041)\n",
            "Loss_D = 0.10625068 (ave = 0.29627541)\n",
            "Loss_G = 7.49387980 (ave = 5.59431564)\n",
            "\n",
            "Real Accuracy : 93.90930155577624\n",
            "Fake Accuracy : 2.4495200264812977\n",
            "epoch: [90/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.056s / 10iters, (0.506)\tData load 4.435s / 10iters, (0.443478)\n",
            "Loss_D = 0.40144724 (ave = 0.26558002)\n",
            "Loss_G = 6.64010334 (ave = 6.15230274)\n",
            "\n",
            "epoch: [90/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.674s / 10iters, (0.067)\tData load 0.127s / 10iters, (0.012720)\n",
            "Loss_D = 0.11746768 (ave = 0.30413246)\n",
            "Loss_G = 5.57431364 (ave = 5.88595984)\n",
            "\n",
            "epoch: [90/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.603s / 10iters, (0.060)\tData load 0.079s / 10iters, (0.007903)\n",
            "Loss_D = 0.14333680 (ave = 0.27178917)\n",
            "Loss_G = 4.27071524 (ave = 5.61788954)\n",
            "\n",
            "epoch: [90/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.617s / 10iters, (0.062)\tData load 0.091s / 10iters, (0.009110)\n",
            "Loss_D = 0.08485991 (ave = 0.26220839)\n",
            "Loss_G = 2.60659671 (ave = 5.52541319)\n",
            "\n",
            "epoch: [90/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.703s / 10iters, (0.070)\tData load 0.094s / 10iters, (0.009369)\n",
            "Loss_D = 0.30812255 (ave = 0.25902416)\n",
            "Loss_G = 1.99841607 (ave = 5.44757222)\n",
            "\n",
            "epoch: [90/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.649s / 10iters, (0.065)\tData load 0.057s / 10iters, (0.005703)\n",
            "Loss_D = 0.35524321 (ave = 0.27338313)\n",
            "Loss_G = 6.86331081 (ave = 5.59651658)\n",
            "\n",
            "epoch: [90/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.627s / 10iters, (0.063)\tData load 0.075s / 10iters, (0.007542)\n",
            "Loss_D = 0.06608547 (ave = 0.26928020)\n",
            "Loss_G = 4.78727436 (ave = 5.56075376)\n",
            "\n",
            "epoch: [90/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.610s / 10iters, (0.061)\tData load 0.079s / 10iters, (0.007944)\n",
            "Loss_D = 0.78039449 (ave = 0.27723655)\n",
            "Loss_G = 11.69944572 (ave = 5.63257035)\n",
            "\n",
            "epoch: [90/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.611s / 10iters, (0.061)\tData load 0.073s / 10iters, (0.007305)\n",
            "Loss_D = 0.37090856 (ave = 0.32876603)\n",
            "Loss_G = 7.98661089 (ave = 5.69072207)\n",
            "\n",
            "epoch: [90/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.623s / 10iters, (0.062)\tData load 0.087s / 10iters, (0.008737)\n",
            "Loss_D = 0.31695133 (ave = 0.36298390)\n",
            "Loss_G = 5.99362278 (ave = 5.66721222)\n",
            "\n",
            "epoch: [90/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.628s / 10iters, (0.063)\tData load 0.103s / 10iters, (0.010322)\n",
            "Loss_D = 0.66620147 (ave = 0.35354087)\n",
            "Loss_G = 8.84831905 (ave = 5.68800567)\n",
            "\n",
            "epoch: [90/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.570s / 10iters, (0.057)\tData load 0.091s / 10iters, (0.009120)\n",
            "Loss_D = 0.31680486 (ave = 0.34950841)\n",
            "Loss_G = 5.52635241 (ave = 5.67666051)\n",
            "\n",
            "epoch: [90/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.691s / 10iters, (0.069)\tData load 0.102s / 10iters, (0.010230)\n",
            "Loss_D = 0.87375134 (ave = 0.34577330)\n",
            "Loss_G = 3.43615389 (ave = 5.56906944)\n",
            "\n",
            "epoch: [90/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.629s / 10iters, (0.063)\tData load 0.118s / 10iters, (0.011779)\n",
            "Loss_D = 0.22285339 (ave = 0.33625936)\n",
            "Loss_G = 3.62095666 (ave = 5.52924182)\n",
            "\n",
            "epoch: [90/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.641s / 10iters, (0.064)\tData load 0.061s / 10iters, (0.006063)\n",
            "Loss_D = 0.24701920 (ave = 0.33363564)\n",
            "Loss_G = 5.58271837 (ave = 5.50012541)\n",
            "\n",
            "epoch: [90/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.589s / 10iters, (0.059)\tData load 0.072s / 10iters, (0.007181)\n",
            "Loss_D = 0.04785760 (ave = 0.32840423)\n",
            "Loss_G = 4.33881950 (ave = 5.47656890)\n",
            "\n",
            "epoch: [90/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.656s / 10iters, (0.066)\tData load 0.080s / 10iters, (0.008049)\n",
            "Loss_D = 0.19753540 (ave = 0.33291531)\n",
            "Loss_G = 5.10069275 (ave = 5.48890699)\n",
            "\n",
            "epoch: [90/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.636s / 10iters, (0.064)\tData load 0.068s / 10iters, (0.006805)\n",
            "Loss_D = 0.04329853 (ave = 0.33274997)\n",
            "Loss_G = 4.03127098 (ave = 5.50423916)\n",
            "\n",
            "epoch: [90/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.645s / 10iters, (0.065)\tData load 0.087s / 10iters, (0.008721)\n",
            "Loss_D = 0.12500733 (ave = 0.33314696)\n",
            "Loss_G = 6.27087641 (ave = 5.53215580)\n",
            "\n",
            "epoch: [90/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.603s / 10iters, (0.060)\tData load 0.084s / 10iters, (0.008434)\n",
            "Loss_D = 0.03571815 (ave = 0.32899595)\n",
            "Loss_G = 5.03727818 (ave = 5.53134109)\n",
            "\n",
            "epoch: [90/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.702s / 10iters, (0.070)\tData load 0.079s / 10iters, (0.007905)\n",
            "Loss_D = 0.32518715 (ave = 0.33311109)\n",
            "Loss_G = 6.55301619 (ave = 5.57561930)\n",
            "\n",
            "epoch: [90/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.582s / 10iters, (0.058)\tData load 0.085s / 10iters, (0.008525)\n",
            "Loss_D = 0.26951116 (ave = 0.33123097)\n",
            "Loss_G = 5.50351906 (ave = 5.57046632)\n",
            "\n",
            "epoch: [90/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.323s / 10iters, (0.032)\tData load 0.061s / 10iters, (0.006077)\n",
            "Loss_D = 0.37809905 (ave = 0.34447891)\n",
            "Loss_G = 5.99961042 (ave = 5.55459654)\n",
            "\n",
            "epoch: [90/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.068s / 3iters, (0.023)\tData load 0.015s / 3iters, (0.004845)\n",
            "Loss_D = 0.22781678 (ave = 0.34281342)\n",
            "Loss_G = 5.49717140 (ave = 5.56226823)\n",
            "\n",
            "Real Accuracy : 92.61833829857663\n",
            "Fake Accuracy : 2.8136378682555447\n",
            "epoch: [91/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.042s / 10iters, (0.504)\tData load 4.370s / 10iters, (0.436999)\n",
            "Loss_D = 0.57322407 (ave = 0.30773925)\n",
            "Loss_G = 5.84095001 (ave = 5.93892097)\n",
            "\n",
            "epoch: [91/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.664s / 10iters, (0.066)\tData load 0.074s / 10iters, (0.007425)\n",
            "Loss_D = 0.61303759 (ave = 0.35201093)\n",
            "Loss_G = 7.63603449 (ave = 5.75910070)\n",
            "\n",
            "epoch: [91/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.553s / 10iters, (0.055)\tData load 0.093s / 10iters, (0.009299)\n",
            "Loss_D = 0.33880827 (ave = 0.35132960)\n",
            "Loss_G = 4.13317919 (ave = 5.56730817)\n",
            "\n",
            "epoch: [91/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.725s / 10iters, (0.072)\tData load 0.084s / 10iters, (0.008448)\n",
            "Loss_D = 0.02916456 (ave = 0.35641566)\n",
            "Loss_G = 5.29890156 (ave = 5.54622196)\n",
            "\n",
            "epoch: [91/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.550s / 10iters, (0.055)\tData load 0.072s / 10iters, (0.007180)\n",
            "Loss_D = 0.13876072 (ave = 0.33618978)\n",
            "Loss_G = 5.11743498 (ave = 5.39111070)\n",
            "\n",
            "epoch: [91/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.699s / 10iters, (0.070)\tData load 0.089s / 10iters, (0.008933)\n",
            "Loss_D = 0.60948098 (ave = 0.33604449)\n",
            "Loss_G = 6.27852631 (ave = 5.54857959)\n",
            "\n",
            "epoch: [91/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.643s / 10iters, (0.064)\tData load 0.056s / 10iters, (0.005623)\n",
            "Loss_D = 0.56872761 (ave = 0.32325004)\n",
            "Loss_G = 6.91931200 (ave = 5.54533277)\n",
            "\n",
            "epoch: [91/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.645s / 10iters, (0.064)\tData load 0.098s / 10iters, (0.009784)\n",
            "Loss_D = 0.36597288 (ave = 0.33663785)\n",
            "Loss_G = 5.86596632 (ave = 5.52948547)\n",
            "\n",
            "epoch: [91/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.585s / 10iters, (0.058)\tData load 0.074s / 10iters, (0.007413)\n",
            "Loss_D = 0.59560317 (ave = 0.34071487)\n",
            "Loss_G = 6.07186985 (ave = 5.60325397)\n",
            "\n",
            "epoch: [91/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.624s / 10iters, (0.062)\tData load 0.089s / 10iters, (0.008916)\n",
            "Loss_D = 0.37806135 (ave = 0.34114120)\n",
            "Loss_G = 6.07464933 (ave = 5.56943983)\n",
            "\n",
            "epoch: [91/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.665s / 10iters, (0.067)\tData load 0.086s / 10iters, (0.008628)\n",
            "Loss_D = 0.19881517 (ave = 0.33683706)\n",
            "Loss_G = 5.56352568 (ave = 5.59223411)\n",
            "\n",
            "epoch: [91/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.677s / 10iters, (0.068)\tData load 0.066s / 10iters, (0.006625)\n",
            "Loss_D = 0.47750181 (ave = 0.34202213)\n",
            "Loss_G = 4.99403715 (ave = 5.59178435)\n",
            "\n",
            "epoch: [91/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.582s / 10iters, (0.058)\tData load 0.071s / 10iters, (0.007106)\n",
            "Loss_D = 0.10326403 (ave = 0.34748827)\n",
            "Loss_G = 3.40429401 (ave = 5.60282995)\n",
            "\n",
            "epoch: [91/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.669s / 10iters, (0.067)\tData load 0.083s / 10iters, (0.008296)\n",
            "Loss_D = 0.59692407 (ave = 0.34238201)\n",
            "Loss_G = 9.74447823 (ave = 5.60290562)\n",
            "\n",
            "epoch: [91/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.687s / 10iters, (0.069)\tData load 0.084s / 10iters, (0.008364)\n",
            "Loss_D = 0.23439601 (ave = 0.35394860)\n",
            "Loss_G = 6.09019566 (ave = 5.62777168)\n",
            "\n",
            "epoch: [91/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.593s / 10iters, (0.059)\tData load 0.096s / 10iters, (0.009609)\n",
            "Loss_D = 0.11467104 (ave = 0.35484474)\n",
            "Loss_G = 2.80758452 (ave = 5.64809146)\n",
            "\n",
            "epoch: [91/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.588s / 10iters, (0.059)\tData load 0.089s / 10iters, (0.008930)\n",
            "Loss_D = 0.19810186 (ave = 0.35209426)\n",
            "Loss_G = 5.49631977 (ave = 5.65481154)\n",
            "\n",
            "epoch: [91/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.580s / 10iters, (0.058)\tData load 0.085s / 10iters, (0.008482)\n",
            "Loss_D = 0.23916516 (ave = 0.34962730)\n",
            "Loss_G = 5.09147310 (ave = 5.62149446)\n",
            "\n",
            "epoch: [91/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.624s / 10iters, (0.062)\tData load 0.082s / 10iters, (0.008152)\n",
            "Loss_D = 0.05626280 (ave = 0.35288129)\n",
            "Loss_G = 6.70318270 (ave = 5.64822503)\n",
            "\n",
            "epoch: [91/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.625s / 10iters, (0.062)\tData load 0.082s / 10iters, (0.008189)\n",
            "Loss_D = 0.43779260 (ave = 0.34808642)\n",
            "Loss_G = 5.71277332 (ave = 5.61085527)\n",
            "\n",
            "epoch: [91/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.600s / 10iters, (0.060)\tData load 0.064s / 10iters, (0.006444)\n",
            "Loss_D = 0.06935475 (ave = 0.34578261)\n",
            "Loss_G = 4.69020128 (ave = 5.60074104)\n",
            "\n",
            "epoch: [91/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.576s / 10iters, (0.058)\tData load 0.090s / 10iters, (0.008950)\n",
            "Loss_D = 0.13281716 (ave = 0.34010205)\n",
            "Loss_G = 4.28033733 (ave = 5.57853814)\n",
            "\n",
            "epoch: [91/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.322s / 10iters, (0.032)\tData load 0.055s / 10iters, (0.005506)\n",
            "Loss_D = 0.47191036 (ave = 0.33874416)\n",
            "Loss_G = 5.29861212 (ave = 5.58967167)\n",
            "\n",
            "epoch: [91/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.066s / 3iters, (0.022)\tData load 0.015s / 3iters, (0.005097)\n",
            "Loss_D = 0.21810043 (ave = 0.33898169)\n",
            "Loss_G = 6.06169367 (ave = 5.59299447)\n",
            "\n",
            "Real Accuracy : 93.61138695796095\n",
            "Fake Accuracy : 2.8136378682555447\n",
            "epoch: [92/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.092s / 10iters, (0.509)\tData load 4.388s / 10iters, (0.438808)\n",
            "Loss_D = 0.40715009 (ave = 0.32788987)\n",
            "Loss_G = 5.43868208 (ave = 5.77210720)\n",
            "\n",
            "epoch: [92/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.622s / 10iters, (0.062)\tData load 0.091s / 10iters, (0.009098)\n",
            "Loss_D = 0.06462959 (ave = 0.30341219)\n",
            "Loss_G = 6.84832287 (ave = 5.80197117)\n",
            "\n",
            "epoch: [92/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.643s / 10iters, (0.064)\tData load 0.074s / 10iters, (0.007403)\n",
            "Loss_D = 0.52084816 (ave = 0.31222788)\n",
            "Loss_G = 7.19589949 (ave = 5.59029369)\n",
            "\n",
            "epoch: [92/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.595s / 10iters, (0.060)\tData load 0.069s / 10iters, (0.006873)\n",
            "Loss_D = 0.31541109 (ave = 0.30557295)\n",
            "Loss_G = 6.10955143 (ave = 5.73238186)\n",
            "\n",
            "epoch: [92/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.569s / 10iters, (0.057)\tData load 0.067s / 10iters, (0.006744)\n",
            "Loss_D = 0.25853804 (ave = 0.31626268)\n",
            "Loss_G = 8.67525768 (ave = 5.81958975)\n",
            "\n",
            "epoch: [92/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.668s / 10iters, (0.067)\tData load 0.129s / 10iters, (0.012941)\n",
            "Loss_D = 0.98968029 (ave = 0.36157467)\n",
            "Loss_G = 6.07585239 (ave = 5.88708250)\n",
            "\n",
            "epoch: [92/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.623s / 10iters, (0.062)\tData load 0.076s / 10iters, (0.007639)\n",
            "Loss_D = 0.06080923 (ave = 0.40052573)\n",
            "Loss_G = 6.76136065 (ave = 6.02458630)\n",
            "\n",
            "epoch: [92/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.615s / 10iters, (0.062)\tData load 0.078s / 10iters, (0.007811)\n",
            "Loss_D = 0.28596199 (ave = 0.37352216)\n",
            "Loss_G = 5.07280779 (ave = 6.02641717)\n",
            "\n",
            "epoch: [92/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.616s / 10iters, (0.062)\tData load 0.091s / 10iters, (0.009064)\n",
            "Loss_D = 0.79269218 (ave = 0.37016819)\n",
            "Loss_G = 9.26546860 (ave = 6.00946898)\n",
            "\n",
            "epoch: [92/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.632s / 10iters, (0.063)\tData load 0.091s / 10iters, (0.009117)\n",
            "Loss_D = 0.32557428 (ave = 0.35690726)\n",
            "Loss_G = 4.50793362 (ave = 5.93360774)\n",
            "\n",
            "epoch: [92/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.595s / 10iters, (0.059)\tData load 0.092s / 10iters, (0.009166)\n",
            "Loss_D = 0.63966048 (ave = 0.35908580)\n",
            "Loss_G = 3.96265459 (ave = 5.91245143)\n",
            "\n",
            "epoch: [92/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.748s / 10iters, (0.075)\tData load 0.074s / 10iters, (0.007356)\n",
            "Loss_D = 0.36044312 (ave = 0.35165592)\n",
            "Loss_G = 4.52716684 (ave = 5.85911171)\n",
            "\n",
            "epoch: [92/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.578s / 10iters, (0.058)\tData load 0.064s / 10iters, (0.006413)\n",
            "Loss_D = 0.18964200 (ave = 0.33906602)\n",
            "Loss_G = 4.11126184 (ave = 5.79148201)\n",
            "\n",
            "epoch: [92/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.663s / 10iters, (0.066)\tData load 0.072s / 10iters, (0.007169)\n",
            "Loss_D = 0.17277139 (ave = 0.32986949)\n",
            "Loss_G = 5.02168703 (ave = 5.75745901)\n",
            "\n",
            "epoch: [92/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.643s / 10iters, (0.064)\tData load 0.063s / 10iters, (0.006327)\n",
            "Loss_D = 0.77815109 (ave = 0.32919875)\n",
            "Loss_G = 8.14284325 (ave = 5.77115004)\n",
            "\n",
            "epoch: [92/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.687s / 10iters, (0.069)\tData load 0.071s / 10iters, (0.007120)\n",
            "Loss_D = 0.29602593 (ave = 0.33007927)\n",
            "Loss_G = 5.90698957 (ave = 5.77705108)\n",
            "\n",
            "epoch: [92/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.590s / 10iters, (0.059)\tData load 0.100s / 10iters, (0.010000)\n",
            "Loss_D = 0.51549220 (ave = 0.32937788)\n",
            "Loss_G = 2.95273328 (ave = 5.75887359)\n",
            "\n",
            "epoch: [92/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.588s / 10iters, (0.059)\tData load 0.088s / 10iters, (0.008813)\n",
            "Loss_D = 0.03113869 (ave = 0.33317025)\n",
            "Loss_G = 5.20366478 (ave = 5.73718353)\n",
            "\n",
            "epoch: [92/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.602s / 10iters, (0.060)\tData load 0.117s / 10iters, (0.011654)\n",
            "Loss_D = 0.24019365 (ave = 0.34965627)\n",
            "Loss_G = 6.85919380 (ave = 5.77058204)\n",
            "\n",
            "epoch: [92/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.629s / 10iters, (0.063)\tData load 0.060s / 10iters, (0.006014)\n",
            "Loss_D = 0.23601428 (ave = 0.34747013)\n",
            "Loss_G = 4.62233639 (ave = 5.74450465)\n",
            "\n",
            "epoch: [92/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.656s / 10iters, (0.066)\tData load 0.060s / 10iters, (0.006022)\n",
            "Loss_D = 0.33916682 (ave = 0.34261881)\n",
            "Loss_G = 5.37895155 (ave = 5.73361407)\n",
            "\n",
            "epoch: [92/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.586s / 10iters, (0.059)\tData load 0.064s / 10iters, (0.006351)\n",
            "Loss_D = 0.74623609 (ave = 0.34478078)\n",
            "Loss_G = 6.99554253 (ave = 5.73476673)\n",
            "\n",
            "epoch: [92/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.354s / 10iters, (0.035)\tData load 0.064s / 10iters, (0.006356)\n",
            "Loss_D = 0.51454699 (ave = 0.34073431)\n",
            "Loss_G = 4.05415630 (ave = 5.70876146)\n",
            "\n",
            "epoch: [92/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.066s / 3iters, (0.022)\tData load 0.014s / 3iters, (0.004663)\n",
            "Loss_D = 0.22839347 (ave = 0.33859300)\n",
            "Loss_G = 7.35099649 (ave = 5.70751629)\n",
            "\n",
            "Real Accuracy : 93.54518371400198\n",
            "Fake Accuracy : 2.7143330023171135\n",
            "epoch: [93/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 4.964s / 10iters, (0.496)\tData load 4.241s / 10iters, (0.424062)\n",
            "Loss_D = 0.33774880 (ave = 0.23228875)\n",
            "Loss_G = 5.93494177 (ave = 5.89533482)\n",
            "\n",
            "epoch: [93/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.657s / 10iters, (0.066)\tData load 0.105s / 10iters, (0.010458)\n",
            "Loss_D = 0.27540225 (ave = 0.25849131)\n",
            "Loss_G = 6.74241590 (ave = 5.86428268)\n",
            "\n",
            "epoch: [93/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.652s / 10iters, (0.065)\tData load 0.094s / 10iters, (0.009360)\n",
            "Loss_D = 0.09014525 (ave = 0.30813162)\n",
            "Loss_G = 3.94231009 (ave = 5.79436522)\n",
            "\n",
            "epoch: [93/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.582s / 10iters, (0.058)\tData load 0.095s / 10iters, (0.009547)\n",
            "Loss_D = 0.47995967 (ave = 0.35540200)\n",
            "Loss_G = 5.02850008 (ave = 5.84460229)\n",
            "\n",
            "epoch: [93/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.657s / 10iters, (0.066)\tData load 0.104s / 10iters, (0.010358)\n",
            "Loss_D = 0.37825492 (ave = 0.34108678)\n",
            "Loss_G = 5.23447609 (ave = 5.76460548)\n",
            "\n",
            "epoch: [93/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.574s / 10iters, (0.057)\tData load 0.101s / 10iters, (0.010149)\n",
            "Loss_D = 0.17395259 (ave = 0.31467912)\n",
            "Loss_G = 4.38792467 (ave = 5.62373081)\n",
            "\n",
            "epoch: [93/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.562s / 10iters, (0.056)\tData load 0.091s / 10iters, (0.009132)\n",
            "Loss_D = 0.26329982 (ave = 0.32399164)\n",
            "Loss_G = 2.32999134 (ave = 5.56726549)\n",
            "\n",
            "epoch: [93/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.687s / 10iters, (0.069)\tData load 0.087s / 10iters, (0.008734)\n",
            "Loss_D = 0.41491398 (ave = 0.33362913)\n",
            "Loss_G = 4.68214989 (ave = 5.48284698)\n",
            "\n",
            "epoch: [93/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.562s / 10iters, (0.056)\tData load 0.091s / 10iters, (0.009099)\n",
            "Loss_D = 0.46152070 (ave = 0.35393647)\n",
            "Loss_G = 6.82297754 (ave = 5.51457564)\n",
            "\n",
            "epoch: [93/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.647s / 10iters, (0.065)\tData load 0.097s / 10iters, (0.009708)\n",
            "Loss_D = 0.33925653 (ave = 0.34682400)\n",
            "Loss_G = 5.16061974 (ave = 5.49502881)\n",
            "\n",
            "epoch: [93/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.595s / 10iters, (0.060)\tData load 0.072s / 10iters, (0.007151)\n",
            "Loss_D = 0.17713508 (ave = 0.33999836)\n",
            "Loss_G = 3.01754165 (ave = 5.44847201)\n",
            "\n",
            "epoch: [93/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.681s / 10iters, (0.068)\tData load 0.056s / 10iters, (0.005560)\n",
            "Loss_D = 0.20709440 (ave = 0.33708436)\n",
            "Loss_G = 5.67807102 (ave = 5.49370546)\n",
            "\n",
            "epoch: [93/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.634s / 10iters, (0.063)\tData load 0.065s / 10iters, (0.006534)\n",
            "Loss_D = 0.58039939 (ave = 0.33382908)\n",
            "Loss_G = 3.43073034 (ave = 5.50991143)\n",
            "\n",
            "epoch: [93/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.623s / 10iters, (0.062)\tData load 0.079s / 10iters, (0.007871)\n",
            "Loss_D = 0.12430781 (ave = 0.34336181)\n",
            "Loss_G = 4.85577726 (ave = 5.53081978)\n",
            "\n",
            "epoch: [93/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.655s / 10iters, (0.066)\tData load 0.073s / 10iters, (0.007299)\n",
            "Loss_D = 0.11506215 (ave = 0.34981832)\n",
            "Loss_G = 3.54726124 (ave = 5.54445827)\n",
            "\n",
            "epoch: [93/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.594s / 10iters, (0.059)\tData load 0.078s / 10iters, (0.007757)\n",
            "Loss_D = 0.39567161 (ave = 0.35147651)\n",
            "Loss_G = 4.67614079 (ave = 5.57615621)\n",
            "\n",
            "epoch: [93/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.580s / 10iters, (0.058)\tData load 0.060s / 10iters, (0.006012)\n",
            "Loss_D = 0.63596529 (ave = 0.35522549)\n",
            "Loss_G = 5.59549236 (ave = 5.57992661)\n",
            "\n",
            "epoch: [93/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.606s / 10iters, (0.061)\tData load 0.083s / 10iters, (0.008337)\n",
            "Loss_D = 0.30755392 (ave = 0.35487293)\n",
            "Loss_G = 5.55657625 (ave = 5.59457046)\n",
            "\n",
            "epoch: [93/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.625s / 10iters, (0.062)\tData load 0.071s / 10iters, (0.007115)\n",
            "Loss_D = 0.68858016 (ave = 0.37311088)\n",
            "Loss_G = 6.91100788 (ave = 5.58522859)\n",
            "\n",
            "epoch: [93/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.593s / 10iters, (0.059)\tData load 0.085s / 10iters, (0.008535)\n",
            "Loss_D = 0.12607865 (ave = 0.36938360)\n",
            "Loss_G = 6.63745689 (ave = 5.57981313)\n",
            "\n",
            "epoch: [93/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.620s / 10iters, (0.062)\tData load 0.062s / 10iters, (0.006237)\n",
            "Loss_D = 0.23796509 (ave = 0.37243099)\n",
            "Loss_G = 4.68683195 (ave = 5.57472081)\n",
            "\n",
            "epoch: [93/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.590s / 10iters, (0.059)\tData load 0.088s / 10iters, (0.008835)\n",
            "Loss_D = 0.17935629 (ave = 0.36634166)\n",
            "Loss_G = 5.63912249 (ave = 5.56585765)\n",
            "\n",
            "epoch: [93/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.346s / 10iters, (0.035)\tData load 0.066s / 10iters, (0.006566)\n",
            "Loss_D = 0.08573659 (ave = 0.36114218)\n",
            "Loss_G = 5.26797581 (ave = 5.52672145)\n",
            "\n",
            "epoch: [93/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.068s / 3iters, (0.023)\tData load 0.013s / 3iters, (0.004252)\n",
            "Loss_D = 0.17206456 (ave = 0.36024204)\n",
            "Loss_G = 7.44062328 (ave = 5.52423334)\n",
            "\n",
            "Real Accuracy : 93.11486262826878\n",
            "Fake Accuracy : 2.7474346242965906\n",
            "epoch: [94/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 4.897s / 10iters, (0.490)\tData load 4.350s / 10iters, (0.435045)\n",
            "Loss_D = 0.91088611 (ave = 0.24322027)\n",
            "Loss_G = 3.88427305 (ave = 5.21364870)\n",
            "\n",
            "epoch: [94/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.668s / 10iters, (0.067)\tData load 0.105s / 10iters, (0.010490)\n",
            "Loss_D = 0.43369329 (ave = 0.34809051)\n",
            "Loss_G = 6.89128447 (ave = 5.33720009)\n",
            "\n",
            "epoch: [94/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.640s / 10iters, (0.064)\tData load 0.065s / 10iters, (0.006510)\n",
            "Loss_D = 0.05678029 (ave = 0.30224323)\n",
            "Loss_G = 2.80656576 (ave = 5.35336717)\n",
            "\n",
            "epoch: [94/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.585s / 10iters, (0.058)\tData load 0.080s / 10iters, (0.008008)\n",
            "Loss_D = 0.14872552 (ave = 0.30744195)\n",
            "Loss_G = 6.56066370 (ave = 5.51368475)\n",
            "\n",
            "epoch: [94/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.610s / 10iters, (0.061)\tData load 0.075s / 10iters, (0.007472)\n",
            "Loss_D = 0.33549452 (ave = 0.30370396)\n",
            "Loss_G = 6.53113651 (ave = 5.52216009)\n",
            "\n",
            "epoch: [94/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.635s / 10iters, (0.063)\tData load 0.099s / 10iters, (0.009855)\n",
            "Loss_D = 0.16251174 (ave = 0.30852258)\n",
            "Loss_G = 5.55918980 (ave = 5.63281536)\n",
            "\n",
            "epoch: [94/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.591s / 10iters, (0.059)\tData load 0.066s / 10iters, (0.006575)\n",
            "Loss_D = 0.34207219 (ave = 0.29396075)\n",
            "Loss_G = 6.00330544 (ave = 5.63037242)\n",
            "\n",
            "epoch: [94/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.551s / 10iters, (0.055)\tData load 0.093s / 10iters, (0.009331)\n",
            "Loss_D = 0.16979425 (ave = 0.29269357)\n",
            "Loss_G = 4.55088377 (ave = 5.57480096)\n",
            "\n",
            "epoch: [94/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.687s / 10iters, (0.069)\tData load 0.117s / 10iters, (0.011749)\n",
            "Loss_D = 0.24024944 (ave = 0.28444777)\n",
            "Loss_G = 3.59211564 (ave = 5.58370431)\n",
            "\n",
            "epoch: [94/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.566s / 10iters, (0.057)\tData load 0.084s / 10iters, (0.008409)\n",
            "Loss_D = 0.03499890 (ave = 0.27616396)\n",
            "Loss_G = 7.41539478 (ave = 5.54284339)\n",
            "\n",
            "epoch: [94/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.644s / 10iters, (0.064)\tData load 0.086s / 10iters, (0.008556)\n",
            "Loss_D = 0.29601598 (ave = 0.26649754)\n",
            "Loss_G = 5.09430504 (ave = 5.47406651)\n",
            "\n",
            "epoch: [94/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.639s / 10iters, (0.064)\tData load 0.090s / 10iters, (0.008952)\n",
            "Loss_D = 0.05441900 (ave = 0.27368736)\n",
            "Loss_G = 4.60146952 (ave = 5.53453732)\n",
            "\n",
            "epoch: [94/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.696s / 10iters, (0.070)\tData load 0.090s / 10iters, (0.009038)\n",
            "Loss_D = 0.24988572 (ave = 0.27851382)\n",
            "Loss_G = 4.14787531 (ave = 5.49532906)\n",
            "\n",
            "epoch: [94/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.589s / 10iters, (0.059)\tData load 0.087s / 10iters, (0.008740)\n",
            "Loss_D = 0.22415441 (ave = 0.26999654)\n",
            "Loss_G = 5.15610838 (ave = 5.48882216)\n",
            "\n",
            "epoch: [94/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.677s / 10iters, (0.068)\tData load 0.088s / 10iters, (0.008848)\n",
            "Loss_D = 0.04550686 (ave = 0.27014244)\n",
            "Loss_G = 5.32990599 (ave = 5.52469642)\n",
            "\n",
            "epoch: [94/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.651s / 10iters, (0.065)\tData load 0.059s / 10iters, (0.005869)\n",
            "Loss_D = 0.27853578 (ave = 0.27411196)\n",
            "Loss_G = 4.69884253 (ave = 5.51171085)\n",
            "\n",
            "epoch: [94/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.586s / 10iters, (0.059)\tData load 0.058s / 10iters, (0.005800)\n",
            "Loss_D = 0.43177536 (ave = 0.27575930)\n",
            "Loss_G = 5.73780298 (ave = 5.51016487)\n",
            "\n",
            "epoch: [94/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.687s / 10iters, (0.069)\tData load 0.064s / 10iters, (0.006397)\n",
            "Loss_D = 0.11436786 (ave = 0.27146494)\n",
            "Loss_G = 6.44229364 (ave = 5.51230560)\n",
            "\n",
            "epoch: [94/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.649s / 10iters, (0.065)\tData load 0.076s / 10iters, (0.007647)\n",
            "Loss_D = 0.58961052 (ave = 0.26892659)\n",
            "Loss_G = 4.42285252 (ave = 5.48965580)\n",
            "\n",
            "epoch: [94/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.643s / 10iters, (0.064)\tData load 0.074s / 10iters, (0.007404)\n",
            "Loss_D = 0.15763256 (ave = 0.26476634)\n",
            "Loss_G = 5.21019220 (ave = 5.45624300)\n",
            "\n",
            "epoch: [94/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.580s / 10iters, (0.058)\tData load 0.075s / 10iters, (0.007477)\n",
            "Loss_D = 0.15038991 (ave = 0.26243359)\n",
            "Loss_G = 2.97447181 (ave = 5.42481844)\n",
            "\n",
            "epoch: [94/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.624s / 10iters, (0.062)\tData load 0.098s / 10iters, (0.009779)\n",
            "Loss_D = 0.79421484 (ave = 0.26219574)\n",
            "Loss_G = 8.61418343 (ave = 5.45124913)\n",
            "\n",
            "epoch: [94/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.344s / 10iters, (0.034)\tData load 0.062s / 10iters, (0.006243)\n",
            "Loss_D = 0.28069231 (ave = 0.26296579)\n",
            "Loss_G = 5.72740078 (ave = 5.47668606)\n",
            "\n",
            "epoch: [94/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.065s / 3iters, (0.022)\tData load 0.016s / 3iters, (0.005389)\n",
            "Loss_D = 0.61230761 (ave = 0.26319528)\n",
            "Loss_G = 2.68561363 (ave = 5.45784718)\n",
            "\n",
            "Real Accuracy : 95.43197616683217\n",
            "Fake Accuracy : 2.0854021847070507\n",
            "epoch: [95/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.117s / 10iters, (0.512)\tData load 4.316s / 10iters, (0.431617)\n",
            "Loss_D = 0.02430123 (ave = 0.17992738)\n",
            "Loss_G = 5.12349272 (ave = 5.75105333)\n",
            "\n",
            "epoch: [95/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.671s / 10iters, (0.067)\tData load 0.058s / 10iters, (0.005832)\n",
            "Loss_D = 0.15455389 (ave = 0.19115829)\n",
            "Loss_G = 6.83761311 (ave = 5.68681533)\n",
            "\n",
            "epoch: [95/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.658s / 10iters, (0.066)\tData load 0.089s / 10iters, (0.008859)\n",
            "Loss_D = 0.95099491 (ave = 0.27115242)\n",
            "Loss_G = 9.60206509 (ave = 5.67506973)\n",
            "\n",
            "epoch: [95/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.598s / 10iters, (0.060)\tData load 0.087s / 10iters, (0.008679)\n",
            "Loss_D = 0.33551306 (ave = 0.29692719)\n",
            "Loss_G = 7.03030634 (ave = 5.85485654)\n",
            "\n",
            "epoch: [95/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.612s / 10iters, (0.061)\tData load 0.098s / 10iters, (0.009815)\n",
            "Loss_D = 0.71969074 (ave = 0.32997284)\n",
            "Loss_G = 4.67871952 (ave = 5.79392535)\n",
            "\n",
            "epoch: [95/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.613s / 10iters, (0.061)\tData load 0.077s / 10iters, (0.007681)\n",
            "Loss_D = 0.65669787 (ave = 0.35432626)\n",
            "Loss_G = 8.53897572 (ave = 5.99051432)\n",
            "\n",
            "epoch: [95/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.595s / 10iters, (0.060)\tData load 0.068s / 10iters, (0.006822)\n",
            "Loss_D = 0.09585391 (ave = 0.36662592)\n",
            "Loss_G = 4.74025059 (ave = 5.95417070)\n",
            "\n",
            "epoch: [95/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.709s / 10iters, (0.071)\tData load 0.105s / 10iters, (0.010543)\n",
            "Loss_D = 0.64281350 (ave = 0.36621454)\n",
            "Loss_G = 7.36367893 (ave = 5.91829329)\n",
            "\n",
            "epoch: [95/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.614s / 10iters, (0.061)\tData load 0.067s / 10iters, (0.006703)\n",
            "Loss_D = 0.08994234 (ave = 0.35864830)\n",
            "Loss_G = 6.95983601 (ave = 5.96209140)\n",
            "\n",
            "epoch: [95/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.600s / 10iters, (0.060)\tData load 0.068s / 10iters, (0.006778)\n",
            "Loss_D = 0.15059666 (ave = 0.34974403)\n",
            "Loss_G = 6.43047905 (ave = 6.00208921)\n",
            "\n",
            "epoch: [95/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.571s / 10iters, (0.057)\tData load 0.067s / 10iters, (0.006690)\n",
            "Loss_D = 0.19398697 (ave = 0.35549298)\n",
            "Loss_G = 6.81194258 (ave = 5.98348040)\n",
            "\n",
            "epoch: [95/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.650s / 10iters, (0.065)\tData load 0.120s / 10iters, (0.011992)\n",
            "Loss_D = 0.39218453 (ave = 0.35051712)\n",
            "Loss_G = 6.05955744 (ave = 5.98023351)\n",
            "\n",
            "epoch: [95/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.627s / 10iters, (0.063)\tData load 0.064s / 10iters, (0.006424)\n",
            "Loss_D = 0.66561115 (ave = 0.34229366)\n",
            "Loss_G = 3.23013473 (ave = 5.88487806)\n",
            "\n",
            "epoch: [95/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.635s / 10iters, (0.064)\tData load 0.054s / 10iters, (0.005361)\n",
            "Loss_D = 0.12686597 (ave = 0.34583088)\n",
            "Loss_G = 6.01579762 (ave = 5.92294639)\n",
            "\n",
            "epoch: [95/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.654s / 10iters, (0.065)\tData load 0.070s / 10iters, (0.006985)\n",
            "Loss_D = 0.08631808 (ave = 0.34598603)\n",
            "Loss_G = 7.44662189 (ave = 5.90488678)\n",
            "\n",
            "epoch: [95/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.583s / 10iters, (0.058)\tData load 0.092s / 10iters, (0.009168)\n",
            "Loss_D = 0.50302517 (ave = 0.34670672)\n",
            "Loss_G = 4.01782322 (ave = 5.87174642)\n",
            "\n",
            "epoch: [95/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.537s / 10iters, (0.054)\tData load 0.070s / 10iters, (0.006984)\n",
            "Loss_D = 0.33299974 (ave = 0.33514309)\n",
            "Loss_G = 5.87189484 (ave = 5.86470340)\n",
            "\n",
            "epoch: [95/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.655s / 10iters, (0.065)\tData load 0.106s / 10iters, (0.010569)\n",
            "Loss_D = 0.09951124 (ave = 0.33545651)\n",
            "Loss_G = 3.94459057 (ave = 5.84402841)\n",
            "\n",
            "epoch: [95/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.574s / 10iters, (0.057)\tData load 0.068s / 10iters, (0.006780)\n",
            "Loss_D = 0.96599054 (ave = 0.33433128)\n",
            "Loss_G = 4.88617659 (ave = 5.83635099)\n",
            "\n",
            "epoch: [95/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.596s / 10iters, (0.060)\tData load 0.083s / 10iters, (0.008270)\n",
            "Loss_D = 0.15269729 (ave = 0.33167925)\n",
            "Loss_G = 6.16831446 (ave = 5.82056314)\n",
            "\n",
            "epoch: [95/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.659s / 10iters, (0.066)\tData load 0.100s / 10iters, (0.009968)\n",
            "Loss_D = 0.16948073 (ave = 0.32939521)\n",
            "Loss_G = 6.56571770 (ave = 5.81484354)\n",
            "\n",
            "epoch: [95/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.696s / 10iters, (0.070)\tData load 0.052s / 10iters, (0.005239)\n",
            "Loss_D = 0.19456413 (ave = 0.33307279)\n",
            "Loss_G = 5.26243496 (ave = 5.82712724)\n",
            "\n",
            "epoch: [95/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.346s / 10iters, (0.035)\tData load 0.056s / 10iters, (0.005567)\n",
            "Loss_D = 0.16561466 (ave = 0.32878292)\n",
            "Loss_G = 3.45935082 (ave = 5.79453654)\n",
            "\n",
            "epoch: [95/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.071s / 3iters, (0.024)\tData load 0.014s / 3iters, (0.004703)\n",
            "Loss_D = 1.09756410 (ave = 0.33115422)\n",
            "Loss_G = 2.12271166 (ave = 5.78861045)\n",
            "\n",
            "Real Accuracy : 93.57828533598146\n",
            "Fake Accuracy : 2.9460443561734526\n",
            "epoch: [96/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.094s / 10iters, (0.509)\tData load 4.362s / 10iters, (0.436181)\n",
            "Loss_D = 0.20111507 (ave = 0.28176844)\n",
            "Loss_G = 4.53584671 (ave = 5.57486820)\n",
            "\n",
            "epoch: [96/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.629s / 10iters, (0.063)\tData load 0.088s / 10iters, (0.008763)\n",
            "Loss_D = 0.04009189 (ave = 0.34160060)\n",
            "Loss_G = 7.89341640 (ave = 6.03029981)\n",
            "\n",
            "epoch: [96/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.636s / 10iters, (0.064)\tData load 0.091s / 10iters, (0.009111)\n",
            "Loss_D = 0.52391499 (ave = 0.34109079)\n",
            "Loss_G = 6.70586586 (ave = 6.18029838)\n",
            "\n",
            "epoch: [96/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.628s / 10iters, (0.063)\tData load 0.095s / 10iters, (0.009493)\n",
            "Loss_D = 0.35546520 (ave = 0.31925282)\n",
            "Loss_G = 4.47840166 (ave = 6.02201679)\n",
            "\n",
            "epoch: [96/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.595s / 10iters, (0.059)\tData load 0.066s / 10iters, (0.006569)\n",
            "Loss_D = 0.71188092 (ave = 0.30887840)\n",
            "Loss_G = 7.68722630 (ave = 5.90865825)\n",
            "\n",
            "epoch: [96/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.664s / 10iters, (0.066)\tData load 0.069s / 10iters, (0.006911)\n",
            "Loss_D = 0.25207511 (ave = 0.32148883)\n",
            "Loss_G = 7.43175507 (ave = 5.90830032)\n",
            "\n",
            "epoch: [96/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.640s / 10iters, (0.064)\tData load 0.066s / 10iters, (0.006633)\n",
            "Loss_D = 0.30775699 (ave = 0.31949656)\n",
            "Loss_G = 4.98761272 (ave = 5.88269765)\n",
            "\n",
            "epoch: [96/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.599s / 10iters, (0.060)\tData load 0.084s / 10iters, (0.008398)\n",
            "Loss_D = 0.30049387 (ave = 0.33211096)\n",
            "Loss_G = 5.59111261 (ave = 5.79207703)\n",
            "\n",
            "epoch: [96/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.590s / 10iters, (0.059)\tData load 0.091s / 10iters, (0.009146)\n",
            "Loss_D = 0.45241767 (ave = 0.33618936)\n",
            "Loss_G = 5.85034990 (ave = 5.79684739)\n",
            "\n",
            "epoch: [96/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.661s / 10iters, (0.066)\tData load 0.076s / 10iters, (0.007570)\n",
            "Loss_D = 0.23216745 (ave = 0.32857044)\n",
            "Loss_G = 7.29834318 (ave = 5.81571806)\n",
            "\n",
            "epoch: [96/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.569s / 10iters, (0.057)\tData load 0.095s / 10iters, (0.009468)\n",
            "Loss_D = 0.08533278 (ave = 0.32731974)\n",
            "Loss_G = 7.34337187 (ave = 5.80402191)\n",
            "\n",
            "epoch: [96/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.609s / 10iters, (0.061)\tData load 0.114s / 10iters, (0.011369)\n",
            "Loss_D = 0.30617505 (ave = 0.32432437)\n",
            "Loss_G = 6.26871300 (ave = 5.76628311)\n",
            "\n",
            "epoch: [96/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.641s / 10iters, (0.064)\tData load 0.100s / 10iters, (0.010022)\n",
            "Loss_D = 0.09250899 (ave = 0.32344521)\n",
            "Loss_G = 4.44699717 (ave = 5.78772163)\n",
            "\n",
            "epoch: [96/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.669s / 10iters, (0.067)\tData load 0.060s / 10iters, (0.006016)\n",
            "Loss_D = 0.37042072 (ave = 0.31817975)\n",
            "Loss_G = 6.59371233 (ave = 5.77644561)\n",
            "\n",
            "epoch: [96/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.616s / 10iters, (0.062)\tData load 0.078s / 10iters, (0.007831)\n",
            "Loss_D = 0.19044706 (ave = 0.31240645)\n",
            "Loss_G = 5.61757135 (ave = 5.73801140)\n",
            "\n",
            "epoch: [96/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.728s / 10iters, (0.073)\tData load 0.076s / 10iters, (0.007609)\n",
            "Loss_D = 0.34773588 (ave = 0.31135502)\n",
            "Loss_G = 3.22524047 (ave = 5.74068126)\n",
            "\n",
            "epoch: [96/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.612s / 10iters, (0.061)\tData load 0.069s / 10iters, (0.006889)\n",
            "Loss_D = 0.11930092 (ave = 0.31243542)\n",
            "Loss_G = 4.64301205 (ave = 5.75216006)\n",
            "\n",
            "epoch: [96/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.663s / 10iters, (0.066)\tData load 0.075s / 10iters, (0.007511)\n",
            "Loss_D = 0.40288067 (ave = 0.31579363)\n",
            "Loss_G = 5.76875210 (ave = 5.73865808)\n",
            "\n",
            "epoch: [96/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.640s / 10iters, (0.064)\tData load 0.056s / 10iters, (0.005608)\n",
            "Loss_D = 0.50324523 (ave = 0.31567205)\n",
            "Loss_G = 6.26671124 (ave = 5.75912037)\n",
            "\n",
            "epoch: [96/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.617s / 10iters, (0.062)\tData load 0.058s / 10iters, (0.005803)\n",
            "Loss_D = 0.12982213 (ave = 0.31128405)\n",
            "Loss_G = 5.60317469 (ave = 5.74515504)\n",
            "\n",
            "epoch: [96/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.595s / 10iters, (0.060)\tData load 0.081s / 10iters, (0.008052)\n",
            "Loss_D = 0.05737489 (ave = 0.31115342)\n",
            "Loss_G = 6.70795202 (ave = 5.74074098)\n",
            "\n",
            "epoch: [96/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.686s / 10iters, (0.069)\tData load 0.083s / 10iters, (0.008292)\n",
            "Loss_D = 0.12492719 (ave = 0.30939076)\n",
            "Loss_G = 5.01606750 (ave = 5.71235688)\n",
            "\n",
            "epoch: [96/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.298s / 10iters, (0.030)\tData load 0.046s / 10iters, (0.004586)\n",
            "Loss_D = 1.24820507 (ave = 0.30993190)\n",
            "Loss_G = 4.69440174 (ave = 5.72409989)\n",
            "\n",
            "epoch: [96/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.070s / 3iters, (0.023)\tData load 0.014s / 3iters, (0.004756)\n",
            "Loss_D = 0.51221037 (ave = 0.30966327)\n",
            "Loss_G = 5.33289242 (ave = 5.71009371)\n",
            "\n",
            "Real Accuracy : 93.97550479973519\n",
            "Fake Accuracy : 2.284011916583913\n",
            "epoch: [97/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.154s / 10iters, (0.515)\tData load 4.346s / 10iters, (0.434578)\n",
            "Loss_D = 0.15622246 (ave = 0.25681830)\n",
            "Loss_G = 5.15407562 (ave = 6.00397387)\n",
            "\n",
            "epoch: [97/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.662s / 10iters, (0.066)\tData load 0.082s / 10iters, (0.008163)\n",
            "Loss_D = 0.24557829 (ave = 0.23030307)\n",
            "Loss_G = 4.12094975 (ave = 5.86559908)\n",
            "\n",
            "epoch: [97/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.598s / 10iters, (0.060)\tData load 0.084s / 10iters, (0.008351)\n",
            "Loss_D = 0.20817767 (ave = 0.25102430)\n",
            "Loss_G = 6.98936987 (ave = 6.10673151)\n",
            "\n",
            "epoch: [97/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.606s / 10iters, (0.061)\tData load 0.077s / 10iters, (0.007700)\n",
            "Loss_D = 0.09286557 (ave = 0.26035833)\n",
            "Loss_G = 7.21797991 (ave = 6.02165616)\n",
            "\n",
            "epoch: [97/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.606s / 10iters, (0.061)\tData load 0.077s / 10iters, (0.007713)\n",
            "Loss_D = 0.15605786 (ave = 0.27972697)\n",
            "Loss_G = 5.48636055 (ave = 5.97845026)\n",
            "\n",
            "epoch: [97/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.631s / 10iters, (0.063)\tData load 0.055s / 10iters, (0.005468)\n",
            "Loss_D = 0.18456246 (ave = 0.29175955)\n",
            "Loss_G = 5.37862206 (ave = 6.03848681)\n",
            "\n",
            "epoch: [97/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.618s / 10iters, (0.062)\tData load 0.081s / 10iters, (0.008058)\n",
            "Loss_D = 0.73520315 (ave = 0.29739141)\n",
            "Loss_G = 6.03371096 (ave = 6.07019741)\n",
            "\n",
            "epoch: [97/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.610s / 10iters, (0.061)\tData load 0.072s / 10iters, (0.007151)\n",
            "Loss_D = 0.22579806 (ave = 0.28886879)\n",
            "Loss_G = 3.86988425 (ave = 5.98810016)\n",
            "\n",
            "epoch: [97/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.656s / 10iters, (0.066)\tData load 0.110s / 10iters, (0.010965)\n",
            "Loss_D = 0.24925774 (ave = 0.29748254)\n",
            "Loss_G = 5.01929760 (ave = 5.91065623)\n",
            "\n",
            "epoch: [97/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.530s / 10iters, (0.053)\tData load 0.082s / 10iters, (0.008202)\n",
            "Loss_D = 0.18328415 (ave = 0.30123942)\n",
            "Loss_G = 4.66487932 (ave = 5.95991887)\n",
            "\n",
            "epoch: [97/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.671s / 10iters, (0.067)\tData load 0.084s / 10iters, (0.008428)\n",
            "Loss_D = 0.04441988 (ave = 0.28914009)\n",
            "Loss_G = 4.47028160 (ave = 5.90095010)\n",
            "\n",
            "epoch: [97/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.635s / 10iters, (0.063)\tData load 0.077s / 10iters, (0.007713)\n",
            "Loss_D = 0.26550737 (ave = 0.29374205)\n",
            "Loss_G = 6.86722612 (ave = 5.86219167)\n",
            "\n",
            "epoch: [97/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.633s / 10iters, (0.063)\tData load 0.095s / 10iters, (0.009510)\n",
            "Loss_D = 0.01542762 (ave = 0.28799548)\n",
            "Loss_G = 5.89287329 (ave = 5.82412922)\n",
            "\n",
            "epoch: [97/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.589s / 10iters, (0.059)\tData load 0.088s / 10iters, (0.008834)\n",
            "Loss_D = 0.40789747 (ave = 0.28508990)\n",
            "Loss_G = 5.05508137 (ave = 5.74025664)\n",
            "\n",
            "epoch: [97/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.634s / 10iters, (0.063)\tData load 0.076s / 10iters, (0.007606)\n",
            "Loss_D = 0.32512128 (ave = 0.28759001)\n",
            "Loss_G = 4.60673904 (ave = 5.72593954)\n",
            "\n",
            "epoch: [97/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.629s / 10iters, (0.063)\tData load 0.064s / 10iters, (0.006376)\n",
            "Loss_D = 0.37480089 (ave = 0.28580886)\n",
            "Loss_G = 3.81319475 (ave = 5.71228775)\n",
            "\n",
            "epoch: [97/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.652s / 10iters, (0.065)\tData load 0.077s / 10iters, (0.007733)\n",
            "Loss_D = 0.50634569 (ave = 0.28976688)\n",
            "Loss_G = 5.52528715 (ave = 5.74292044)\n",
            "\n",
            "epoch: [97/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.668s / 10iters, (0.067)\tData load 0.069s / 10iters, (0.006941)\n",
            "Loss_D = 0.35612831 (ave = 0.28630744)\n",
            "Loss_G = 9.19407940 (ave = 5.72108935)\n",
            "\n",
            "epoch: [97/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.566s / 10iters, (0.057)\tData load 0.093s / 10iters, (0.009324)\n",
            "Loss_D = 0.02151214 (ave = 0.29115186)\n",
            "Loss_G = 6.90428734 (ave = 5.72080889)\n",
            "\n",
            "epoch: [97/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.604s / 10iters, (0.060)\tData load 0.084s / 10iters, (0.008355)\n",
            "Loss_D = 0.08591618 (ave = 0.28407627)\n",
            "Loss_G = 4.40711546 (ave = 5.70719293)\n",
            "\n",
            "epoch: [97/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.638s / 10iters, (0.064)\tData load 0.097s / 10iters, (0.009735)\n",
            "Loss_D = 0.09801430 (ave = 0.28831726)\n",
            "Loss_G = 6.00492048 (ave = 5.69815389)\n",
            "\n",
            "epoch: [97/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.609s / 10iters, (0.061)\tData load 0.096s / 10iters, (0.009593)\n",
            "Loss_D = 0.32745975 (ave = 0.29052390)\n",
            "Loss_G = 7.65588570 (ave = 5.70736444)\n",
            "\n",
            "epoch: [97/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.292s / 10iters, (0.029)\tData load 0.056s / 10iters, (0.005608)\n",
            "Loss_D = 0.13057399 (ave = 0.29144037)\n",
            "Loss_G = 6.14515638 (ave = 5.70863066)\n",
            "\n",
            "epoch: [97/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.069s / 3iters, (0.023)\tData load 0.015s / 3iters, (0.005142)\n",
            "Loss_D = 0.55222845 (ave = 0.29176933)\n",
            "Loss_G = 4.31878901 (ave = 5.70643923)\n",
            "\n",
            "Real Accuracy : 94.40582588546839\n",
            "Fake Accuracy : 2.4495200264812977\n",
            "epoch: [98/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.033s / 10iters, (0.503)\tData load 4.306s / 10iters, (0.430589)\n",
            "Loss_D = 0.15662333 (ave = 0.56573748)\n",
            "Loss_G = 7.74173164 (ave = 6.20401716)\n",
            "\n",
            "epoch: [98/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.622s / 10iters, (0.062)\tData load 0.077s / 10iters, (0.007731)\n",
            "Loss_D = 0.28230250 (ave = 0.41190810)\n",
            "Loss_G = 5.49014091 (ave = 5.82464229)\n",
            "\n",
            "epoch: [98/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.633s / 10iters, (0.063)\tData load 0.063s / 10iters, (0.006296)\n",
            "Loss_D = 0.36583456 (ave = 0.47619963)\n",
            "Loss_G = 4.05650282 (ave = 5.69085810)\n",
            "\n",
            "epoch: [98/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.573s / 10iters, (0.057)\tData load 0.058s / 10iters, (0.005757)\n",
            "Loss_D = 0.25934523 (ave = 0.55527327)\n",
            "Loss_G = 3.06518149 (ave = 5.63936653)\n",
            "\n",
            "epoch: [98/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.689s / 10iters, (0.069)\tData load 0.068s / 10iters, (0.006813)\n",
            "Loss_D = 0.21576260 (ave = 0.53971966)\n",
            "Loss_G = 6.42758703 (ave = 5.78524650)\n",
            "\n",
            "epoch: [98/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.588s / 10iters, (0.059)\tData load 0.072s / 10iters, (0.007169)\n",
            "Loss_D = 0.19965699 (ave = 0.50449970)\n",
            "Loss_G = 2.45169616 (ave = 5.67620968)\n",
            "\n",
            "epoch: [98/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.676s / 10iters, (0.068)\tData load 0.081s / 10iters, (0.008080)\n",
            "Loss_D = 0.62233162 (ave = 0.50332222)\n",
            "Loss_G = 6.99248791 (ave = 5.80506662)\n",
            "\n",
            "epoch: [98/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.545s / 10iters, (0.055)\tData load 0.089s / 10iters, (0.008904)\n",
            "Loss_D = 0.55718714 (ave = 0.47388416)\n",
            "Loss_G = 5.20463085 (ave = 5.71530318)\n",
            "\n",
            "epoch: [98/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.696s / 10iters, (0.070)\tData load 0.077s / 10iters, (0.007727)\n",
            "Loss_D = 0.82765812 (ave = 0.46776705)\n",
            "Loss_G = 2.55189276 (ave = 5.70774690)\n",
            "\n",
            "epoch: [98/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.633s / 10iters, (0.063)\tData load 0.070s / 10iters, (0.007022)\n",
            "Loss_D = 0.14784209 (ave = 0.44851759)\n",
            "Loss_G = 6.49135876 (ave = 5.69138036)\n",
            "\n",
            "epoch: [98/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.669s / 10iters, (0.067)\tData load 0.066s / 10iters, (0.006559)\n",
            "Loss_D = 0.32565013 (ave = 0.42947695)\n",
            "Loss_G = 5.95053768 (ave = 5.70400088)\n",
            "\n",
            "epoch: [98/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.717s / 10iters, (0.072)\tData load 0.068s / 10iters, (0.006771)\n",
            "Loss_D = 0.05975495 (ave = 0.41460626)\n",
            "Loss_G = 6.81810999 (ave = 5.68440424)\n",
            "\n",
            "epoch: [98/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.658s / 10iters, (0.066)\tData load 0.071s / 10iters, (0.007096)\n",
            "Loss_D = 0.71783525 (ave = 0.40849415)\n",
            "Loss_G = 7.40050030 (ave = 5.74467957)\n",
            "\n",
            "epoch: [98/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.563s / 10iters, (0.056)\tData load 0.062s / 10iters, (0.006240)\n",
            "Loss_D = 0.15623230 (ave = 0.40804487)\n",
            "Loss_G = 4.04773283 (ave = 5.71752643)\n",
            "\n",
            "epoch: [98/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.643s / 10iters, (0.064)\tData load 0.069s / 10iters, (0.006926)\n",
            "Loss_D = 0.16932735 (ave = 0.40106316)\n",
            "Loss_G = 4.47081709 (ave = 5.73520392)\n",
            "\n",
            "epoch: [98/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.617s / 10iters, (0.062)\tData load 0.091s / 10iters, (0.009069)\n",
            "Loss_D = 0.30048114 (ave = 0.39530958)\n",
            "Loss_G = 5.37453270 (ave = 5.68532666)\n",
            "\n",
            "epoch: [98/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.602s / 10iters, (0.060)\tData load 0.084s / 10iters, (0.008399)\n",
            "Loss_D = 0.60527772 (ave = 0.39367158)\n",
            "Loss_G = 5.91368914 (ave = 5.68937527)\n",
            "\n",
            "epoch: [98/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.592s / 10iters, (0.059)\tData load 0.090s / 10iters, (0.008981)\n",
            "Loss_D = 0.13800919 (ave = 0.39095076)\n",
            "Loss_G = 7.82099152 (ave = 5.73426278)\n",
            "\n",
            "epoch: [98/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.594s / 10iters, (0.059)\tData load 0.086s / 10iters, (0.008639)\n",
            "Loss_D = 0.06695627 (ave = 0.38317978)\n",
            "Loss_G = 5.55307531 (ave = 5.75393189)\n",
            "\n",
            "epoch: [98/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.637s / 10iters, (0.064)\tData load 0.090s / 10iters, (0.008983)\n",
            "Loss_D = 0.08774674 (ave = 0.37774785)\n",
            "Loss_G = 3.45241570 (ave = 5.76811615)\n",
            "\n",
            "epoch: [98/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.534s / 10iters, (0.053)\tData load 0.063s / 10iters, (0.006323)\n",
            "Loss_D = 0.28509179 (ave = 0.37267957)\n",
            "Loss_G = 6.89404297 (ave = 5.73323861)\n",
            "\n",
            "epoch: [98/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.638s / 10iters, (0.064)\tData load 0.068s / 10iters, (0.006803)\n",
            "Loss_D = 0.10571218 (ave = 0.36893548)\n",
            "Loss_G = 5.79840374 (ave = 5.71715983)\n",
            "\n",
            "epoch: [98/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.291s / 10iters, (0.029)\tData load 0.057s / 10iters, (0.005692)\n",
            "Loss_D = 0.74103683 (ave = 0.36388395)\n",
            "Loss_G = 7.12768888 (ave = 5.71454712)\n",
            "\n",
            "epoch: [98/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.066s / 3iters, (0.022)\tData load 0.016s / 3iters, (0.005430)\n",
            "Loss_D = 0.05483979 (ave = 0.36360924)\n",
            "Loss_G = 6.07106018 (ave = 5.72981197)\n",
            "\n",
            "Real Accuracy : 92.38662694472029\n",
            "Fake Accuracy : 2.8467394902350214\n",
            "epoch: [99/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.021s / 10iters, (0.502)\tData load 4.382s / 10iters, (0.438246)\n",
            "Loss_D = 0.04131751 (ave = 0.35790993)\n",
            "Loss_G = 6.74388218 (ave = 6.81414948)\n",
            "\n",
            "epoch: [99/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.673s / 10iters, (0.067)\tData load 0.113s / 10iters, (0.011265)\n",
            "Loss_D = 0.74325329 (ave = 0.33866315)\n",
            "Loss_G = 6.27209806 (ave = 6.22783792)\n",
            "\n",
            "epoch: [99/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.508s / 10iters, (0.051)\tData load 0.070s / 10iters, (0.007050)\n",
            "Loss_D = 0.64550698 (ave = 0.32486114)\n",
            "Loss_G = 3.99380112 (ave = 6.04973904)\n",
            "\n",
            "epoch: [99/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.614s / 10iters, (0.061)\tData load 0.089s / 10iters, (0.008880)\n",
            "Loss_D = 0.31842223 (ave = 0.28744045)\n",
            "Loss_G = 5.98002052 (ave = 6.06134776)\n",
            "\n",
            "epoch: [99/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.711s / 10iters, (0.071)\tData load 0.080s / 10iters, (0.008049)\n",
            "Loss_D = 0.63456279 (ave = 0.31833230)\n",
            "Loss_G = 6.50509644 (ave = 5.90327100)\n",
            "\n",
            "epoch: [99/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.599s / 10iters, (0.060)\tData load 0.066s / 10iters, (0.006648)\n",
            "Loss_D = 0.38047838 (ave = 0.30294279)\n",
            "Loss_G = 5.81464624 (ave = 5.87817481)\n",
            "\n",
            "epoch: [99/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.716s / 10iters, (0.072)\tData load 0.076s / 10iters, (0.007623)\n",
            "Loss_D = 0.06209734 (ave = 0.29856782)\n",
            "Loss_G = 7.51901531 (ave = 5.88892692)\n",
            "\n",
            "epoch: [99/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.623s / 10iters, (0.062)\tData load 0.076s / 10iters, (0.007630)\n",
            "Loss_D = 0.51725638 (ave = 0.30778137)\n",
            "Loss_G = 8.86598969 (ave = 5.86654110)\n",
            "\n",
            "epoch: [99/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.616s / 10iters, (0.062)\tData load 0.078s / 10iters, (0.007821)\n",
            "Loss_D = 0.21838124 (ave = 0.31473466)\n",
            "Loss_G = 5.41517448 (ave = 5.89180022)\n",
            "\n",
            "epoch: [99/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.589s / 10iters, (0.059)\tData load 0.087s / 10iters, (0.008684)\n",
            "Loss_D = 0.06614915 (ave = 0.29695606)\n",
            "Loss_G = 4.89391613 (ave = 5.90754205)\n",
            "\n",
            "epoch: [99/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.636s / 10iters, (0.064)\tData load 0.083s / 10iters, (0.008255)\n",
            "Loss_D = 0.22036868 (ave = 0.28795057)\n",
            "Loss_G = 6.66875792 (ave = 5.86828539)\n",
            "\n",
            "epoch: [99/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.656s / 10iters, (0.066)\tData load 0.067s / 10iters, (0.006657)\n",
            "Loss_D = 0.92026925 (ave = 0.32212979)\n",
            "Loss_G = 2.75514245 (ave = 5.85840246)\n",
            "\n",
            "epoch: [99/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.654s / 10iters, (0.065)\tData load 0.081s / 10iters, (0.008083)\n",
            "Loss_D = 0.07101324 (ave = 0.32741314)\n",
            "Loss_G = 6.75017262 (ave = 5.88384646)\n",
            "\n",
            "epoch: [99/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.647s / 10iters, (0.065)\tData load 0.085s / 10iters, (0.008545)\n",
            "Loss_D = 0.13706958 (ave = 0.32178194)\n",
            "Loss_G = 5.22971296 (ave = 5.87720789)\n",
            "\n",
            "epoch: [99/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.621s / 10iters, (0.062)\tData load 0.097s / 10iters, (0.009653)\n",
            "Loss_D = 0.40817147 (ave = 0.31271874)\n",
            "Loss_G = 2.85007858 (ave = 5.81312558)\n",
            "\n",
            "epoch: [99/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.593s / 10iters, (0.059)\tData load 0.091s / 10iters, (0.009128)\n",
            "Loss_D = 0.11077686 (ave = 0.31431562)\n",
            "Loss_G = 5.96551943 (ave = 5.76653725)\n",
            "\n",
            "epoch: [99/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.624s / 10iters, (0.062)\tData load 0.071s / 10iters, (0.007110)\n",
            "Loss_D = 0.24493459 (ave = 0.31145850)\n",
            "Loss_G = 4.23334599 (ave = 5.73989863)\n",
            "\n",
            "epoch: [99/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.623s / 10iters, (0.062)\tData load 0.082s / 10iters, (0.008235)\n",
            "Loss_D = 0.14056896 (ave = 0.32560549)\n",
            "Loss_G = 7.65504217 (ave = 5.80261344)\n",
            "\n",
            "epoch: [99/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.633s / 10iters, (0.063)\tData load 0.079s / 10iters, (0.007853)\n",
            "Loss_D = 0.72921044 (ave = 0.32553555)\n",
            "Loss_G = 5.62998867 (ave = 5.82311398)\n",
            "\n",
            "epoch: [99/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.590s / 10iters, (0.059)\tData load 0.081s / 10iters, (0.008107)\n",
            "Loss_D = 0.38186044 (ave = 0.32348194)\n",
            "Loss_G = 6.03929329 (ave = 5.82607808)\n",
            "\n",
            "epoch: [99/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.637s / 10iters, (0.064)\tData load 0.069s / 10iters, (0.006926)\n",
            "Loss_D = 0.89439017 (ave = 0.32282378)\n",
            "Loss_G = 5.42051411 (ave = 5.83788244)\n",
            "\n",
            "epoch: [99/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.584s / 10iters, (0.058)\tData load 0.083s / 10iters, (0.008309)\n",
            "Loss_D = 0.46143118 (ave = 0.33292753)\n",
            "Loss_G = 6.90085077 (ave = 5.87340247)\n",
            "\n",
            "epoch: [99/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.301s / 10iters, (0.030)\tData load 0.061s / 10iters, (0.006138)\n",
            "Loss_D = 0.16990286 (ave = 0.33509029)\n",
            "Loss_G = 5.96025276 (ave = 5.86483360)\n",
            "\n",
            "epoch: [99/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.072s / 3iters, (0.024)\tData load 0.016s / 3iters, (0.005189)\n",
            "Loss_D = 0.41177398 (ave = 0.33410095)\n",
            "Loss_G = 5.95344687 (ave = 5.86821182)\n",
            "\n",
            "Real Accuracy : 93.18106587222773\n",
            "Fake Accuracy : 3.0122476001324063\n",
            "epoch: [100/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.199s / 10iters, (0.520)\tData load 4.473s / 10iters, (0.447303)\n",
            "Loss_D = 0.50093162 (ave = 0.49344050)\n",
            "Loss_G = 3.75806570 (ave = 6.30213037)\n",
            "\n",
            "epoch: [100/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.684s / 10iters, (0.068)\tData load 0.073s / 10iters, (0.007339)\n",
            "Loss_D = 1.12493134 (ave = 0.45217075)\n",
            "Loss_G = 6.79535770 (ave = 6.06999662)\n",
            "\n",
            "epoch: [100/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.599s / 10iters, (0.060)\tData load 0.095s / 10iters, (0.009524)\n",
            "Loss_D = 1.23636401 (ave = 0.40326785)\n",
            "Loss_G = 6.97132635 (ave = 5.84864708)\n",
            "\n",
            "epoch: [100/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.593s / 10iters, (0.059)\tData load 0.074s / 10iters, (0.007425)\n",
            "Loss_D = 0.50795376 (ave = 0.37462392)\n",
            "Loss_G = 5.79859209 (ave = 5.91940287)\n",
            "\n",
            "epoch: [100/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.693s / 10iters, (0.069)\tData load 0.080s / 10iters, (0.007964)\n",
            "Loss_D = 0.34646767 (ave = 0.38887200)\n",
            "Loss_G = 4.19153547 (ave = 5.93790751)\n",
            "\n",
            "epoch: [100/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.661s / 10iters, (0.066)\tData load 0.100s / 10iters, (0.010038)\n",
            "Loss_D = 0.05969128 (ave = 0.37087200)\n",
            "Loss_G = 4.02152586 (ave = 5.89371202)\n",
            "\n",
            "epoch: [100/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.685s / 10iters, (0.068)\tData load 0.086s / 10iters, (0.008649)\n",
            "Loss_D = 0.08327136 (ave = 0.35056423)\n",
            "Loss_G = 6.57636213 (ave = 5.87916891)\n",
            "\n",
            "epoch: [100/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.582s / 10iters, (0.058)\tData load 0.077s / 10iters, (0.007661)\n",
            "Loss_D = 0.19434421 (ave = 0.34087570)\n",
            "Loss_G = 6.03796864 (ave = 5.83589088)\n",
            "\n",
            "epoch: [100/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.577s / 10iters, (0.058)\tData load 0.082s / 10iters, (0.008154)\n",
            "Loss_D = 0.16322012 (ave = 0.33409981)\n",
            "Loss_G = 5.63623238 (ave = 5.74270140)\n",
            "\n",
            "epoch: [100/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.688s / 10iters, (0.069)\tData load 0.099s / 10iters, (0.009912)\n",
            "Loss_D = 0.26396438 (ave = 0.32371784)\n",
            "Loss_G = 4.17540169 (ave = 5.72309390)\n",
            "\n",
            "epoch: [100/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.587s / 10iters, (0.059)\tData load 0.080s / 10iters, (0.007971)\n",
            "Loss_D = 0.32519943 (ave = 0.31860620)\n",
            "Loss_G = 6.27292299 (ave = 5.77044751)\n",
            "\n",
            "epoch: [100/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.619s / 10iters, (0.062)\tData load 0.097s / 10iters, (0.009684)\n",
            "Loss_D = 0.39106670 (ave = 0.31745900)\n",
            "Loss_G = 7.12633085 (ave = 5.79673618)\n",
            "\n",
            "epoch: [100/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.592s / 10iters, (0.059)\tData load 0.085s / 10iters, (0.008497)\n",
            "Loss_D = 0.26534021 (ave = 0.31062738)\n",
            "Loss_G = 6.14006519 (ave = 5.76939021)\n",
            "\n",
            "epoch: [100/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.596s / 10iters, (0.060)\tData load 0.086s / 10iters, (0.008593)\n",
            "Loss_D = 0.04646870 (ave = 0.29773427)\n",
            "Loss_G = 4.95129967 (ave = 5.72890194)\n",
            "\n",
            "epoch: [100/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.617s / 10iters, (0.062)\tData load 0.078s / 10iters, (0.007809)\n",
            "Loss_D = 1.73665369 (ave = 0.31519050)\n",
            "Loss_G = 10.54016972 (ave = 5.72701366)\n",
            "\n",
            "epoch: [100/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.689s / 10iters, (0.069)\tData load 0.079s / 10iters, (0.007901)\n",
            "Loss_D = 0.16493385 (ave = 0.31996153)\n",
            "Loss_G = 5.37741423 (ave = 5.76630513)\n",
            "\n",
            "epoch: [100/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.655s / 10iters, (0.066)\tData load 0.076s / 10iters, (0.007616)\n",
            "Loss_D = 0.31748188 (ave = 0.31589045)\n",
            "Loss_G = 4.79190111 (ave = 5.75057641)\n",
            "\n",
            "epoch: [100/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.626s / 10iters, (0.063)\tData load 0.061s / 10iters, (0.006076)\n",
            "Loss_D = 0.06215866 (ave = 0.31016492)\n",
            "Loss_G = 3.83564806 (ave = 5.75044608)\n",
            "\n",
            "epoch: [100/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.592s / 10iters, (0.059)\tData load 0.070s / 10iters, (0.006953)\n",
            "Loss_D = 0.65694278 (ave = 0.31490092)\n",
            "Loss_G = 5.57815838 (ave = 5.74249201)\n",
            "\n",
            "epoch: [100/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.569s / 10iters, (0.057)\tData load 0.081s / 10iters, (0.008145)\n",
            "Loss_D = 0.45630109 (ave = 0.31006977)\n",
            "Loss_G = 6.84132910 (ave = 5.70484695)\n",
            "\n",
            "epoch: [100/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.555s / 10iters, (0.056)\tData load 0.067s / 10iters, (0.006658)\n",
            "Loss_D = 0.09190943 (ave = 0.30856488)\n",
            "Loss_G = 5.19392061 (ave = 5.68706670)\n",
            "\n",
            "epoch: [100/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.640s / 10iters, (0.064)\tData load 0.095s / 10iters, (0.009460)\n",
            "Loss_D = 0.60849595 (ave = 0.31186080)\n",
            "Loss_G = 6.35533237 (ave = 5.70290317)\n",
            "\n",
            "epoch: [100/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.357s / 10iters, (0.036)\tData load 0.049s / 10iters, (0.004917)\n",
            "Loss_D = 0.45713896 (ave = 0.30818560)\n",
            "Loss_G = 6.51393175 (ave = 5.70248961)\n",
            "\n",
            "epoch: [100/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.067s / 3iters, (0.022)\tData load 0.011s / 3iters, (0.003781)\n",
            "Loss_D = 0.52488059 (ave = 0.30823809)\n",
            "Loss_G = 3.46194220 (ave = 5.70217551)\n",
            "\n",
            "Real Accuracy : 94.3727242634889\n",
            "Fake Accuracy : 2.2509102946044357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NNhwNi5BSr0",
        "outputId": "6ca625c2-0f4e-4273-c8ee-133996aa8e2f"
      },
      "source": [
        "#load the saved models here\r\n",
        "def generate_images(batch_size):\r\n",
        "  #fake_num = math.ceil(batch_size/class_num)\r\n",
        "  conditional_z, z_label = conditional_latent_generator(distribution, 2, batch_size)\r\n",
        "\r\n",
        "  noise = conditional_z.view(-1, z_dim, 1, 1)\r\n",
        "  print(noise.shape)\r\n",
        "  if use_cuda:\r\n",
        "    noise = noise.cuda(gpu)\r\n",
        "\r\n",
        "  fake = G(noise)\r\n",
        "  print(fake.shape)\r\n",
        "\r\n",
        "  for i, label in enumerate(z_label):\r\n",
        "    cv = output_images_dir+\"/covid\"\r\n",
        "    ncv=output_images_dir+\"/noncovid\"\r\n",
        "\r\n",
        "    os.makedirs(cv, exist_ok = True)\r\n",
        "    os.makedirs(ncv, exist_ok = True)\r\n",
        "\r\n",
        "    if label == 0:\r\n",
        "      vutils.save_image(fake[i].detach(), ncv+'/fake_samples_{:03d}.png'.format(i),normalize=True, nrow=5)\r\n",
        "    else:\r\n",
        "      vutils.save_image(fake[i].detach(), cv+'/fake_samples_{:03d}.png'.format(i),normalize=True, nrow=5)\r\n",
        "\r\n",
        "\r\n",
        "generate_images(2000)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2000, 100, 1, 1])\n",
            "torch.Size([2000, 3, 64, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ5RSip1LMOP",
        "outputId": "00a3e63e-1e4f-4a26-ed9b-3a9adaadf1f0"
      },
      "source": [
        "# G = torch.load(checkpoint_dir+\"/gan/G_epoch_19.pth\")\r\n",
        "# generate_images(50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 100, 1, 1])\n",
            "torch.Size([32, 3, 64, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTWp89VcJe24"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z2UMjnXI8jL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXo26KV2I6fj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VytkymqOIzO6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}