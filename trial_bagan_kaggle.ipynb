{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "trial_bagan_kaggle.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abbyambita/Diagnosing-COVID-from-CT-Scan-Images/blob/main/trial_bagan_kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZBMv7HEE81_"
      },
      "source": [
        "https://github.com/seokinj/BAGAN/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrbY_X-nvYFM",
        "outputId": "2b1291a7-d529-4c86-82e8-b38cce5077d7"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncGTysumvhSl",
        "outputId": "7d5d6425-f336-49db-85d7-7b11b55c110e"
      },
      "source": [
        "import os \r\n",
        "\r\n",
        "os.chdir(\"/content/gdrive/My Drive\")\r\n",
        "\r\n",
        "#!ls  '/content/gdrive/My Drive/CS 284 Mini-Project/Code/'\r\n",
        "\r\n",
        "%cd \"/content/gdrive/My Drive/CS 284 Mini-Project/Code/\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/.shortcut-targets-by-id/1eVFVz23F6ROX0s10Oe3tT9HVzr502iW2/CS 284 Mini-Project/Code\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu35A4u7wEDx"
      },
      "source": [
        "from __future__ import print_function\r\n",
        "#%matplotlib inline\r\n",
        "import argparse\r\n",
        "import os\r\n",
        "import PIL\r\n",
        "import glob\r\n",
        "import xml.etree.ElementTree as ET\r\n",
        "import random\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.parallel\r\n",
        "import torch.backends.cudnn as cudnn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.utils.data\r\n",
        "import torchvision.datasets as dset\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torchvision.utils as vutils\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.animation as animation\r\n",
        "import seaborn as sns\r\n",
        "from IPython.display import HTML\r\n",
        "from torchvision.utils import save_image\r\n",
        "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\r\n",
        "from tqdm import tqdm_notebook as tqdm\r\n",
        "from IPython.display import clear_output\r\n",
        "from scipy.stats import truncnorm\r\n",
        "%matplotlib inline\r\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\r\n",
        "\r\n",
        "from easydict import EasyDict as edict\r\n",
        "from PIL import Image\r\n",
        "from collections import OrderedDict\r\n",
        "import yaml\r\n",
        "import imageio\r\n",
        "import numpy as np\r\n",
        "import torch.utils.data as data\r\n",
        "import torchvision.datasets as datasets\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import matplotlib\r\n",
        "matplotlib.use('Agg')\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import sys\r\n",
        "import time\r\n",
        "import math\r\n",
        "\r\n",
        "import scipy.misc\r\n",
        "import torchvision\r\n",
        "import torchvision.datasets as datasets\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6Ylm3_NuanS"
      },
      "source": [
        "workers = 6\r\n",
        "display= 10\r\n",
        "epoches= 100\r\n",
        "test_epoches= 30\r\n",
        "batch_size= 32\r\n",
        "base_lr= 0.0002\r\n",
        "beta1= 0.5\r\n",
        "ano_para= 0.1\r\n",
        "image_size= 64 \r\n",
        "z_dim= 100\r\n",
        "c_dim= 3\r\n",
        "gf_dim= 64\r\n",
        "df_dim= 64\r\n",
        "#class_num= 10\r\n",
        "class_num= 2\r\n",
        "pretrained = True\r\n",
        "\r\n",
        "dir = \"epochs=\"+str(epoches)+\"_lr=\"+str(base_lr)+\"_batch_size=\"+str(batch_size)\r\n",
        "checkpoint_dir = \"model_backup/bagan/kaggle/\"+dir\r\n",
        "save_dir = \"plots/bagan/kaggle/\"+dir\r\n",
        "distribution_dir =\"model_result/bagan/kaggle/\"+dir+\"/distribution\"\r\n",
        "output_images_dir = \"bagan_output_images/kaggle/\"+dir\r\n",
        "\r\n",
        "os.makedirs(\"model_result/bagan/kaggle/\"+dir, exist_ok=True)\r\n",
        "os.makedirs(\"plots/bagan/kaggle/\"+dir, exist_ok=True)\r\n",
        "os.makedirs(\"model_backup/bagan/kaggle/\"+dir, exist_ok=True)\r\n",
        "os.makedirs(output_images_dir, exist_ok=True)\r\n",
        "\r\n",
        "os.makedirs(\"model_result/bagan/kaggle/\"+dir+\"/distribution\", exist_ok=True)\r\n",
        "\r\n",
        "os.makedirs(save_dir+\"/accuracy\", exist_ok=True)\r\n",
        "os.makedirs(save_dir+\"/loss\", exist_ok=True)\r\n",
        "os.makedirs(checkpoint_dir+\"/gan\", exist_ok=True)\r\n",
        "os.makedirs(checkpoint_dir+\"/vae\", exist_ok=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-tWCNsN0c-g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3QUSZYhy9T5"
      },
      "source": [
        "def load_images(batch_size, image_size):\r\n",
        "  dataroot = \"revised-kaggle-validation/train\"\r\n",
        "\r\n",
        "  dataset = dset.ImageFolder(root=dataroot,\r\n",
        "                            transform=transforms.Compose([\r\n",
        "                                transforms.Resize(image_size),\r\n",
        "                                transforms.RandomHorizontalFlip(),\r\n",
        "                                transforms.CenterCrop(image_size),\r\n",
        "                                transforms.ToTensor(),\r\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\r\n",
        "                            ]))\r\n",
        "  \r\n",
        "  \r\n",
        "  dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,shuffle=True, num_workers=workers)\r\n",
        "\r\n",
        "  return dataloader"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EJwL7DAzXXa",
        "outputId": "6c2d9c02-2ee2-49e2-ddd7-3724b5b55184"
      },
      "source": [
        "dataloader = load_images(32, 128)\r\n",
        "print(len(dataloader))\r\n",
        "# real_batch = iter(dataloader).next()\r\n",
        "# plt.figure(figsize=(15,15))\r\n",
        "# plt.axis(\"off\")\r\n",
        "# plt.title(\"Training Images\")\r\n",
        "# image = np.transpose(vutils.make_grid(real_batch[0].to(device), normalize=True).cpu(),axes=(1,2,0))\r\n",
        "# plt.imshow(image)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoXkR1rPnm70"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D58t3IfNW_pC"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "\r\n",
        "# Generator\r\n",
        "class Decoder(nn.Module):\r\n",
        "\tdef __init__(self, z_dim, c_dim, gf_dim):\r\n",
        "\t\tsuper(Decoder, self).__init__()\r\n",
        "\r\n",
        "\t\tself.convTrans0 = nn.ConvTranspose2d(z_dim, gf_dim*8, 4, 1, 0, bias=False)\r\n",
        "\t\tself.bn0 = nn.BatchNorm2d(gf_dim*8)\r\n",
        "\t\tself.relu0 = nn.ReLU(inplace=True)\r\n",
        "\t\t\r\n",
        "\t\tself.convTrans1 = nn.ConvTranspose2d(gf_dim*8, gf_dim*4, 4, 2, 1, bias=False)\r\n",
        "\t\tself.bn1 = nn.BatchNorm2d(gf_dim*4)\r\n",
        "\t\tself.relu1 = nn.ReLU(inplace=True)\r\n",
        "\r\n",
        "\t\tself.convTrans2 = nn.ConvTranspose2d(gf_dim*4, gf_dim*2, 4, 2, 1, bias=False)\r\n",
        "\t\tself.bn2 = nn.BatchNorm2d(gf_dim*2)\r\n",
        "\t\tself.relu2 = nn.ReLU(inplace=True)\r\n",
        "\r\n",
        "\t\tself.convTrans3 = nn.ConvTranspose2d(gf_dim*2, gf_dim, 4, 2, 1, bias=False)\r\n",
        "\t\tself.bn3 = nn.BatchNorm2d(gf_dim)\r\n",
        "\t\tself.relu3 = nn.ReLU(inplace=True)\r\n",
        "\r\n",
        "\t\tself.convTrans4 = nn.ConvTranspose2d(gf_dim, c_dim, 4, 2, 1, bias=False)\r\n",
        "\t\tself.tanh = nn.Tanh()\r\n",
        "\r\n",
        "\t\tfor m in self.modules():\r\n",
        "\t\t\t\tif isinstance(m, nn.ConvTranspose2d):\r\n",
        "\t\t\t\t\t\tm.weight.data.normal_(0.0, 0.02)\r\n",
        "\t\t\t\t\t\tif m.bias is not None:\r\n",
        "\t\t\t\t\t\t\t\tm.bias.data.zero_()\r\n",
        "\r\n",
        "\tdef forward(self, z):\r\n",
        "\t\th0 = self.relu0(self.bn0(self.convTrans0(z)))\r\n",
        "\t\th1 = self.relu1(self.bn1(self.convTrans1(h0)))\r\n",
        "\t\th2 = self.relu2(self.bn2(self.convTrans2(h1)))\r\n",
        "\t\th3 = self.relu3(self.bn3(self.convTrans3(h2)))\r\n",
        "\t\th4 = self.convTrans4(h3)\r\n",
        "\t\toutput = self.tanh(h4)\r\n",
        "\t\treturn output # (c_dim, 64, 64)\r\n",
        "\r\n",
        "# Discriminator\r\n",
        "class Encoder(nn.Module): \r\n",
        "\tdef __init__(self, z_dim, c_dim, df_dim):\r\n",
        "\t\tsuper(Encoder, self).__init__()\r\n",
        "\t\tself.df_dim = df_dim\r\n",
        "\r\n",
        "\t\tself.conv0 = nn.Conv2d(c_dim, df_dim, 4, 2, 1, bias=False)\r\n",
        "\t\tself.relu0 = nn.LeakyReLU(0.2, inplace=True)\r\n",
        "\t\t\r\n",
        "\t\tself.conv1 = nn.Conv2d(df_dim, df_dim*2, 4, 2, 1, bias=False)\r\n",
        "\t\tself.bn1 = nn.BatchNorm2d(df_dim*2)\r\n",
        "\t\tself.relu1 = nn.LeakyReLU(0.2, inplace=True)\r\n",
        "\r\n",
        "\t\tself.conv2 = nn.Conv2d(df_dim*2, df_dim*4, 4, 2, 1, bias=False)\r\n",
        "\t\tself.bn2 = nn.BatchNorm2d(df_dim*4)\r\n",
        "\t\tself.relu2 = nn.LeakyReLU(0.2, inplace=True)\r\n",
        "\r\n",
        "\t\tself.conv3 = nn.Conv2d(df_dim*4, df_dim*8, 4, 2, 1, bias=False)\r\n",
        "\t\tself.bn3 = nn.BatchNorm2d(df_dim*8)\r\n",
        "\t\tself.relu3 = nn.LeakyReLU(0.2, inplace=True)\r\n",
        "\r\n",
        "\t\tself.fc_z1 = nn.Linear(df_dim*8*4*4, z_dim)\r\n",
        "\t\tself.fc_z2 = nn.Linear(df_dim*8*4*4, z_dim)\r\n",
        "\r\n",
        "\t\t#self.conv4 = nn.Conv2d(df_dim*8, 1, 4, 1, 0, bias=False)\r\n",
        "\r\n",
        "\t\tfor m in self.modules():\r\n",
        "\t\t\t\tif isinstance(m, nn.Conv2d):\r\n",
        "\t\t\t\t\t\tm.weight.data.normal_(0.0, 0.02)\r\n",
        "\t\t\t\t\t\tif m.bias is not None:\r\n",
        "\t\t\t\t\t\t\t\tm.bias.data.zero_()\r\n",
        "\r\n",
        "\tdef forward(self, input):\r\n",
        "\t\th0 = self.relu0(self.conv0(input))\r\n",
        "\t\th1 = self.relu1(self.bn1(self.conv1(h0)))\r\n",
        "\t\th2 = self.relu2(self.bn2(self.conv2(h1)))\r\n",
        "\t\th3 = self.relu3(self.bn3(self.conv3(h2)))\r\n",
        "\t\t\r\n",
        "\t\tmu = self.fc_z1(h3.view(-1, self.df_dim*8*4*4))\t# (1, 128*8*4*4)\r\n",
        "\t\tsigma = self.fc_z2(h3.view(-1, self.df_dim*8*4*4))\r\n",
        "\t\treturn mu,sigma # by squeeze, get just float not float Tenosor\r\n",
        "\r\n",
        "\r\n",
        "class Generator(nn.Module):\r\n",
        "        def __init__(self, z_dim, c_dim, gf_dim):\r\n",
        "                super(Generator, self).__init__()\r\n",
        "\r\n",
        "                self.convTrans0 = nn.ConvTranspose2d(z_dim, gf_dim*8, 4, 1, 0, bias=False)\r\n",
        "                self.bn0 = nn.BatchNorm2d(gf_dim*8)\r\n",
        "                self.relu0 = nn.ReLU(inplace=True)\r\n",
        "\r\n",
        "                self.convTrans1 = nn.ConvTranspose2d(gf_dim*8, gf_dim*4, 4, 2, 1, bias=False)\r\n",
        "                self.bn1 = nn.BatchNorm2d(gf_dim*4)\r\n",
        "                self.relu1 = nn.ReLU(inplace=True)\r\n",
        "\r\n",
        "                self.convTrans2 = nn.ConvTranspose2d(gf_dim*4, gf_dim*2, 4, 2, 1, bias=False)\r\n",
        "                self.bn2 = nn.BatchNorm2d(gf_dim*2)\r\n",
        "                self.relu2 = nn.ReLU(inplace=True)\r\n",
        "\r\n",
        "                self.convTrans3 = nn.ConvTranspose2d(gf_dim*2, gf_dim, 4, 2, 1, bias=False)\r\n",
        "                self.bn3 = nn.BatchNorm2d(gf_dim)\r\n",
        "                self.relu3 = nn.ReLU(inplace=True)\r\n",
        "\r\n",
        "                self.convTrans4 = nn.ConvTranspose2d(gf_dim, c_dim, 4, 2, 1, bias=False)\r\n",
        "                self.tanh = nn.Tanh()\r\n",
        "\r\n",
        "\r\n",
        "        def forward(self, z):\r\n",
        "                h0 = self.relu0(self.bn0(self.convTrans0(z)))\r\n",
        "                h1 = self.relu1(self.bn1(self.convTrans1(h0)))\r\n",
        "                h2 = self.relu2(self.bn2(self.convTrans2(h1)))\r\n",
        "                h3 = self.relu3(self.bn3(self.convTrans3(h2)))\r\n",
        "                h4 = self.convTrans4(h3)\r\n",
        "                output = self.tanh(h4)\r\n",
        "                return output # (c_dim, 64, 64)\r\n",
        "\r\n",
        "class _ganLokaggles(nn.Module):\r\n",
        "    '''\r\n",
        "    Layer of the GAN logits of the discriminator\r\n",
        "    The layer gets class logits as inputs and calculates GAN logits to\r\n",
        "    differentiate real and fake images in a numerical stable way\r\n",
        "    '''\r\n",
        "    def __init__(self, num_classes):\r\n",
        "        '''\r\n",
        "        :param num_classes: Number of real data classes (10 for SVHN)\r\n",
        "        '''\r\n",
        "        super(_ganLogits, self).__init__()\r\n",
        "        self.num_classes = num_classes\r\n",
        "\r\n",
        "    def forward(self, class_logits):\r\n",
        "        '''\r\n",
        "        :param class_logits: Unscaled log probabilities of house numbers\r\n",
        "        '''\r\n",
        "\r\n",
        "        # Set gan_logits such that P(input is real | input) = sigmoid(gan_logits).\r\n",
        "        # Keep in mind that class_logits gives you the probability distribution over all the real\r\n",
        "        # classes and the fake class. You need to work out how to transform this multiclass softmax\r\n",
        "        # distribution into a binary real-vs-fake decision that can be described with a sigmoid.\r\n",
        "        # Numerical stability is very important.\r\n",
        "        # You'll probably need to use this numerical stability trick:\r\n",
        "        # log sum_i exp a_i = m + log sum_i exp(a_i - m).\r\n",
        "        # This is numerically stable when m = max_i a_i.\r\n",
        "        # (It helps to think about what goes wrong when...\r\n",
        "        #   1. One value of a_i is very large\r\n",
        "        #   2. All the values of a_i are very negative\r\n",
        "        # This trick and this value of m fix both those cases, but the naive implementation and\r\n",
        "        # other values of m encounter various problems)\r\n",
        "        real_class_logits, fake_class_logits = torch.split(class_logits, self.num_classes, dim=1)\r\n",
        "        fake_class_logits = torch.squeeze(fake_class_logits)\r\n",
        "\r\n",
        "        max_val, _ = torch.max(real_class_logits, 1, keepdim=True)\r\n",
        "        stable_class_logits = real_class_logits - max_val\r\n",
        "        max_val = torch.squeeze(max_val)\r\n",
        "        gan_logits = torch.log(torch.sum(torch.exp(stable_class_logits), 1)) + max_val - fake_class_logits\r\n",
        "\r\n",
        "        return gan_logits\t# [128]\r\n",
        "\r\n",
        "class Discriminator(nn.Module):\r\n",
        "        def __init__(self, z_dim, c_dim, df_dim, class_num):\r\n",
        "                super(Discriminator, self).__init__()\r\n",
        "                self.df_dim = df_dim\r\n",
        "\r\n",
        "                self.conv0 = nn.Conv2d(c_dim, df_dim, 4, 2, 1, bias=False)\r\n",
        "                self.relu0 = nn.LeakyReLU(0.2, inplace=True)\r\n",
        "\r\n",
        "                self.conv1 = nn.Conv2d(df_dim, df_dim*2, 4, 2, 1, bias=False)\r\n",
        "                self.bn1 = nn.BatchNorm2d(df_dim*2)\r\n",
        "                self.relu1 = nn.LeakyReLU(0.2, inplace=True)\r\n",
        "\r\n",
        "                self.conv2 = nn.Conv2d(df_dim*2, df_dim*4, 4, 2, 1, bias=False)\r\n",
        "                self.bn2 = nn.BatchNorm2d(df_dim*4)\r\n",
        "                self.relu2 = nn.LeakyReLU(0.2, inplace=True)\r\n",
        "\r\n",
        "                self.conv3 = nn.Conv2d(df_dim*4, df_dim*8, 4, 2, 1, bias=False)\r\n",
        "                self.bn3 = nn.BatchNorm2d(df_dim*8)\r\n",
        "                self.relu3 = nn.LeakyReLU(0.2, inplace=True)\r\n",
        "\r\n",
        "\t\t#self.fc_z = nn.Linear(df_dim*8*4*4, z_dim)\r\n",
        "                self.fc_aux = nn.Linear(df_dim*8*4*4, class_num+1)\r\n",
        "                self.softmax = nn.LogSoftmax()\r\n",
        "\r\n",
        "                for m in self.modules():\r\n",
        "                        if isinstance(m, nn.Linear):\r\n",
        "                                m.weight.data.normal_(0.0, 0.02)\r\n",
        "                                if m.bias is not None:\r\n",
        "                                        m.bias.data.zero_()\r\n",
        "\r\n",
        "\r\n",
        "        def forward(self, input):\r\n",
        "                h0 = self.relu0(self.conv0(input))\r\n",
        "                h1 = self.relu1(self.bn1(self.conv1(h0)))\r\n",
        "                h2 = self.relu2(self.bn2(self.conv2(h1)))\r\n",
        "                h3 = self.relu3(self.bn3(self.conv3(h2)))\r\n",
        "                #cl = self.class_logistics(h3.view(-1, self.df_dim*8*4*4))\r\n",
        "                #gl = self.gan_logistics(cl)    \r\n",
        "                output = self.softmax(self.fc_aux(h3.view(-1, self.df_dim*8*4*4)))\r\n",
        "                return h3, output\r\n",
        "                #return h3, output.view(-1,1).squeeze(1) # by squeeze, get just float not float Tenosor"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRU147caRRFw"
      },
      "source": [
        "def conditional_latent_generator(distribution, class_num, batch):\r\n",
        "\tclass_labels = torch.randint(0, class_num, (batch,), dtype=torch.long)\r\n",
        "\tfake_z = distribution[class_labels[0].item()].sample((1,))\r\n",
        "\tfor c in class_labels[1:]:\r\n",
        "\t\tfake_z = torch.cat((fake_z, distribution[c.item()].sample((1,))), dim=0)\r\n",
        "\treturn fake_z, class_labels"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFjMloLlRgZk"
      },
      "source": [
        "def batch2one(Z, y, z, class_num):\r\n",
        "\tfor i in range(y.shape[0]):\r\n",
        "\t\tZ[y[i]] = torch.cat((Z[y[i]], z[i].cpu()), dim=0) # Z[label][0] should be deleted..\r\n",
        "\treturn Z\t\t\t\r\n",
        "\t\r\n",
        "class AverageMeter(object):\r\n",
        "    \"\"\" Computes ans stores the average and current value\"\"\"\r\n",
        "    def __init__(self):\r\n",
        "        self.reset()\r\n",
        "    \r\n",
        "    def reset(self):\r\n",
        "        self.val = 0.\r\n",
        "        self.avg = 0.\r\n",
        "        self.sum = 0.\r\n",
        "        self.count = 0\r\n",
        "    \r\n",
        "    def update(self, val, n=1):\r\n",
        "        self.val = val\r\n",
        "        self.sum += val * n\r\n",
        "        self.count += n\r\n",
        "        self.avg = self.sum / self.count\r\n",
        "\r\n",
        "def one_hot(x, num_classes):\r\n",
        "        '''\r\n",
        "        One-hot encoding of the vector of classes. It uses number of classes + 1 to\r\n",
        "        encode fake images\r\n",
        "        :param x: vector of output classes to one-hot encode\r\n",
        "        :return: one-hot encoded version of the input vector\r\n",
        "        '''\r\n",
        "        label_numpy = x.data.cpu().numpy()\r\n",
        "        label_onehot = np.zeros((label_numpy.shape[0], num_classes + 1))\r\n",
        "        label_onehot[np.arange(label_numpy.shape[0]), label_numpy] = 1\r\n",
        "        return torch.FloatTensor(label_onehot)\r\n",
        "\r\n",
        "\r\n",
        "def weights_init(m):\r\n",
        "        classname = m.__class__.__name__\r\n",
        "        if classname.find('Conv') != -1:\r\n",
        "                m.weight.data.normal_(0.0, 0.02)\r\n",
        "        elif classname.find('BatchNorm') != -1:\r\n",
        "                m.weight.data.normal_(1.0, 0.02)\r\n",
        "                m.bias.data.fill_(0)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCst51DRRkkW"
      },
      "source": [
        "def save_checkpoint(state, filename='checkpoint'):\r\n",
        "    torch.save(state, filename + '.pth.tar')\r\n",
        "\r\n",
        "def print_gan_log(epoch, epoches, iteration, iters, learning_rate,\r\n",
        "              display, batch_time, data_time, D_losses, G_losses):\r\n",
        "    print('epoch: [{}/{}] iteration: [{}/{}]\\t'\r\n",
        "          'Learning rate: {}'.format(epoch, epoches, iteration, iters, learning_rate))\r\n",
        "    print('Time {batch_time.sum:.3f}s / {0}iters, ({batch_time.avg:.3f})\\t'\r\n",
        "          'Data load {data_time.sum:.3f}s / {0}iters, ({data_time.avg:3f})\\n'\r\n",
        "          'Loss_D = {loss_D.val:.8f} (ave = {loss_D.avg:.8f})\\n'\r\n",
        "          'Loss_G = {loss_G.val:.8f} (ave = {loss_G.avg:.8f})\\n'.format(\r\n",
        "              display, batch_time=batch_time,\r\n",
        "              data_time=data_time, loss_D=D_losses, loss_G=G_losses))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocAcgo24RxDa"
      },
      "source": [
        "#Clear\r\n",
        "def print_vae_log(epoch, epoches, iteration, iters, learning_rate,\r\n",
        "              display, batch_time, data_time, losses):\r\n",
        "\r\n",
        "    print('epoch: [{}/{}] iteration: [{}/{}]\\t'\r\n",
        "          'Learning rate: {}'.format(epoch, epoches, iteration, iters, learning_rate))\r\n",
        "    print('Time {batch_time.sum:.3f}s / {0}iters, ({batch_time.avg:.3f})\\t'\r\n",
        "          'Data load {data_time.sum:.3f}s / {0}iters, ({data_time.avg:3f})\\n'\r\n",
        "          'Loss = {loss.val:.8f} (ave = {loss.avg:.8f})\\n'.format(\r\n",
        "              display, batch_time=batch_time,\r\n",
        "              data_time=data_time, loss=losses))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXPZrvD6Rz9T"
      },
      "source": [
        "def plot_result2(fake, image_size, num_epoch, save_dir, name, fig_size=(8, 8), is_gray=False):\r\n",
        "\r\n",
        "    generate_images = fake\r\n",
        "    #G.train() # for next train after plot_result at a epoch ...\r\n",
        "\r\n",
        "    n_rows = n_cols = 8\r\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=fig_size)\r\n",
        "\r\n",
        "    for ax, img in zip(axes.flatten(), generate_images):\r\n",
        "        ax.axis('off')\r\n",
        "        ax.set_adjustable('box')\r\n",
        "        if is_gray:\r\n",
        "            img = img.cpu().data.view(image_size, image_size).numpy()\r\n",
        "            ax.imshow(img, cmap='gray', aspect='equal')\r\n",
        "        else:\r\n",
        "            img = (((img - img.min()) * 255) / (img.max() - img.min())).cpu().data.numpy().transpose(1, 2, 0).astype(np.uint8)\r\n",
        "            ax.imshow(img, cmap=None, aspect='equal')\r\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\r\n",
        "    title = 'Epoch {0}'.format(num_epoch)\r\n",
        "    fig.text(0.5, 0.04, title, ha='center')\r\n",
        "\r\n",
        "    if name == \"dcgan\":\r\n",
        "        plt.savefig(os.path.join(save_dir, 'DCGAN_epoch_{}.png'.format(num_epoch)))\r\n",
        "        plt.close()\r\n",
        "\r\n",
        "    elif name == \"anomaly\":\r\n",
        "        plt.savefig(os.path.join(save_dir, 'anoGAN_epoch_{}.png'.format(num_epoch)))\r\n",
        "        plt.close()\r\n",
        "\r\n",
        "    elif name == \"vae\":\r\n",
        "        plt.savefig(os.path.join(save_dir, 'vae_epoch_{}.png'.format(num_epoch)))\r\n",
        "        plt.close()\r\n",
        "\r\n",
        "    elif name ==\"gan\":\r\n",
        "        plt.savefig(os.path.join(save_dir, 'gan_epoch_{}.png'.format(num_epoch)))\r\n",
        "        plt.close()\r\n",
        "\r\n",
        "def plot_result(G, fixed_noise, image_size, num_epoch, save_dir, name, fig_size=(8, 8), is_gray=False):\r\n",
        "\r\n",
        "    G.eval()\r\n",
        "    generate_images = G(fixed_noise)\r\n",
        "    G.train() # for next train after plot_result at a epoch ... \r\n",
        "    \r\n",
        "    n_rows = n_cols = 8\r\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=fig_size)\r\n",
        "    \r\n",
        "    for ax, img in zip(axes.flatten(), generate_images):\r\n",
        "        ax.axis('off')\r\n",
        "        ax.set_adjustable('box')\r\n",
        "        if is_gray:\r\n",
        "            img = img.cpu().data.view(image_size, image_size).numpy()\r\n",
        "            ax.imshow(img, cmap='gray', aspect='equal')\r\n",
        "        else:\r\n",
        "            img = (((img - img.min()) * 255) / (img.max() - img.min())).cpu().data.numpy().transpose(1, 2, 0).astype(np.uint8)\r\n",
        "            ax.imshow(img, cmap=None, aspect='equal')\r\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\r\n",
        "    title = 'Epoch {0}'.format(num_epoch)\r\n",
        "    fig.text(0.5, 0.04, title, ha='center')\r\n",
        "    \r\n",
        "    if name == \"dcgan\":\r\n",
        "        plt.savefig(os.path.join(save_dir, 'DCGAN_epoch_{}.png'.format(num_epoch)))\r\n",
        "        plt.close()\r\n",
        "\r\n",
        "    elif name == \"anomaly\":\r\n",
        "        plt.savefig(os.path.join(save_dir, 'anoGAN_epoch_{}.png'.format(num_epoch)))\r\n",
        "        plt.close()\r\n",
        "\r\n",
        "    elif name == \"vae\":\r\n",
        "        plt.savefig(os.path.join(save_dir, 'vae_epoch_{}.png'.format(num_epoch)))\r\n",
        "        plt.close()\r\n",
        "    \r\n",
        "    elif name ==\"gan\":\r\n",
        "        plt.savefig(os.path.join(save_dir, 'gan_epoch_{}.png'.format(num_epoch)))\r\n",
        "        plt.close()\r\n",
        "\r\n",
        "#Clear    \r\n",
        "def plot_loss(num_epoch, epoches, save_dir, **loss):\r\n",
        "    fig, ax = plt.subplots() \r\n",
        "    ax.set_xlim(0,epoches + 1)\r\n",
        "    if len(loss) == 2:\r\n",
        "        ax.set_ylim(0, max(np.max(loss['g_loss']), np.max(loss['d_loss'])) * 1.1)\r\n",
        "    elif len(loss) == 1:\r\n",
        "        ax.set_ylim(0, max(np.max(loss['vae_loss'])) * 1.1)\r\n",
        "    plt.xlabel('Epoch {}'.format(num_epoch))\r\n",
        "    plt.ylabel('Loss')\r\n",
        "    \r\n",
        "    if len(loss) == 2:\r\n",
        "        plt.plot([i for i in range(1, num_epoch + 1)], loss['d_loss'], label='Discriminator', color='red', linewidth=3)\r\n",
        "        plt.plot([i for i in range(1, num_epoch + 1)], loss['g_loss'], label='Generator', color='mediumblue', linewidth=3)\r\n",
        "        plt.legend()\r\n",
        "        plt.savefig(os.path.join(os.path.join(save_dir, \"loss\"), 'gan_loss_epoch_{}.png'.format(num_epoch)))\r\n",
        "    elif len(loss) == 1:\r\n",
        "        plt.plot([i for i in range(1, num_epoch + 1)], loss['vae_loss'], label='vae_loss', color='red', linewidht=3)\r\n",
        "        plt.legend()\r\n",
        "        plt.savefig(os.path.join(os.path.join(save_dir, \"loss\"), 'vae_loss_epoch_{}.png'.format(num_epoch)))\r\n",
        " \r\n",
        "    plt.close()\r\n",
        "\r\n",
        "#Clear\r\n",
        "def plot_accuracy(num_epoch, epoches, save_dir, real_acc, fake_acc):\r\n",
        "\tfig, ax = plt.subplots()\r\n",
        "\tax.set_xlim(0,epoches + 1)\r\n",
        "\tax.set_ylim(0, max(np.max(real_acc), np.max(fake_acc)) * 1.1)\r\n",
        "\tplt.xlabel('Epoch {}'.format(num_epoch))\r\n",
        "\tplt.ylabel('Accuracy')\r\n",
        "\r\n",
        "\tplt.plot([i for i in range(1, num_epoch + 1)], real_acc, label='real data', color='red', linewidth=3)\r\n",
        "\tplt.plot([i for i in range(1, num_epoch + 1)], fake_acc, label='fake data', color='mediumblue', linewidth=3)\r\n",
        "\tplt.legend()\r\n",
        "\tplt.savefig(os.path.join(os.path.join(save_dir, \"accuracy\"), 'gan_accuracy_epoch_{}.png'.format(num_epoch)))\r\n",
        "\r\n",
        "\tplt.close()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7sEvv5gSer1"
      },
      "source": [
        "import torch.distributions.multivariate_normal as mn"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCdghNksVggK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0a3122f-464e-4729-9639-199204ef5992"
      },
      "source": [
        "#run as pretrained = False first then run again with pretrained = True??? Baket?\r\n",
        "pretrained = True\r\n",
        "if __name__ == \"__main__\":\r\n",
        "  use_cuda = torch.cuda.is_available()\r\n",
        "  gpu = 0\r\n",
        "\r\n",
        "  train_loader = load_images(batch_size, image_size)\r\n",
        "\r\n",
        "\r\n",
        "  decoder = Decoder(z_dim, c_dim, gf_dim)\r\n",
        "  encoder = Encoder(z_dim, c_dim, df_dim)\r\n",
        "\r\n",
        "  if not pretrained:\r\n",
        "    if use_cuda:\r\n",
        "      decoder = decoder.cuda(gpu)\r\n",
        "      encoder = encoder.cuda(gpu)\r\n",
        "\r\n",
        "    # WHY BECLoss() - only need to determine fake/real for Discriminator\r\n",
        "    criterion = nn.BCELoss()\r\n",
        "    if use_cuda:\r\n",
        "      criterion = criterion.cuda(gpu)\r\n",
        "\r\n",
        "    optimizerE = torch.optim.Adam(encoder.parameters(), lr=base_lr, betas=(beta1, 0.999))\r\n",
        "    optimizerD = torch.optim.Adam(decoder.parameters(), lr=base_lr, betas=(beta1, 0.999))\r\n",
        "\r\n",
        "    batch_time = AverageMeter()\r\n",
        "    data_time = AverageMeter()\r\n",
        "    losses = AverageMeter()\r\n",
        "\r\n",
        "    fixed_noise = torch.FloatTensor(8 * 8, z_dim, 1, 1).normal_(0, 1)\r\n",
        "    if use_cuda:\r\n",
        "      fixed_noise = fixed_noise.cuda(gpu)\r\n",
        "    with torch.no_grad():\r\n",
        "      fixed_noisev = fixed_noise\r\n",
        "\r\n",
        "    end = time.time()\r\n",
        "    \r\n",
        "    encoder.train()\r\n",
        "    decoder.train()\r\n",
        "    loss_list = []\r\n",
        "\r\n",
        "    \r\n",
        "    criterion = nn.MSELoss(size_average=False)\t\r\n",
        "    for epoch in range(epoches):\r\n",
        "      for i, (input, label) in enumerate(train_loader):\r\n",
        "        #l Update 'D' : max log(D(x)) + log(1-D(G(z)))\r\n",
        "        data_time.update(time.time()-end)\r\n",
        "      \r\n",
        "        batch_size = input.size(0)\r\n",
        "        if use_cuda:\r\n",
        "          input = input.cuda(gpu)\r\n",
        "        \r\n",
        "        mu, log_sigmoid = encoder(input)\r\n",
        "        # reparameterization\r\n",
        "        std = torch.exp(log_sigmoid/2)\r\n",
        "        eps = torch.randn_like(std)\r\n",
        "        z = mu + eps * std\r\n",
        "        z = z.view(-1, z_dim, 1, 1)\t\r\n",
        "        if use_cuda:\r\n",
        "          z = z.cuda(gpu)\r\n",
        "\r\n",
        "        # reconstruct image\r\n",
        "        x_reconstruct = decoder(z)\r\n",
        "\r\n",
        "        # reconstruct_loss + KL_divergence\r\n",
        "        reconstruct_loss = criterion(x_reconstruct, input)\r\n",
        "        kl_div = -0.5 * torch.sum(1+log_sigmoid-mu.pow(2)-log_sigmoid.exp())\r\n",
        "        loss = reconstruct_loss + kl_div\r\n",
        "        losses.update(loss.item())\t\r\n",
        "        optimizerE.zero_grad()\r\n",
        "        optimizerD.zero_grad()\r\n",
        "        loss.backward()\r\n",
        "        optimizerE.step()\r\n",
        "        optimizerD.step()\r\n",
        "\r\n",
        "        batch_time.update(time.time()-end)\r\n",
        "        end = time.time()\r\n",
        "    \r\n",
        "        # log every 100th train data of train_loader - display(100)\t\r\n",
        "        if (i+1) % display == 0:\r\n",
        "          print_vae_log(epoch+1, epoches, i+1, len(train_loader), base_lr, display, batch_time, data_time, losses)\r\n",
        "          # Is it Continous ???\r\n",
        "          batch_time.reset()\r\n",
        "          data_time.reset()\r\n",
        "        # log every 1 epoch (all of train_loader)\r\n",
        "        elif (i+1) == len(train_loader):\r\n",
        "          print_vae_log(epoch + 1, epoches, i + 1, len(train_loader), base_lr, (i + 1) % display, batch_time, data_time, losses)\r\n",
        "          batch_time.reset()\r\n",
        "          data_time.reset()\r\n",
        "\r\n",
        "      # log every 1 epoch\r\n",
        "      loss_list.append(losses.avg)\r\n",
        "      losses.reset()\r\n",
        "\r\n",
        "      plot_result(decoder, fixed_noisev, image_size, epoch + 1,save_dir, 'vae', is_gray=(c_dim == 1))\r\n",
        "      #plot_loss(epoch+1, config.epoches, args.save_dir, vae_loss=loss_list)\r\n",
        "      # save the D and G.\r\n",
        "      save_checkpoint({'epoch': epoch, 'state_dict': encoder.state_dict(),}, os.path.join(os.path.join(checkpoint_dir,\"vae\"), 'encoder_epoch_{}'.format(epoch)))\r\n",
        "      save_checkpoint({'epoch': epoch, 'state_dict': decoder.state_dict(),}, os.path.join(os.path.join(checkpoint_dir,\"vae\"), 'decoder_epoch_{}'.format(epoch)))\r\n",
        "\r\n",
        "    #create_gif(epoches, save_dir, 'vae')\r\n",
        "\r\n",
        "  ## Class Conditional Generator - Pretrained Model\"\r\n",
        "  else:\r\n",
        "    print(\"Class Conditional Generator - Use Pretrained Model\")\r\n",
        "    if use_cuda:\r\n",
        "      encoder = encoder.cuda(gpu)\r\n",
        "      decoder = decoder.cuda(gpu)\r\n",
        "    encoder.load_state_dict(torch.load(os.path.join(os.path.join(checkpoint_dir, \"vae\"), \"encoder_epoch_\"+ str(epoches-1) + \".pth.tar\"))['state_dict'])\r\n",
        "    decoder.load_state_dict(torch.load(os.path.join(os.path.join(checkpoint_dir, \"vae\"), \"decoder_epoch_\"+ str(epoches-1) + \".pth.tar\"))['state_dict'])\r\n",
        "    #Z = np.empty([config.class_num, config.z_dim], dtype=float)\r\n",
        "    # Z : [label-1, labe-2, ... ]\r\n",
        "    # Z[label-1] : [[z1], [z2], ... ] (#labeld_data, #z_dim)\r\n",
        "    encoder.eval()\r\n",
        "    decoder.eval()\r\n",
        "    Z = []\r\n",
        "    with torch.no_grad():\r\n",
        "      for i in range(class_num):\r\n",
        "        Z.append(torch.zeros((1, z_dim), dtype=torch.float)) # Z : [class_num, z_dim]\r\n",
        "    \r\n",
        "      for i, (input, label) in enumerate(train_loader):\r\n",
        "        if use_cuda:\r\n",
        "          input = input.cuda(gpu)\r\n",
        "        mu, log_sigmoid = encoder(input)\r\n",
        "        std = torch.exp(log_sigmoid/2)\r\n",
        "        eps = torch.randn_like(std)\r\n",
        "        z = mu + eps * std\r\n",
        "        z = z.view(-1, 1, z_dim)\r\n",
        "        Z = batch2one(Z, label, z, class_num)\r\n",
        "\r\n",
        "      N = []\r\n",
        "      for i in range(class_num):\r\n",
        "        label_mean = torch.mean(Z[i][1:], dim=0).float()\r\n",
        "        label_cov = torch.from_numpy(np.cov(Z[i][1:].numpy(), rowvar=False)).float()\r\n",
        "        #print(\"{}th Z : {}\".format(i+1, Z[i][1:].shape))\r\n",
        "        #print(\"{}-class  mean : {}\".format(i+1, label_mean.shape))\r\n",
        "        #print(\"{}-class covariance : {}\".format(i+1, label_cov.shape))\r\n",
        "        m = mn.MultivariateNormal(label_mean, label_cov)\r\n",
        "        sample = m.sample((64,))\r\n",
        "        print(sample.shape)\r\n",
        "        if use_cuda:\r\n",
        "          sample = sample.cuda(gpu)\r\n",
        "        fake = decoder(sample.view(-1, z_dim, 1, 1))\r\n",
        "        \r\n",
        "        \r\n",
        "        plot_result2(fake, image_size, i, 'data/gan/samples', 'ssgan', is_gray=(c_dim == 1))\r\n",
        "        N.append(m)\r\n",
        "      print(\"uhm\")\r\n",
        "      torch.save({'distribution': N}, os.path.join(distribution_dir, 'class_distribution')+'.dt')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class Conditional Generator - Use Pretrained Model\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "uhm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58SE8dlOTKJD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae920508-515f-429e-d273-8be2100cce3e"
      },
      "source": [
        "pretrained = True\r\n",
        "if __name__ == \"__main__\":\r\n",
        "  use_cuda = torch.cuda.is_available()\r\n",
        "  gpu = 0\r\n",
        "\r\n",
        "  # parser.add_argument('--save_dir', type=str, dest='save_dir', help='the path of generated data dir', default='sample')\r\n",
        "  # parser.add_argument('--distribution_dir', type=str, dest='distribution_dir', help='the path of class distribution dir', default='distribution')\r\n",
        "  # parser.add_argument('--test_dir', type=str, dest='test_dir', help='the path of anomaly test data')\r\n",
        "  # parser.add_argument('--test_result_dir', type=str, dest='test_result_dir', help='the path of anomaly test result dir')\r\n",
        "  train_loader = load_images(batch_size, image_size)\r\n",
        "\r\n",
        "  G = Generator(z_dim, c_dim, gf_dim)\r\n",
        "  G.apply(weights_init)\r\n",
        "\r\n",
        "  D = Discriminator(z_dim, c_dim, df_dim, class_num)\r\n",
        "  D.apply(weights_init)\r\n",
        "\r\n",
        "  # if not pretrained:\r\n",
        "  #   if use_cuda:\r\n",
        "  #     print(\"duh\")\r\n",
        "  #     G = G.cuda(gpu)\r\n",
        "  #     D = D.cuda(gpu)\r\n",
        "\r\n",
        "  if use_cuda:\r\n",
        "    print(\"duh\")\r\n",
        "    G = G.cuda(gpu)\r\n",
        "    D = D.cuda(gpu)\r\n",
        "\r\n",
        "\r\n",
        "  distribution = torch.load(os.path.join(distribution_dir,'class_distribution.dt'))['distribution']\r\n",
        "\r\n",
        "  #G.load_state_dict(torch.load(os.path.join(os.path.join(args.checkpoint_dir,\"vae\") , \"decoder_epoch_\"+str(config.epoches-1) + \".pth.tar\"))['state_dict'])\r\n",
        "\r\n",
        "  # state_e = torch.load(os.path.join(os.path.join(args.checkpoint_dir,\"vae\"), \"encoder_epoch_\"+str(config.epoches-1) + \".pth.tar\"))['state_dict']\r\n",
        "  # del state_e['fc_z1.weight']\r\n",
        "  # del state_e['fc_z1.bias']\r\n",
        "  # del state_e['fc_z2.weight']\r\n",
        "  # del state_e['fc_z2.bias']\r\n",
        "  # state_e.update({'fc_aux.weight':D.state_dict()['fc_aux.weight']})\r\n",
        "  # state_e.update({'fc_aux.bias':D.state_dict()['fc_aux.bias']})\r\n",
        "\r\n",
        "  # D.load_state_dict(state_e)\r\n",
        "\r\n",
        "  criterion = nn.NLLLoss()\r\n",
        "\r\n",
        "  optimizerD = torch.optim.Adam(D.parameters(), lr=base_lr, betas=(beta1, 0.999))\r\n",
        "  optimizerG = torch.optim.Adam(G.parameters(), lr=base_lr, betas=(beta1, 0.999))\r\n",
        "\r\n",
        "  batch_time = AverageMeter()\r\n",
        "  data_time = AverageMeter()\r\n",
        "  D_losses = AverageMeter()\r\n",
        "  G_losses = AverageMeter()\r\n",
        "\r\n",
        "  #fixed_noise = torch.FloatTensor(8 * 8, config.z_dim, 1, 1).normal_(0, 1)\r\n",
        "  #if use_cuda:\r\n",
        "  #\tfixed_noise = fixed_noise.cuda(gpu)\r\n",
        "  #with torch.no_grad():\r\n",
        "  #\tfixed_noisev = fixed_noise\r\n",
        "\r\n",
        "  end = time.time()\r\n",
        "\r\n",
        "  D.train()\r\n",
        "  G.train()\r\n",
        "  D_loss_list = []\r\n",
        "  G_loss_list = []\r\n",
        "\r\n",
        "  real_label = torch.LongTensor(batch_size)\r\n",
        "  fake_label = torch.LongTensor(batch_size)\t\r\n",
        "\r\n",
        "  for epoch in range(epoches):\r\n",
        "    total_real = 0\r\n",
        "    total_fake = 0\r\n",
        "    correct_real = 0\r\n",
        "    correct_fake = 0\r\n",
        "    for i, (input, label) in enumerate(train_loader):\r\n",
        "      # Update 'D' : max log(D(x)) + log(1-D(G(z)))\r\n",
        "      data_time.update(time.time()-end)\r\n",
        "      batch_size = input.size(0)\r\n",
        "      fake_num = math.ceil(batch_size/class_num)\t# For each batch, 1/(n+1) of total images are fake\r\n",
        "      conditional_z, z_label = conditional_latent_generator(distribution, class_num, batch_size)\r\n",
        "\r\n",
        "      label = label.long().squeeze() # \"squeeze\" : [batch, 1] --> [batch] ... e.g) [1,2,3,4...]\t\t\r\n",
        "      #print(label[0])\r\n",
        "      #print(path[0])\r\n",
        "      if use_cuda:\r\n",
        "        input = input.cuda(gpu)\r\n",
        "        label = label.cuda(gpu)\r\n",
        "\r\n",
        "      sample_features, D_real = D(input)\r\n",
        "      real_label.resize_(batch_size).copy_(label)\t# \"cpu\" : gpu --> cpu // <<.data.cpu vs cpu>> // \"resize_as\" : get tensor size and resize \r\n",
        "      if use_cuda:\r\n",
        "        real_label = real_label.cuda(gpu) \r\n",
        "      \r\n",
        "      D_loss_real = criterion(D_real, real_label)\r\n",
        "      noise = conditional_z[0:fake_num].view(-1, z_dim, 1, 1)\r\n",
        "\r\n",
        "      fake_label.resize_(noise.shape[0]).fill_(class_num)\t# fake_label = '(num_class)+1'\r\n",
        "      if use_cuda:\r\n",
        "        noise = noise.cuda(gpu)\r\n",
        "        fake_label = fake_label.cuda(gpu)\r\n",
        "        z_label = z_label.cuda(gpu)\r\n",
        "      \r\n",
        "      fake = G(noise)\r\n",
        "\r\n",
        "      _, D_fake = D(fake.detach())\t# Fake image...\r\n",
        "      D_loss_fake = criterion(D_fake, fake_label)\t# Hmmmm...... fake_label? or z_label?\r\n",
        "\r\n",
        "      D_loss = D_loss_real + D_loss_fake\r\n",
        "      D_losses.update(D_loss.item())\r\n",
        "      D.zero_grad()\r\n",
        "      G.zero_grad()\r\n",
        "      D_loss.backward()\r\n",
        "      optimizerD.step()\r\n",
        "\r\n",
        "      # Update 'G' : max log(D(G(z)))\r\n",
        "      noise = conditional_z.view(-1, z_dim, 1, 1)\r\n",
        "      if use_cuda:\r\n",
        "        noise = noise.cuda(gpu)\r\n",
        "      fake = G(noise)\r\n",
        "      _, D_fake = D(fake)\r\n",
        "      G_loss = criterion(D_fake, z_label)\r\n",
        "      #G_losses.update(G_loss.data[0])\r\n",
        "      G_losses.update(G_loss.item())\r\n",
        "\r\n",
        "      D.zero_grad()\r\n",
        "      G.zero_grad()\r\n",
        "      G_loss.backward()\r\n",
        "      optimizerG.step()\r\n",
        "\r\n",
        "      batch_time.update(time.time()-end)\r\n",
        "      end = time.time()\r\n",
        "      \r\n",
        "      pred_real = torch.max(D_real.data, 1)[1]\r\n",
        "      pred_fake = torch.max(D_fake.data, 1)[1]\r\n",
        "      total_real += real_label.size(0)\r\n",
        "      total_fake += z_label.size(0)\r\n",
        "      correct_real += (pred_real == real_label).sum().item()\r\n",
        "      correct_fake += (pred_fake == z_label).sum().item()\r\n",
        "\r\n",
        "      # log every 100th train data of train_loader - display(100)\t\r\n",
        "      if (i+1) % display == 0:\r\n",
        "        print_gan_log(epoch+1, epoches, i+1, len(train_loader), base_lr, display, batch_time, data_time, D_losses, G_losses)\r\n",
        "        # Is it Continous ???\r\n",
        "        batch_time.reset()\r\n",
        "        data_time.reset()\r\n",
        "      # log every 1 epoch (all of train_loader) ... \"End of all mini-Batch\"\r\n",
        "      elif (i+1) == len(train_loader):\r\n",
        "        print_gan_log(epoch + 1, epoches, i + 1, len(train_loader), base_lr,\r\n",
        "                          (i + 1) % display, batch_time, data_time, D_losses, G_losses)\r\n",
        "        #accuracy = masked_correct.item()/max(1.0, num_samples.item())\r\n",
        "        plot_result2(fake, image_size, epoch + 1, save_dir, 'gan', is_gray=(c_dim == 1))\r\n",
        "        real_acc = 100 * correct_real / total_real\r\n",
        "        fake_acc = 100 * correct_fake / total_fake\r\n",
        "        print('Real Accuracy : {}'.format(real_acc))\r\n",
        "        print('Fake Accuracy : {}'.format(fake_acc))\r\n",
        "        #plot_accuracy(epoch+1, epoches, save_dir, real_acc, fake_acc)\r\n",
        "        batch_time.reset()\r\n",
        "        data_time.reset()\r\n",
        "\r\n",
        "    # log every 1 epoch\r\n",
        "    D_loss_list.append(D_losses.avg)\r\n",
        "    G_loss_list.append(G_losses.avg)\r\n",
        "    D_losses.reset()\r\n",
        "    G_losses.reset()\r\n",
        "\r\n",
        "    plot_result(G, fixed_noisev, image_size, epoch + 1, save_dir, 'gan', is_gray=(c_dim == 1))\r\n",
        "    plot_loss(epoch+1,epoches, save_dir, d_loss=D_loss_list, g_loss=G_loss_list)\r\n",
        "    # save the D and G.\r\n",
        "    #save_checkpoint({'epoch': epoch, 'state_dict': D.state_dict(),}, os.path.join(os.path.join(checkpoint_dir,'gan'), 'D_epoch_{}'.format(epoch)))\r\n",
        "    #save_checkpoint({'epoch': epoch, 'state_dict': G.state_dict(),}, os.path.join(os.path.join(checkpoint_dir,'gan'), 'G_epoch_{}'.format(epoch)))\r\n",
        "\r\n",
        "    torch.save(D, os.path.join(os.path.join(checkpoint_dir,'gan'), 'D_epoch_{}.pth'.format(epoch)))\r\n",
        "    torch.save(G, os.path.join(os.path.join(checkpoint_dir,'gan'), 'G_epoch_{}.pth'.format(epoch)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "duh\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:198: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: [1/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 1.359s / 10iters, (0.136)\tData load 0.644s / 10iters, (0.064433)\n",
            "Loss_D = 1.55756938 (ave = 1.94280602)\n",
            "Loss_G = 8.60314655 (ave = 7.80654635)\n",
            "\n",
            "epoch: [1/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.673s / 10iters, (0.067)\tData load 0.086s / 10iters, (0.008557)\n",
            "Loss_D = 0.96634412 (ave = 1.70442106)\n",
            "Loss_G = 8.30878067 (ave = 8.24787543)\n",
            "\n",
            "epoch: [1/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.645s / 10iters, (0.064)\tData load 0.066s / 10iters, (0.006633)\n",
            "Loss_D = 3.14097261 (ave = 1.87788146)\n",
            "Loss_G = 10.09541702 (ave = 9.10091146)\n",
            "\n",
            "epoch: [1/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.602s / 10iters, (0.060)\tData load 0.085s / 10iters, (0.008482)\n",
            "Loss_D = 1.41279531 (ave = 1.74970966)\n",
            "Loss_G = 15.11264038 (ave = 9.71687341)\n",
            "\n",
            "epoch: [1/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.576s / 10iters, (0.058)\tData load 0.085s / 10iters, (0.008501)\n",
            "Loss_D = 0.76795095 (ave = 1.64930639)\n",
            "Loss_G = 14.22683239 (ave = 10.68234558)\n",
            "\n",
            "epoch: [1/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.657s / 10iters, (0.066)\tData load 0.103s / 10iters, (0.010254)\n",
            "Loss_D = 1.79972959 (ave = 1.71079328)\n",
            "Loss_G = 11.44655704 (ave = 11.14787767)\n",
            "\n",
            "epoch: [1/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.711s / 10iters, (0.071)\tData load 0.077s / 10iters, (0.007667)\n",
            "Loss_D = 2.86804271 (ave = 1.75990843)\n",
            "Loss_G = 20.74406242 (ave = 12.05297817)\n",
            "\n",
            "epoch: [1/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.645s / 10iters, (0.065)\tData load 0.085s / 10iters, (0.008515)\n",
            "Loss_D = 1.17275345 (ave = 1.77393248)\n",
            "Loss_G = 10.13502979 (ave = 12.29567733)\n",
            "\n",
            "epoch: [1/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.602s / 10iters, (0.060)\tData load 0.079s / 10iters, (0.007853)\n",
            "Loss_D = 2.12943792 (ave = 1.76056751)\n",
            "Loss_G = 11.92640018 (ave = 12.39366383)\n",
            "\n",
            "epoch: [1/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.626s / 10iters, (0.063)\tData load 0.091s / 10iters, (0.009134)\n",
            "Loss_D = 1.01176715 (ave = 1.79017137)\n",
            "Loss_G = 7.30419827 (ave = 12.33703616)\n",
            "\n",
            "epoch: [1/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.617s / 10iters, (0.062)\tData load 0.064s / 10iters, (0.006448)\n",
            "Loss_D = 1.57455254 (ave = 1.83470945)\n",
            "Loss_G = 7.44789362 (ave = 12.45647257)\n",
            "\n",
            "epoch: [1/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.621s / 10iters, (0.062)\tData load 0.092s / 10iters, (0.009229)\n",
            "Loss_D = 1.26707721 (ave = 1.83716028)\n",
            "Loss_G = 2.74166203 (ave = 12.10473512)\n",
            "\n",
            "epoch: [1/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.608s / 10iters, (0.061)\tData load 0.065s / 10iters, (0.006532)\n",
            "Loss_D = 1.59033644 (ave = 1.85431010)\n",
            "Loss_G = 4.06103325 (ave = 11.70164555)\n",
            "\n",
            "epoch: [1/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.592s / 10iters, (0.059)\tData load 0.101s / 10iters, (0.010069)\n",
            "Loss_D = 1.42554557 (ave = 1.82434162)\n",
            "Loss_G = 6.22001600 (ave = 11.32045983)\n",
            "\n",
            "epoch: [1/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.751s / 10iters, (0.075)\tData load 0.099s / 10iters, (0.009903)\n",
            "Loss_D = 2.56393886 (ave = 1.82158414)\n",
            "Loss_G = 5.18064356 (ave = 10.99739307)\n",
            "\n",
            "epoch: [1/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.618s / 10iters, (0.062)\tData load 0.087s / 10iters, (0.008683)\n",
            "Loss_D = 0.97747588 (ave = 1.79137346)\n",
            "Loss_G = 7.41683292 (ave = 10.70610710)\n",
            "\n",
            "epoch: [1/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.604s / 10iters, (0.060)\tData load 0.089s / 10iters, (0.008868)\n",
            "Loss_D = 2.10993528 (ave = 1.78057584)\n",
            "Loss_G = 10.11028385 (ave = 10.44124810)\n",
            "\n",
            "epoch: [1/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.520s / 10iters, (0.052)\tData load 0.058s / 10iters, (0.005828)\n",
            "Loss_D = 1.12018800 (ave = 1.75047234)\n",
            "Loss_G = 6.96207142 (ave = 10.21296246)\n",
            "\n",
            "epoch: [1/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.660s / 10iters, (0.066)\tData load 0.096s / 10iters, (0.009647)\n",
            "Loss_D = 0.66342795 (ave = 1.71644642)\n",
            "Loss_G = 6.30297947 (ave = 9.96679126)\n",
            "\n",
            "epoch: [1/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.584s / 10iters, (0.058)\tData load 0.076s / 10iters, (0.007567)\n",
            "Loss_D = 0.72092909 (ave = 1.71615680)\n",
            "Loss_G = 6.29836464 (ave = 9.79186558)\n",
            "\n",
            "epoch: [1/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.686s / 10iters, (0.069)\tData load 0.081s / 10iters, (0.008053)\n",
            "Loss_D = 1.23367786 (ave = 1.69401698)\n",
            "Loss_G = 8.58525658 (ave = 9.59293839)\n",
            "\n",
            "epoch: [1/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.637s / 10iters, (0.064)\tData load 0.091s / 10iters, (0.009150)\n",
            "Loss_D = 2.15119123 (ave = 1.67482548)\n",
            "Loss_G = 10.38942909 (ave = 9.46959323)\n",
            "\n",
            "epoch: [1/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.332s / 10iters, (0.033)\tData load 0.063s / 10iters, (0.006299)\n",
            "Loss_D = 0.60229158 (ave = 1.64469683)\n",
            "Loss_G = 3.53943419 (ave = 9.28473550)\n",
            "\n",
            "epoch: [1/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.066s / 3iters, (0.022)\tData load 0.016s / 3iters, (0.005230)\n",
            "Loss_D = 1.22506356 (ave = 1.63876974)\n",
            "Loss_G = 6.41092157 (ave = 9.24788126)\n",
            "\n",
            "Real Accuracy : 58.52366765971533\n",
            "Fake Accuracy : 0.6951340615690169\n",
            "epoch: [2/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.160s / 10iters, (0.516)\tData load 4.414s / 10iters, (0.441441)\n",
            "Loss_D = 0.74282509 (ave = 0.96186860)\n",
            "Loss_G = 5.53135204 (ave = 6.70712233)\n",
            "\n",
            "epoch: [2/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.706s / 10iters, (0.071)\tData load 0.065s / 10iters, (0.006469)\n",
            "Loss_D = 0.98035163 (ave = 0.97520333)\n",
            "Loss_G = 12.16034317 (ave = 6.98885405)\n",
            "\n",
            "epoch: [2/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.647s / 10iters, (0.065)\tData load 0.064s / 10iters, (0.006414)\n",
            "Loss_D = 0.27813318 (ave = 0.91733099)\n",
            "Loss_G = 5.71986341 (ave = 6.76342829)\n",
            "\n",
            "epoch: [2/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.607s / 10iters, (0.061)\tData load 0.083s / 10iters, (0.008271)\n",
            "Loss_D = 1.09006798 (ave = 0.99430313)\n",
            "Loss_G = 12.84660435 (ave = 6.75729759)\n",
            "\n",
            "epoch: [2/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.583s / 10iters, (0.058)\tData load 0.103s / 10iters, (0.010322)\n",
            "Loss_D = 0.54061925 (ave = 0.98637507)\n",
            "Loss_G = 3.87925124 (ave = 6.50361579)\n",
            "\n",
            "epoch: [2/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.591s / 10iters, (0.059)\tData load 0.087s / 10iters, (0.008734)\n",
            "Loss_D = 0.65268868 (ave = 0.95383716)\n",
            "Loss_G = 5.39811182 (ave = 6.28022298)\n",
            "\n",
            "epoch: [2/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.632s / 10iters, (0.063)\tData load 0.090s / 10iters, (0.009001)\n",
            "Loss_D = 4.72036982 (ave = 1.07142324)\n",
            "Loss_G = 5.87618685 (ave = 6.40424169)\n",
            "\n",
            "epoch: [2/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.566s / 10iters, (0.057)\tData load 0.066s / 10iters, (0.006630)\n",
            "Loss_D = 0.77626491 (ave = 1.07531969)\n",
            "Loss_G = 6.08736229 (ave = 6.44467005)\n",
            "\n",
            "epoch: [2/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.643s / 10iters, (0.064)\tData load 0.071s / 10iters, (0.007067)\n",
            "Loss_D = 2.66339302 (ave = 1.16080197)\n",
            "Loss_G = 5.78631592 (ave = 6.51354656)\n",
            "\n",
            "epoch: [2/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.695s / 10iters, (0.069)\tData load 0.086s / 10iters, (0.008638)\n",
            "Loss_D = 1.04852426 (ave = 1.13810828)\n",
            "Loss_G = 6.23731804 (ave = 6.48832776)\n",
            "\n",
            "epoch: [2/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.617s / 10iters, (0.062)\tData load 0.066s / 10iters, (0.006573)\n",
            "Loss_D = 1.13378167 (ave = 1.23611103)\n",
            "Loss_G = 4.66069746 (ave = 6.46210843)\n",
            "\n",
            "epoch: [2/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.694s / 10iters, (0.069)\tData load 0.085s / 10iters, (0.008462)\n",
            "Loss_D = 1.02619088 (ave = 1.22934274)\n",
            "Loss_G = 4.16217375 (ave = 6.36329808)\n",
            "\n",
            "epoch: [2/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.559s / 10iters, (0.056)\tData load 0.082s / 10iters, (0.008169)\n",
            "Loss_D = 1.73057270 (ave = 1.20817039)\n",
            "Loss_G = 3.54645061 (ave = 6.29562002)\n",
            "\n",
            "epoch: [2/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.632s / 10iters, (0.063)\tData load 0.096s / 10iters, (0.009634)\n",
            "Loss_D = 0.72957498 (ave = 1.18220189)\n",
            "Loss_G = 3.27174473 (ave = 6.20489582)\n",
            "\n",
            "epoch: [2/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.637s / 10iters, (0.064)\tData load 0.109s / 10iters, (0.010918)\n",
            "Loss_D = 0.93365741 (ave = 1.24001289)\n",
            "Loss_G = 4.65095139 (ave = 6.26692869)\n",
            "\n",
            "epoch: [2/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.618s / 10iters, (0.062)\tData load 0.077s / 10iters, (0.007736)\n",
            "Loss_D = 0.42521217 (ave = 1.23632116)\n",
            "Loss_G = 4.11703300 (ave = 6.19240553)\n",
            "\n",
            "epoch: [2/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.557s / 10iters, (0.056)\tData load 0.073s / 10iters, (0.007273)\n",
            "Loss_D = 0.76972848 (ave = 1.22749306)\n",
            "Loss_G = 8.17632675 (ave = 6.14507352)\n",
            "\n",
            "epoch: [2/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.594s / 10iters, (0.059)\tData load 0.086s / 10iters, (0.008612)\n",
            "Loss_D = 0.84467256 (ave = 1.23542411)\n",
            "Loss_G = 5.24904537 (ave = 6.12126981)\n",
            "\n",
            "epoch: [2/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.565s / 10iters, (0.056)\tData load 0.109s / 10iters, (0.010897)\n",
            "Loss_D = 0.94521952 (ave = 1.22258783)\n",
            "Loss_G = 5.00375462 (ave = 6.08268986)\n",
            "\n",
            "epoch: [2/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.659s / 10iters, (0.066)\tData load 0.063s / 10iters, (0.006349)\n",
            "Loss_D = 1.12572765 (ave = 1.21096144)\n",
            "Loss_G = 4.48843050 (ave = 6.02521996)\n",
            "\n",
            "epoch: [2/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.591s / 10iters, (0.059)\tData load 0.071s / 10iters, (0.007066)\n",
            "Loss_D = 0.48926735 (ave = 1.20970479)\n",
            "Loss_G = 3.14581418 (ave = 6.01411540)\n",
            "\n",
            "epoch: [2/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.562s / 10iters, (0.056)\tData load 0.093s / 10iters, (0.009255)\n",
            "Loss_D = 2.58318448 (ave = 1.22703431)\n",
            "Loss_G = 1.82849133 (ave = 5.98746434)\n",
            "\n",
            "epoch: [2/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.324s / 10iters, (0.032)\tData load 0.065s / 10iters, (0.006507)\n",
            "Loss_D = 1.29984951 (ave = 1.22304111)\n",
            "Loss_G = 3.20248294 (ave = 5.96370623)\n",
            "\n",
            "epoch: [2/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.064s / 3iters, (0.021)\tData load 0.014s / 3iters, (0.004733)\n",
            "Loss_D = 1.63771105 (ave = 1.22228619)\n",
            "Loss_G = 8.60523129 (ave = 5.96501321)\n",
            "\n",
            "Real Accuracy : 65.57431314134392\n",
            "Fake Accuracy : 2.0854021847070507\n",
            "epoch: [3/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 4.847s / 10iters, (0.485)\tData load 4.115s / 10iters, (0.411501)\n",
            "Loss_D = 1.08700776 (ave = 0.98879053)\n",
            "Loss_G = 4.66243267 (ave = 4.98092308)\n",
            "\n",
            "epoch: [3/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.722s / 10iters, (0.072)\tData load 0.076s / 10iters, (0.007644)\n",
            "Loss_D = 0.61122131 (ave = 0.90582042)\n",
            "Loss_G = 5.47855330 (ave = 4.78056457)\n",
            "\n",
            "epoch: [3/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.612s / 10iters, (0.061)\tData load 0.074s / 10iters, (0.007369)\n",
            "Loss_D = 0.50004959 (ave = 1.05924009)\n",
            "Loss_G = 6.29892731 (ave = 5.01144834)\n",
            "\n",
            "epoch: [3/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.611s / 10iters, (0.061)\tData load 0.095s / 10iters, (0.009457)\n",
            "Loss_D = 1.00940180 (ave = 1.08149622)\n",
            "Loss_G = 6.90993023 (ave = 5.14596807)\n",
            "\n",
            "epoch: [3/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.602s / 10iters, (0.060)\tData load 0.071s / 10iters, (0.007102)\n",
            "Loss_D = 1.13517702 (ave = 1.09219116)\n",
            "Loss_G = 6.35764265 (ave = 5.28002264)\n",
            "\n",
            "epoch: [3/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.547s / 10iters, (0.055)\tData load 0.064s / 10iters, (0.006421)\n",
            "Loss_D = 1.19874954 (ave = 1.08481121)\n",
            "Loss_G = 3.83338785 (ave = 5.34201152)\n",
            "\n",
            "epoch: [3/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.652s / 10iters, (0.065)\tData load 0.101s / 10iters, (0.010096)\n",
            "Loss_D = 0.93146473 (ave = 1.13606930)\n",
            "Loss_G = 4.51398754 (ave = 5.29924246)\n",
            "\n",
            "epoch: [3/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.613s / 10iters, (0.061)\tData load 0.088s / 10iters, (0.008808)\n",
            "Loss_D = 1.15215862 (ave = 1.10204748)\n",
            "Loss_G = 2.91264081 (ave = 5.19601199)\n",
            "\n",
            "epoch: [3/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.622s / 10iters, (0.062)\tData load 0.075s / 10iters, (0.007466)\n",
            "Loss_D = 3.67802882 (ave = 1.17802258)\n",
            "Loss_G = 4.12274790 (ave = 5.23751466)\n",
            "\n",
            "epoch: [3/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.619s / 10iters, (0.062)\tData load 0.105s / 10iters, (0.010539)\n",
            "Loss_D = 1.75930274 (ave = 1.19357124)\n",
            "Loss_G = 1.58781385 (ave = 5.17639356)\n",
            "\n",
            "epoch: [3/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.598s / 10iters, (0.060)\tData load 0.078s / 10iters, (0.007786)\n",
            "Loss_D = 1.04059041 (ave = 1.21610112)\n",
            "Loss_G = 2.99557233 (ave = 5.15746316)\n",
            "\n",
            "epoch: [3/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.678s / 10iters, (0.068)\tData load 0.072s / 10iters, (0.007182)\n",
            "Loss_D = 1.19929409 (ave = 1.20111434)\n",
            "Loss_G = 3.54191637 (ave = 5.12461198)\n",
            "\n",
            "epoch: [3/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.586s / 10iters, (0.059)\tData load 0.069s / 10iters, (0.006909)\n",
            "Loss_D = 1.72375214 (ave = 1.23484834)\n",
            "Loss_G = 6.34637403 (ave = 5.13550806)\n",
            "\n",
            "epoch: [3/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.650s / 10iters, (0.065)\tData load 0.105s / 10iters, (0.010478)\n",
            "Loss_D = 0.97037113 (ave = 1.20474964)\n",
            "Loss_G = 4.22126818 (ave = 5.05194829)\n",
            "\n",
            "epoch: [3/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.627s / 10iters, (0.063)\tData load 0.086s / 10iters, (0.008573)\n",
            "Loss_D = 1.03523624 (ave = 1.18124066)\n",
            "Loss_G = 4.33482075 (ave = 5.01239353)\n",
            "\n",
            "epoch: [3/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.645s / 10iters, (0.065)\tData load 0.073s / 10iters, (0.007336)\n",
            "Loss_D = 0.88907802 (ave = 1.17406892)\n",
            "Loss_G = 6.97761202 (ave = 4.99494541)\n",
            "\n",
            "epoch: [3/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.615s / 10iters, (0.062)\tData load 0.063s / 10iters, (0.006317)\n",
            "Loss_D = 0.64182794 (ave = 1.15621231)\n",
            "Loss_G = 4.72897673 (ave = 4.94655551)\n",
            "\n",
            "epoch: [3/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.629s / 10iters, (0.063)\tData load 0.095s / 10iters, (0.009460)\n",
            "Loss_D = 1.57054305 (ave = 1.14078664)\n",
            "Loss_G = 6.96877289 (ave = 4.91956618)\n",
            "\n",
            "epoch: [3/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.552s / 10iters, (0.055)\tData load 0.072s / 10iters, (0.007195)\n",
            "Loss_D = 1.28243017 (ave = 1.13215709)\n",
            "Loss_G = 7.17012358 (ave = 4.89964758)\n",
            "\n",
            "epoch: [3/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.666s / 10iters, (0.067)\tData load 0.095s / 10iters, (0.009542)\n",
            "Loss_D = 1.70124876 (ave = 1.17864991)\n",
            "Loss_G = 6.79434872 (ave = 4.93617611)\n",
            "\n",
            "epoch: [3/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.609s / 10iters, (0.061)\tData load 0.053s / 10iters, (0.005308)\n",
            "Loss_D = 2.85954475 (ave = 1.17732936)\n",
            "Loss_G = 2.99121213 (ave = 4.90345639)\n",
            "\n",
            "epoch: [3/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.450s / 10iters, (0.045)\tData load 0.053s / 10iters, (0.005261)\n",
            "Loss_D = 1.06625760 (ave = 1.16916049)\n",
            "Loss_G = 3.16247320 (ave = 4.89993119)\n",
            "\n",
            "epoch: [3/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.440s / 10iters, (0.044)\tData load 0.069s / 10iters, (0.006877)\n",
            "Loss_D = 1.77770972 (ave = 1.16871453)\n",
            "Loss_G = 3.80137277 (ave = 4.86301875)\n",
            "\n",
            "epoch: [3/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.074s / 3iters, (0.025)\tData load 0.013s / 3iters, (0.004327)\n",
            "Loss_D = 0.60146630 (ave = 1.16373652)\n",
            "Loss_G = 5.32386971 (ave = 4.87500520)\n",
            "\n",
            "Real Accuracy : 67.22939424031777\n",
            "Fake Accuracy : 3.7404832836809003\n",
            "epoch: [4/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.015s / 10iters, (0.502)\tData load 4.331s / 10iters, (0.433107)\n",
            "Loss_D = 0.38129103 (ave = 0.87411453)\n",
            "Loss_G = 4.66523170 (ave = 4.52340224)\n",
            "\n",
            "epoch: [4/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.662s / 10iters, (0.066)\tData load 0.088s / 10iters, (0.008842)\n",
            "Loss_D = 0.90692407 (ave = 0.90562936)\n",
            "Loss_G = 6.74055576 (ave = 4.49385169)\n",
            "\n",
            "epoch: [4/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.619s / 10iters, (0.062)\tData load 0.093s / 10iters, (0.009310)\n",
            "Loss_D = 0.65345716 (ave = 0.96810801)\n",
            "Loss_G = 4.11619759 (ave = 4.59227073)\n",
            "\n",
            "epoch: [4/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.625s / 10iters, (0.063)\tData load 0.063s / 10iters, (0.006334)\n",
            "Loss_D = 0.88620436 (ave = 0.99766092)\n",
            "Loss_G = 8.30409718 (ave = 4.65104385)\n",
            "\n",
            "epoch: [4/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.551s / 10iters, (0.055)\tData load 0.100s / 10iters, (0.009956)\n",
            "Loss_D = 1.06211686 (ave = 1.03547559)\n",
            "Loss_G = 3.26701307 (ave = 4.64190372)\n",
            "\n",
            "epoch: [4/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.687s / 10iters, (0.069)\tData load 0.077s / 10iters, (0.007690)\n",
            "Loss_D = 0.81215084 (ave = 0.99299512)\n",
            "Loss_G = 3.49460363 (ave = 4.56415118)\n",
            "\n",
            "epoch: [4/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.649s / 10iters, (0.065)\tData load 0.064s / 10iters, (0.006375)\n",
            "Loss_D = 1.52642751 (ave = 1.08503488)\n",
            "Loss_G = 4.79300690 (ave = 4.64714973)\n",
            "\n",
            "epoch: [4/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.627s / 10iters, (0.063)\tData load 0.063s / 10iters, (0.006282)\n",
            "Loss_D = 1.60904384 (ave = 1.08681905)\n",
            "Loss_G = 7.34916115 (ave = 4.65996298)\n",
            "\n",
            "epoch: [4/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.738s / 10iters, (0.074)\tData load 0.079s / 10iters, (0.007941)\n",
            "Loss_D = 0.89464939 (ave = 1.07736004)\n",
            "Loss_G = 5.32198668 (ave = 4.64490026)\n",
            "\n",
            "epoch: [4/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.628s / 10iters, (0.063)\tData load 0.084s / 10iters, (0.008403)\n",
            "Loss_D = 1.33900476 (ave = 1.06999767)\n",
            "Loss_G = 7.27743721 (ave = 4.65788767)\n",
            "\n",
            "epoch: [4/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.595s / 10iters, (0.059)\tData load 0.092s / 10iters, (0.009185)\n",
            "Loss_D = 1.18131816 (ave = 1.08539360)\n",
            "Loss_G = 4.57243538 (ave = 4.71048011)\n",
            "\n",
            "epoch: [4/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.629s / 10iters, (0.063)\tData load 0.075s / 10iters, (0.007499)\n",
            "Loss_D = 0.98444718 (ave = 1.09506096)\n",
            "Loss_G = 5.88572788 (ave = 4.73773218)\n",
            "\n",
            "epoch: [4/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.544s / 10iters, (0.054)\tData load 0.099s / 10iters, (0.009863)\n",
            "Loss_D = 0.71839422 (ave = 1.09251628)\n",
            "Loss_G = 5.05230808 (ave = 4.72562819)\n",
            "\n",
            "epoch: [4/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.560s / 10iters, (0.056)\tData load 0.080s / 10iters, (0.007978)\n",
            "Loss_D = 0.98605233 (ave = 1.08121882)\n",
            "Loss_G = 3.27673745 (ave = 4.76369889)\n",
            "\n",
            "epoch: [4/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.643s / 10iters, (0.064)\tData load 0.085s / 10iters, (0.008494)\n",
            "Loss_D = 2.25446534 (ave = 1.12241518)\n",
            "Loss_G = 2.37776756 (ave = 4.78609848)\n",
            "\n",
            "epoch: [4/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.576s / 10iters, (0.058)\tData load 0.080s / 10iters, (0.007970)\n",
            "Loss_D = 1.83773255 (ave = 1.11836573)\n",
            "Loss_G = 6.71693897 (ave = 4.79642840)\n",
            "\n",
            "epoch: [4/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.596s / 10iters, (0.060)\tData load 0.089s / 10iters, (0.008910)\n",
            "Loss_D = 1.11327839 (ave = 1.12520381)\n",
            "Loss_G = 6.00374699 (ave = 4.80101416)\n",
            "\n",
            "epoch: [4/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.637s / 10iters, (0.064)\tData load 0.089s / 10iters, (0.008950)\n",
            "Loss_D = 1.65808296 (ave = 1.11790726)\n",
            "Loss_G = 6.05948162 (ave = 4.77966340)\n",
            "\n",
            "epoch: [4/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.619s / 10iters, (0.062)\tData load 0.087s / 10iters, (0.008677)\n",
            "Loss_D = 0.55327457 (ave = 1.12541229)\n",
            "Loss_G = 3.52159452 (ave = 4.78896569)\n",
            "\n",
            "epoch: [4/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.606s / 10iters, (0.061)\tData load 0.054s / 10iters, (0.005377)\n",
            "Loss_D = 1.58794737 (ave = 1.12099199)\n",
            "Loss_G = 8.53827572 (ave = 4.79848634)\n",
            "\n",
            "epoch: [4/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.635s / 10iters, (0.064)\tData load 0.061s / 10iters, (0.006144)\n",
            "Loss_D = 0.62350458 (ave = 1.12596917)\n",
            "Loss_G = 4.91977310 (ave = 4.79788771)\n",
            "\n",
            "epoch: [4/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.583s / 10iters, (0.058)\tData load 0.068s / 10iters, (0.006848)\n",
            "Loss_D = 0.86500305 (ave = 1.12113885)\n",
            "Loss_G = 5.06166553 (ave = 4.75486679)\n",
            "\n",
            "epoch: [4/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.357s / 10iters, (0.036)\tData load 0.063s / 10iters, (0.006268)\n",
            "Loss_D = 0.75946248 (ave = 1.11077517)\n",
            "Loss_G = 2.10912657 (ave = 4.72031087)\n",
            "\n",
            "epoch: [4/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.069s / 3iters, (0.023)\tData load 0.014s / 3iters, (0.004534)\n",
            "Loss_D = 0.51400113 (ave = 1.11948205)\n",
            "Loss_G = 2.47936344 (ave = 4.72997675)\n",
            "\n",
            "Real Accuracy : 67.99073154584575\n",
            "Fake Accuracy : 4.270109235352532\n",
            "epoch: [5/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.025s / 10iters, (0.502)\tData load 4.391s / 10iters, (0.439088)\n",
            "Loss_D = 1.14633036 (ave = 1.10842974)\n",
            "Loss_G = 4.61280775 (ave = 4.60177381)\n",
            "\n",
            "epoch: [5/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.697s / 10iters, (0.070)\tData load 0.112s / 10iters, (0.011228)\n",
            "Loss_D = 1.25802493 (ave = 0.98706027)\n",
            "Loss_G = 3.83166385 (ave = 4.68526920)\n",
            "\n",
            "epoch: [5/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.660s / 10iters, (0.066)\tData load 0.067s / 10iters, (0.006654)\n",
            "Loss_D = 0.46596837 (ave = 0.95829521)\n",
            "Loss_G = 4.49338531 (ave = 4.81456931)\n",
            "\n",
            "epoch: [5/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.613s / 10iters, (0.061)\tData load 0.064s / 10iters, (0.006450)\n",
            "Loss_D = 1.70097756 (ave = 0.97327295)\n",
            "Loss_G = 6.09203672 (ave = 4.82705492)\n",
            "\n",
            "epoch: [5/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.652s / 10iters, (0.065)\tData load 0.103s / 10iters, (0.010318)\n",
            "Loss_D = 3.13321233 (ave = 1.03028412)\n",
            "Loss_G = 2.37244177 (ave = 4.88323379)\n",
            "\n",
            "epoch: [5/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.621s / 10iters, (0.062)\tData load 0.087s / 10iters, (0.008714)\n",
            "Loss_D = 0.59331357 (ave = 1.12085447)\n",
            "Loss_G = 2.04889464 (ave = 4.85933639)\n",
            "\n",
            "epoch: [5/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.664s / 10iters, (0.066)\tData load 0.076s / 10iters, (0.007625)\n",
            "Loss_D = 1.20465767 (ave = 1.13419218)\n",
            "Loss_G = 6.03090477 (ave = 4.89703690)\n",
            "\n",
            "epoch: [5/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.612s / 10iters, (0.061)\tData load 0.082s / 10iters, (0.008236)\n",
            "Loss_D = 0.84118527 (ave = 1.11972467)\n",
            "Loss_G = 5.87454653 (ave = 4.86811035)\n",
            "\n",
            "epoch: [5/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.577s / 10iters, (0.058)\tData load 0.075s / 10iters, (0.007544)\n",
            "Loss_D = 1.57903159 (ave = 1.13450981)\n",
            "Loss_G = 4.36737156 (ave = 4.86435960)\n",
            "\n",
            "epoch: [5/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.602s / 10iters, (0.060)\tData load 0.089s / 10iters, (0.008943)\n",
            "Loss_D = 1.19869554 (ave = 1.12544306)\n",
            "Loss_G = 5.98101854 (ave = 4.81956309)\n",
            "\n",
            "epoch: [5/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.635s / 10iters, (0.064)\tData load 0.089s / 10iters, (0.008873)\n",
            "Loss_D = 0.92168570 (ave = 1.11952255)\n",
            "Loss_G = 3.93292999 (ave = 4.76591982)\n",
            "\n",
            "epoch: [5/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.560s / 10iters, (0.056)\tData load 0.079s / 10iters, (0.007889)\n",
            "Loss_D = 0.94899189 (ave = 1.11905904)\n",
            "Loss_G = 3.90708637 (ave = 4.76223543)\n",
            "\n",
            "epoch: [5/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.648s / 10iters, (0.065)\tData load 0.097s / 10iters, (0.009675)\n",
            "Loss_D = 1.45275521 (ave = 1.09991830)\n",
            "Loss_G = 2.27925754 (ave = 4.74555177)\n",
            "\n",
            "epoch: [5/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.628s / 10iters, (0.063)\tData load 0.114s / 10iters, (0.011413)\n",
            "Loss_D = 0.93577886 (ave = 1.12951158)\n",
            "Loss_G = 4.91619301 (ave = 4.78529519)\n",
            "\n",
            "epoch: [5/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.645s / 10iters, (0.064)\tData load 0.082s / 10iters, (0.008202)\n",
            "Loss_D = 0.59722316 (ave = 1.12417214)\n",
            "Loss_G = 3.57820082 (ave = 4.76654146)\n",
            "\n",
            "epoch: [5/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.585s / 10iters, (0.058)\tData load 0.057s / 10iters, (0.005725)\n",
            "Loss_D = 2.61431932 (ave = 1.14141520)\n",
            "Loss_G = 8.10493660 (ave = 4.78308199)\n",
            "\n",
            "epoch: [5/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.668s / 10iters, (0.067)\tData load 0.070s / 10iters, (0.007039)\n",
            "Loss_D = 1.14083159 (ave = 1.14337795)\n",
            "Loss_G = 6.52446508 (ave = 4.80313711)\n",
            "\n",
            "epoch: [5/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.561s / 10iters, (0.056)\tData load 0.095s / 10iters, (0.009463)\n",
            "Loss_D = 1.25103652 (ave = 1.12782307)\n",
            "Loss_G = 6.69511986 (ave = 4.77800592)\n",
            "\n",
            "epoch: [5/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.648s / 10iters, (0.065)\tData load 0.074s / 10iters, (0.007366)\n",
            "Loss_D = 0.99999511 (ave = 1.13170961)\n",
            "Loss_G = 3.25539303 (ave = 4.76779737)\n",
            "\n",
            "epoch: [5/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.601s / 10iters, (0.060)\tData load 0.117s / 10iters, (0.011740)\n",
            "Loss_D = 1.10597146 (ave = 1.13227994)\n",
            "Loss_G = 4.59899139 (ave = 4.76935049)\n",
            "\n",
            "epoch: [5/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.595s / 10iters, (0.059)\tData load 0.092s / 10iters, (0.009190)\n",
            "Loss_D = 2.17838693 (ave = 1.13706577)\n",
            "Loss_G = 6.94582844 (ave = 4.74226441)\n",
            "\n",
            "epoch: [5/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.615s / 10iters, (0.061)\tData load 0.109s / 10iters, (0.010862)\n",
            "Loss_D = 0.94588995 (ave = 1.13122338)\n",
            "Loss_G = 5.55482960 (ave = 4.75034188)\n",
            "\n",
            "epoch: [5/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.306s / 10iters, (0.031)\tData load 0.060s / 10iters, (0.006021)\n",
            "Loss_D = 0.90567780 (ave = 1.12616190)\n",
            "Loss_G = 5.71462536 (ave = 4.73456179)\n",
            "\n",
            "epoch: [5/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.064s / 3iters, (0.021)\tData load 0.015s / 3iters, (0.004838)\n",
            "Loss_D = 1.40015471 (ave = 1.12512998)\n",
            "Loss_G = 6.93830776 (ave = 4.74735443)\n",
            "\n",
            "Real Accuracy : 68.52035749751738\n",
            "Fake Accuracy : 4.303210857332009\n",
            "epoch: [6/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.058s / 10iters, (0.506)\tData load 4.356s / 10iters, (0.435553)\n",
            "Loss_D = 0.73058903 (ave = 0.95066581)\n",
            "Loss_G = 5.91176558 (ave = 4.72506037)\n",
            "\n",
            "epoch: [6/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.692s / 10iters, (0.069)\tData load 0.084s / 10iters, (0.008401)\n",
            "Loss_D = 0.95323277 (ave = 1.07578215)\n",
            "Loss_G = 4.01928234 (ave = 4.60944144)\n",
            "\n",
            "epoch: [6/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.637s / 10iters, (0.064)\tData load 0.120s / 10iters, (0.012041)\n",
            "Loss_D = 0.32552847 (ave = 0.99609071)\n",
            "Loss_G = 6.56899595 (ave = 4.77015990)\n",
            "\n",
            "epoch: [6/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.605s / 10iters, (0.061)\tData load 0.086s / 10iters, (0.008626)\n",
            "Loss_D = 1.23540270 (ave = 1.00792440)\n",
            "Loss_G = 2.63087177 (ave = 4.70162349)\n",
            "\n",
            "epoch: [6/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.625s / 10iters, (0.063)\tData load 0.068s / 10iters, (0.006810)\n",
            "Loss_D = 0.45603949 (ave = 0.97431835)\n",
            "Loss_G = 6.95796394 (ave = 4.71981454)\n",
            "\n",
            "epoch: [6/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.607s / 10iters, (0.061)\tData load 0.115s / 10iters, (0.011530)\n",
            "Loss_D = 0.70811409 (ave = 0.95211794)\n",
            "Loss_G = 4.68334198 (ave = 4.64376367)\n",
            "\n",
            "epoch: [6/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.601s / 10iters, (0.060)\tData load 0.088s / 10iters, (0.008833)\n",
            "Loss_D = 0.53749418 (ave = 1.00244780)\n",
            "Loss_G = 4.38442421 (ave = 4.71232007)\n",
            "\n",
            "epoch: [6/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.655s / 10iters, (0.066)\tData load 0.112s / 10iters, (0.011152)\n",
            "Loss_D = 0.69646335 (ave = 1.03179243)\n",
            "Loss_G = 6.33034325 (ave = 4.78985545)\n",
            "\n",
            "epoch: [6/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.637s / 10iters, (0.064)\tData load 0.059s / 10iters, (0.005867)\n",
            "Loss_D = 1.23174298 (ave = 1.01987085)\n",
            "Loss_G = 5.75311232 (ave = 4.71910892)\n",
            "\n",
            "epoch: [6/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.622s / 10iters, (0.062)\tData load 0.053s / 10iters, (0.005302)\n",
            "Loss_D = 0.90255380 (ave = 1.06581906)\n",
            "Loss_G = 5.54133892 (ave = 4.71396925)\n",
            "\n",
            "epoch: [6/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.628s / 10iters, (0.063)\tData load 0.106s / 10iters, (0.010642)\n",
            "Loss_D = 0.54601145 (ave = 1.08583559)\n",
            "Loss_G = 4.33478308 (ave = 4.72226716)\n",
            "\n",
            "epoch: [6/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.729s / 10iters, (0.073)\tData load 0.077s / 10iters, (0.007702)\n",
            "Loss_D = 0.65647548 (ave = 1.08124540)\n",
            "Loss_G = 4.61285210 (ave = 4.70989952)\n",
            "\n",
            "epoch: [6/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.613s / 10iters, (0.061)\tData load 0.087s / 10iters, (0.008743)\n",
            "Loss_D = 1.01690030 (ave = 1.07677681)\n",
            "Loss_G = 4.57525682 (ave = 4.68432707)\n",
            "\n",
            "epoch: [6/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.630s / 10iters, (0.063)\tData load 0.100s / 10iters, (0.010041)\n",
            "Loss_D = 0.84768540 (ave = 1.06873256)\n",
            "Loss_G = 3.32112646 (ave = 4.65114812)\n",
            "\n",
            "epoch: [6/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.615s / 10iters, (0.061)\tData load 0.079s / 10iters, (0.007891)\n",
            "Loss_D = 2.82964468 (ave = 1.07038405)\n",
            "Loss_G = 1.60100424 (ave = 4.62563496)\n",
            "\n",
            "epoch: [6/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.603s / 10iters, (0.060)\tData load 0.066s / 10iters, (0.006642)\n",
            "Loss_D = 0.96865034 (ave = 1.08884361)\n",
            "Loss_G = 2.63194633 (ave = 4.59800995)\n",
            "\n",
            "epoch: [6/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.680s / 10iters, (0.068)\tData load 0.093s / 10iters, (0.009309)\n",
            "Loss_D = 0.76566863 (ave = 1.09934984)\n",
            "Loss_G = 5.39531660 (ave = 4.61392685)\n",
            "\n",
            "epoch: [6/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.596s / 10iters, (0.060)\tData load 0.067s / 10iters, (0.006678)\n",
            "Loss_D = 1.22988582 (ave = 1.11575735)\n",
            "Loss_G = 5.49167156 (ave = 4.61144226)\n",
            "\n",
            "epoch: [6/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.559s / 10iters, (0.056)\tData load 0.089s / 10iters, (0.008925)\n",
            "Loss_D = 1.50437689 (ave = 1.12682089)\n",
            "Loss_G = 4.60400295 (ave = 4.59428684)\n",
            "\n",
            "epoch: [6/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.680s / 10iters, (0.068)\tData load 0.089s / 10iters, (0.008893)\n",
            "Loss_D = 0.77321249 (ave = 1.12769962)\n",
            "Loss_G = 2.56615400 (ave = 4.56203468)\n",
            "\n",
            "epoch: [6/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.585s / 10iters, (0.059)\tData load 0.083s / 10iters, (0.008257)\n",
            "Loss_D = 0.74409968 (ave = 1.12006085)\n",
            "Loss_G = 2.68621063 (ave = 4.51738774)\n",
            "\n",
            "epoch: [6/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.650s / 10iters, (0.065)\tData load 0.084s / 10iters, (0.008440)\n",
            "Loss_D = 0.54433465 (ave = 1.10275135)\n",
            "Loss_G = 4.78564358 (ave = 4.49436293)\n",
            "\n",
            "epoch: [6/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.348s / 10iters, (0.035)\tData load 0.058s / 10iters, (0.005766)\n",
            "Loss_D = 0.87994736 (ave = 1.10330972)\n",
            "Loss_G = 6.10356951 (ave = 4.49102930)\n",
            "\n",
            "epoch: [6/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.070s / 3iters, (0.023)\tData load 0.015s / 3iters, (0.004865)\n",
            "Loss_D = 1.57980084 (ave = 1.10661005)\n",
            "Loss_G = 11.12932205 (ave = 4.51014960)\n",
            "\n",
            "Real Accuracy : 70.27474346242965\n",
            "Fake Accuracy : 4.766633565044687\n",
            "epoch: [7/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.107s / 10iters, (0.511)\tData load 4.439s / 10iters, (0.443892)\n",
            "Loss_D = 1.65035129 (ave = 1.33592350)\n",
            "Loss_G = 7.46664143 (ave = 4.80817796)\n",
            "\n",
            "epoch: [7/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.695s / 10iters, (0.069)\tData load 0.103s / 10iters, (0.010334)\n",
            "Loss_D = 0.73834676 (ave = 1.17419658)\n",
            "Loss_G = 5.47198391 (ave = 4.49703302)\n",
            "\n",
            "epoch: [7/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.689s / 10iters, (0.069)\tData load 0.063s / 10iters, (0.006310)\n",
            "Loss_D = 0.96946084 (ave = 1.05229579)\n",
            "Loss_G = 4.33344221 (ave = 4.48832608)\n",
            "\n",
            "epoch: [7/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.660s / 10iters, (0.066)\tData load 0.077s / 10iters, (0.007684)\n",
            "Loss_D = 1.65209401 (ave = 1.09452493)\n",
            "Loss_G = 3.01062059 (ave = 4.45842575)\n",
            "\n",
            "epoch: [7/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.617s / 10iters, (0.062)\tData load 0.069s / 10iters, (0.006864)\n",
            "Loss_D = 0.77972800 (ave = 1.09392395)\n",
            "Loss_G = 3.72157335 (ave = 4.34948922)\n",
            "\n",
            "epoch: [7/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.678s / 10iters, (0.068)\tData load 0.063s / 10iters, (0.006303)\n",
            "Loss_D = 0.59762436 (ave = 1.07260333)\n",
            "Loss_G = 5.65651512 (ave = 4.34536763)\n",
            "\n",
            "epoch: [7/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.726s / 10iters, (0.073)\tData load 0.078s / 10iters, (0.007769)\n",
            "Loss_D = 0.70690459 (ave = 1.06036511)\n",
            "Loss_G = 4.44388771 (ave = 4.29210916)\n",
            "\n",
            "epoch: [7/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.642s / 10iters, (0.064)\tData load 0.087s / 10iters, (0.008710)\n",
            "Loss_D = 0.46684951 (ave = 1.09371524)\n",
            "Loss_G = 3.60284019 (ave = 4.33191963)\n",
            "\n",
            "epoch: [7/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.622s / 10iters, (0.062)\tData load 0.091s / 10iters, (0.009057)\n",
            "Loss_D = 1.59913409 (ave = 1.09334222)\n",
            "Loss_G = 6.91746807 (ave = 4.39821954)\n",
            "\n",
            "epoch: [7/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.622s / 10iters, (0.062)\tData load 0.099s / 10iters, (0.009906)\n",
            "Loss_D = 1.61304736 (ave = 1.10528676)\n",
            "Loss_G = 4.01467943 (ave = 4.35538040)\n",
            "\n",
            "epoch: [7/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.613s / 10iters, (0.061)\tData load 0.103s / 10iters, (0.010279)\n",
            "Loss_D = 2.53438377 (ave = 1.13133200)\n",
            "Loss_G = 6.91207981 (ave = 4.35208168)\n",
            "\n",
            "epoch: [7/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.616s / 10iters, (0.062)\tData load 0.074s / 10iters, (0.007388)\n",
            "Loss_D = 0.54734910 (ave = 1.14734716)\n",
            "Loss_G = 2.75635862 (ave = 4.32710861)\n",
            "\n",
            "epoch: [7/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.718s / 10iters, (0.072)\tData load 0.075s / 10iters, (0.007476)\n",
            "Loss_D = 1.06144595 (ave = 1.14192717)\n",
            "Loss_G = 5.24844027 (ave = 4.33235304)\n",
            "\n",
            "epoch: [7/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.685s / 10iters, (0.068)\tData load 0.070s / 10iters, (0.006960)\n",
            "Loss_D = 2.80498266 (ave = 1.15879473)\n",
            "Loss_G = 1.68856406 (ave = 4.32935840)\n",
            "\n",
            "epoch: [7/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.584s / 10iters, (0.058)\tData load 0.076s / 10iters, (0.007598)\n",
            "Loss_D = 1.02832997 (ave = 1.16186594)\n",
            "Loss_G = 5.46079302 (ave = 4.34002375)\n",
            "\n",
            "epoch: [7/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.699s / 10iters, (0.070)\tData load 0.087s / 10iters, (0.008737)\n",
            "Loss_D = 0.36656371 (ave = 1.14249745)\n",
            "Loss_G = 3.75941944 (ave = 4.31091973)\n",
            "\n",
            "epoch: [7/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.678s / 10iters, (0.068)\tData load 0.082s / 10iters, (0.008195)\n",
            "Loss_D = 0.76827627 (ave = 1.13738636)\n",
            "Loss_G = 2.73458338 (ave = 4.29536952)\n",
            "\n",
            "epoch: [7/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.627s / 10iters, (0.063)\tData load 0.084s / 10iters, (0.008365)\n",
            "Loss_D = 1.75764167 (ave = 1.12710796)\n",
            "Loss_G = 9.77887630 (ave = 4.31949939)\n",
            "\n",
            "epoch: [7/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.677s / 10iters, (0.068)\tData load 0.087s / 10iters, (0.008729)\n",
            "Loss_D = 0.91302568 (ave = 1.13192794)\n",
            "Loss_G = 2.86300635 (ave = 4.31263246)\n",
            "\n",
            "epoch: [7/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.602s / 10iters, (0.060)\tData load 0.061s / 10iters, (0.006115)\n",
            "Loss_D = 0.80913121 (ave = 1.11966611)\n",
            "Loss_G = 3.36246753 (ave = 4.31385367)\n",
            "\n",
            "epoch: [7/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.575s / 10iters, (0.058)\tData load 0.077s / 10iters, (0.007720)\n",
            "Loss_D = 1.53022945 (ave = 1.11086602)\n",
            "Loss_G = 1.77690589 (ave = 4.27430683)\n",
            "\n",
            "epoch: [7/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.712s / 10iters, (0.071)\tData load 0.069s / 10iters, (0.006935)\n",
            "Loss_D = 0.76995170 (ave = 1.13351287)\n",
            "Loss_G = 3.30631280 (ave = 4.29261628)\n",
            "\n",
            "epoch: [7/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.306s / 10iters, (0.031)\tData load 0.068s / 10iters, (0.006793)\n",
            "Loss_D = 0.73463738 (ave = 1.12749490)\n",
            "Loss_G = 3.66382933 (ave = 4.27999709)\n",
            "\n",
            "epoch: [7/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.066s / 3iters, (0.022)\tData load 0.015s / 3iters, (0.005107)\n",
            "Loss_D = 0.57937056 (ave = 1.12243777)\n",
            "Loss_G = 4.52040482 (ave = 4.27709637)\n",
            "\n",
            "Real Accuracy : 68.98378020523006\n",
            "Fake Accuracy : 4.336312479311486\n",
            "epoch: [8/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.043s / 10iters, (0.504)\tData load 4.364s / 10iters, (0.436404)\n",
            "Loss_D = 0.96401948 (ave = 1.06420198)\n",
            "Loss_G = 4.74414778 (ave = 3.96197399)\n",
            "\n",
            "epoch: [8/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.666s / 10iters, (0.067)\tData load 0.071s / 10iters, (0.007140)\n",
            "Loss_D = 1.80301452 (ave = 1.05171037)\n",
            "Loss_G = 4.28473234 (ave = 4.10103185)\n",
            "\n",
            "epoch: [8/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.636s / 10iters, (0.064)\tData load 0.088s / 10iters, (0.008837)\n",
            "Loss_D = 0.95385242 (ave = 1.03677443)\n",
            "Loss_G = 7.63362932 (ave = 4.07486082)\n",
            "\n",
            "epoch: [8/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.608s / 10iters, (0.061)\tData load 0.079s / 10iters, (0.007918)\n",
            "Loss_D = 0.69796962 (ave = 1.01566601)\n",
            "Loss_G = 5.85997820 (ave = 4.21227271)\n",
            "\n",
            "epoch: [8/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.577s / 10iters, (0.058)\tData load 0.101s / 10iters, (0.010142)\n",
            "Loss_D = 1.18408573 (ave = 1.03467981)\n",
            "Loss_G = 4.86626577 (ave = 4.22302724)\n",
            "\n",
            "epoch: [8/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.599s / 10iters, (0.060)\tData load 0.097s / 10iters, (0.009701)\n",
            "Loss_D = 2.35532761 (ave = 1.03723363)\n",
            "Loss_G = 9.55169106 (ave = 4.28249475)\n",
            "\n",
            "epoch: [8/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.608s / 10iters, (0.061)\tData load 0.063s / 10iters, (0.006262)\n",
            "Loss_D = 1.66769814 (ave = 1.07617514)\n",
            "Loss_G = 3.95098019 (ave = 4.25759983)\n",
            "\n",
            "epoch: [8/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.668s / 10iters, (0.067)\tData load 0.081s / 10iters, (0.008087)\n",
            "Loss_D = 0.86511499 (ave = 1.08619365)\n",
            "Loss_G = 2.52150249 (ave = 4.21867137)\n",
            "\n",
            "epoch: [8/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.666s / 10iters, (0.067)\tData load 0.075s / 10iters, (0.007525)\n",
            "Loss_D = 0.77315933 (ave = 1.07625881)\n",
            "Loss_G = 3.15170908 (ave = 4.23360921)\n",
            "\n",
            "epoch: [8/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.603s / 10iters, (0.060)\tData load 0.051s / 10iters, (0.005081)\n",
            "Loss_D = 0.99459243 (ave = 1.04894853)\n",
            "Loss_G = 4.08559084 (ave = 4.26248241)\n",
            "\n",
            "epoch: [8/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.641s / 10iters, (0.064)\tData load 0.064s / 10iters, (0.006430)\n",
            "Loss_D = 1.22149742 (ave = 1.04904332)\n",
            "Loss_G = 7.51770115 (ave = 4.27580624)\n",
            "\n",
            "epoch: [8/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.693s / 10iters, (0.069)\tData load 0.097s / 10iters, (0.009681)\n",
            "Loss_D = 0.94496071 (ave = 1.07253070)\n",
            "Loss_G = 3.60654473 (ave = 4.25629873)\n",
            "\n",
            "epoch: [8/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.635s / 10iters, (0.064)\tData load 0.076s / 10iters, (0.007596)\n",
            "Loss_D = 1.63727498 (ave = 1.12783017)\n",
            "Loss_G = 4.53234720 (ave = 4.24504987)\n",
            "\n",
            "epoch: [8/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.572s / 10iters, (0.057)\tData load 0.093s / 10iters, (0.009317)\n",
            "Loss_D = 1.52874351 (ave = 1.12217734)\n",
            "Loss_G = 5.31969213 (ave = 4.22036162)\n",
            "\n",
            "epoch: [8/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.665s / 10iters, (0.066)\tData load 0.083s / 10iters, (0.008346)\n",
            "Loss_D = 0.81251711 (ave = 1.11383111)\n",
            "Loss_G = 2.74973392 (ave = 4.20309929)\n",
            "\n",
            "epoch: [8/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.616s / 10iters, (0.062)\tData load 0.077s / 10iters, (0.007704)\n",
            "Loss_D = 1.56773710 (ave = 1.11232748)\n",
            "Loss_G = 6.58235073 (ave = 4.19538446)\n",
            "\n",
            "epoch: [8/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.567s / 10iters, (0.057)\tData load 0.072s / 10iters, (0.007210)\n",
            "Loss_D = 0.65639848 (ave = 1.10027276)\n",
            "Loss_G = 4.44928074 (ave = 4.17747086)\n",
            "\n",
            "epoch: [8/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.643s / 10iters, (0.064)\tData load 0.096s / 10iters, (0.009574)\n",
            "Loss_D = 1.09918702 (ave = 1.13315190)\n",
            "Loss_G = 4.23157930 (ave = 4.19385997)\n",
            "\n",
            "epoch: [8/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.528s / 10iters, (0.053)\tData load 0.063s / 10iters, (0.006275)\n",
            "Loss_D = 1.09220409 (ave = 1.12720102)\n",
            "Loss_G = 4.13642359 (ave = 4.19643291)\n",
            "\n",
            "epoch: [8/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.644s / 10iters, (0.064)\tData load 0.091s / 10iters, (0.009066)\n",
            "Loss_D = 0.60690868 (ave = 1.14981802)\n",
            "Loss_G = 5.92242861 (ave = 4.22959623)\n",
            "\n",
            "epoch: [8/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.612s / 10iters, (0.061)\tData load 0.103s / 10iters, (0.010335)\n",
            "Loss_D = 1.02503324 (ave = 1.14384850)\n",
            "Loss_G = 3.05024576 (ave = 4.19864932)\n",
            "\n",
            "epoch: [8/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.583s / 10iters, (0.058)\tData load 0.078s / 10iters, (0.007845)\n",
            "Loss_D = 0.92298537 (ave = 1.13379923)\n",
            "Loss_G = 3.89309263 (ave = 4.21009126)\n",
            "\n",
            "epoch: [8/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.307s / 10iters, (0.031)\tData load 0.058s / 10iters, (0.005805)\n",
            "Loss_D = 1.02002072 (ave = 1.13814778)\n",
            "Loss_G = 5.85183907 (ave = 4.21452056)\n",
            "\n",
            "epoch: [8/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.066s / 3iters, (0.022)\tData load 0.013s / 3iters, (0.004349)\n",
            "Loss_D = 0.76691139 (ave = 1.13797684)\n",
            "Loss_G = 6.72688818 (ave = 4.21641433)\n",
            "\n",
            "Real Accuracy : 69.57960940086065\n",
            "Fake Accuracy : 5.031446540880503\n",
            "epoch: [9/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.003s / 10iters, (0.500)\tData load 4.391s / 10iters, (0.439057)\n",
            "Loss_D = 0.90690368 (ave = 0.81627768)\n",
            "Loss_G = 3.29053760 (ave = 4.09525783)\n",
            "\n",
            "epoch: [9/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.703s / 10iters, (0.070)\tData load 0.110s / 10iters, (0.011000)\n",
            "Loss_D = 1.32234514 (ave = 0.98475075)\n",
            "Loss_G = 3.43567872 (ave = 4.24861686)\n",
            "\n",
            "epoch: [9/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.673s / 10iters, (0.067)\tData load 0.073s / 10iters, (0.007270)\n",
            "Loss_D = 1.60552394 (ave = 1.03239148)\n",
            "Loss_G = 2.65312719 (ave = 4.21614073)\n",
            "\n",
            "epoch: [9/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.594s / 10iters, (0.059)\tData load 0.082s / 10iters, (0.008209)\n",
            "Loss_D = 1.15593302 (ave = 1.05431656)\n",
            "Loss_G = 2.91609979 (ave = 4.23214437)\n",
            "\n",
            "epoch: [9/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.596s / 10iters, (0.060)\tData load 0.068s / 10iters, (0.006849)\n",
            "Loss_D = 1.34743619 (ave = 1.14588394)\n",
            "Loss_G = 5.22685432 (ave = 4.19504244)\n",
            "\n",
            "epoch: [9/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.645s / 10iters, (0.064)\tData load 0.095s / 10iters, (0.009515)\n",
            "Loss_D = 0.97119725 (ave = 1.09267774)\n",
            "Loss_G = 4.85934401 (ave = 4.07245263)\n",
            "\n",
            "epoch: [9/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.651s / 10iters, (0.065)\tData load 0.085s / 10iters, (0.008546)\n",
            "Loss_D = 1.67752266 (ave = 1.12631749)\n",
            "Loss_G = 2.47445202 (ave = 4.09055138)\n",
            "\n",
            "epoch: [9/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.672s / 10iters, (0.067)\tData load 0.086s / 10iters, (0.008595)\n",
            "Loss_D = 1.22947454 (ave = 1.12499181)\n",
            "Loss_G = 3.63818645 (ave = 4.03928401)\n",
            "\n",
            "epoch: [9/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.585s / 10iters, (0.058)\tData load 0.073s / 10iters, (0.007328)\n",
            "Loss_D = 0.96547687 (ave = 1.13689422)\n",
            "Loss_G = 4.28478193 (ave = 4.02285152)\n",
            "\n",
            "epoch: [9/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.609s / 10iters, (0.061)\tData load 0.098s / 10iters, (0.009752)\n",
            "Loss_D = 1.35315573 (ave = 1.12765483)\n",
            "Loss_G = 5.60678005 (ave = 4.04639686)\n",
            "\n",
            "epoch: [9/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.609s / 10iters, (0.061)\tData load 0.108s / 10iters, (0.010777)\n",
            "Loss_D = 1.17572117 (ave = 1.12925812)\n",
            "Loss_G = 5.41040850 (ave = 4.05079483)\n",
            "\n",
            "epoch: [9/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.540s / 10iters, (0.054)\tData load 0.085s / 10iters, (0.008459)\n",
            "Loss_D = 1.13495922 (ave = 1.16282885)\n",
            "Loss_G = 3.54087114 (ave = 4.06391188)\n",
            "\n",
            "epoch: [9/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.747s / 10iters, (0.075)\tData load 0.107s / 10iters, (0.010691)\n",
            "Loss_D = 1.16758883 (ave = 1.14954792)\n",
            "Loss_G = 3.22582889 (ave = 4.04636836)\n",
            "\n",
            "epoch: [9/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.573s / 10iters, (0.057)\tData load 0.072s / 10iters, (0.007155)\n",
            "Loss_D = 1.09708548 (ave = 1.13047445)\n",
            "Loss_G = 4.92566967 (ave = 4.02230694)\n",
            "\n",
            "epoch: [9/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.644s / 10iters, (0.064)\tData load 0.074s / 10iters, (0.007432)\n",
            "Loss_D = 0.70473617 (ave = 1.10933286)\n",
            "Loss_G = 3.00585675 (ave = 3.97905209)\n",
            "\n",
            "epoch: [9/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.597s / 10iters, (0.060)\tData load 0.057s / 10iters, (0.005679)\n",
            "Loss_D = 0.82567084 (ave = 1.09685446)\n",
            "Loss_G = 3.15181351 (ave = 3.99497136)\n",
            "\n",
            "epoch: [9/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.597s / 10iters, (0.060)\tData load 0.070s / 10iters, (0.006967)\n",
            "Loss_D = 0.35972202 (ave = 1.08407958)\n",
            "Loss_G = 2.41326785 (ave = 3.98190788)\n",
            "\n",
            "epoch: [9/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.619s / 10iters, (0.062)\tData load 0.091s / 10iters, (0.009081)\n",
            "Loss_D = 1.00916898 (ave = 1.06992954)\n",
            "Loss_G = 1.93566382 (ave = 3.98418282)\n",
            "\n",
            "epoch: [9/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.640s / 10iters, (0.064)\tData load 0.076s / 10iters, (0.007575)\n",
            "Loss_D = 0.53944606 (ave = 1.07496498)\n",
            "Loss_G = 4.05614328 (ave = 4.01459021)\n",
            "\n",
            "epoch: [9/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.593s / 10iters, (0.059)\tData load 0.096s / 10iters, (0.009641)\n",
            "Loss_D = 0.74409366 (ave = 1.06631900)\n",
            "Loss_G = 6.84020424 (ave = 4.00770416)\n",
            "\n",
            "epoch: [9/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.605s / 10iters, (0.061)\tData load 0.071s / 10iters, (0.007142)\n",
            "Loss_D = 0.68225211 (ave = 1.05962097)\n",
            "Loss_G = 4.61026287 (ave = 4.00433659)\n",
            "\n",
            "epoch: [9/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.586s / 10iters, (0.059)\tData load 0.081s / 10iters, (0.008110)\n",
            "Loss_D = 0.62298954 (ave = 1.06159609)\n",
            "Loss_G = 5.99284601 (ave = 4.00375090)\n",
            "\n",
            "epoch: [9/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.355s / 10iters, (0.036)\tData load 0.075s / 10iters, (0.007458)\n",
            "Loss_D = 1.10358822 (ave = 1.06443719)\n",
            "Loss_G = 4.65374136 (ave = 4.00261152)\n",
            "\n",
            "epoch: [9/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.068s / 3iters, (0.023)\tData load 0.013s / 3iters, (0.004497)\n",
            "Loss_D = 1.38677025 (ave = 1.06296754)\n",
            "Loss_G = 6.88000965 (ave = 4.01878434)\n",
            "\n",
            "Real Accuracy : 71.06918238993711\n",
            "Fake Accuracy : 5.892088712346905\n",
            "epoch: [10/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.248s / 10iters, (0.525)\tData load 4.511s / 10iters, (0.451103)\n",
            "Loss_D = 0.50952744 (ave = 0.93881032)\n",
            "Loss_G = 4.27203226 (ave = 4.02061006)\n",
            "\n",
            "epoch: [10/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.690s / 10iters, (0.069)\tData load 0.082s / 10iters, (0.008192)\n",
            "Loss_D = 1.16952991 (ave = 0.99561837)\n",
            "Loss_G = 4.88555956 (ave = 4.19491245)\n",
            "\n",
            "epoch: [10/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.645s / 10iters, (0.064)\tData load 0.112s / 10iters, (0.011249)\n",
            "Loss_D = 1.16676199 (ave = 1.02523834)\n",
            "Loss_G = 5.35948849 (ave = 4.04222915)\n",
            "\n",
            "epoch: [10/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.606s / 10iters, (0.061)\tData load 0.103s / 10iters, (0.010348)\n",
            "Loss_D = 0.84570837 (ave = 0.97474996)\n",
            "Loss_G = 3.92482638 (ave = 4.03252715)\n",
            "\n",
            "epoch: [10/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.606s / 10iters, (0.061)\tData load 0.090s / 10iters, (0.008974)\n",
            "Loss_D = 0.94471121 (ave = 0.93759676)\n",
            "Loss_G = 4.25341511 (ave = 3.98561142)\n",
            "\n",
            "epoch: [10/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.592s / 10iters, (0.059)\tData load 0.081s / 10iters, (0.008071)\n",
            "Loss_D = 0.93687654 (ave = 0.97289482)\n",
            "Loss_G = 3.32826519 (ave = 3.98019372)\n",
            "\n",
            "epoch: [10/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.754s / 10iters, (0.075)\tData load 0.103s / 10iters, (0.010331)\n",
            "Loss_D = 0.80866456 (ave = 0.97141264)\n",
            "Loss_G = 3.44174147 (ave = 3.93697413)\n",
            "\n",
            "epoch: [10/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.656s / 10iters, (0.066)\tData load 0.097s / 10iters, (0.009686)\n",
            "Loss_D = 1.16953635 (ave = 0.97065302)\n",
            "Loss_G = 2.66844082 (ave = 3.94726539)\n",
            "\n",
            "epoch: [10/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.582s / 10iters, (0.058)\tData load 0.073s / 10iters, (0.007279)\n",
            "Loss_D = 0.35486490 (ave = 0.96598005)\n",
            "Loss_G = 2.97988892 (ave = 3.94468453)\n",
            "\n",
            "epoch: [10/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.651s / 10iters, (0.065)\tData load 0.106s / 10iters, (0.010590)\n",
            "Loss_D = 1.99743199 (ave = 0.98695846)\n",
            "Loss_G = 4.78660870 (ave = 3.96833899)\n",
            "\n",
            "epoch: [10/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.583s / 10iters, (0.058)\tData load 0.109s / 10iters, (0.010866)\n",
            "Loss_D = 0.90848607 (ave = 0.99078030)\n",
            "Loss_G = 2.56413937 (ave = 3.99795944)\n",
            "\n",
            "epoch: [10/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.788s / 10iters, (0.079)\tData load 0.111s / 10iters, (0.011138)\n",
            "Loss_D = 0.88971186 (ave = 1.00743781)\n",
            "Loss_G = 2.60709143 (ave = 3.98534531)\n",
            "\n",
            "epoch: [10/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.621s / 10iters, (0.062)\tData load 0.080s / 10iters, (0.007967)\n",
            "Loss_D = 0.82852137 (ave = 1.00814009)\n",
            "Loss_G = 6.08111000 (ave = 3.99754286)\n",
            "\n",
            "epoch: [10/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.614s / 10iters, (0.061)\tData load 0.088s / 10iters, (0.008770)\n",
            "Loss_D = 0.46240517 (ave = 0.99719414)\n",
            "Loss_G = 3.76691651 (ave = 3.99794186)\n",
            "\n",
            "epoch: [10/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.617s / 10iters, (0.062)\tData load 0.067s / 10iters, (0.006675)\n",
            "Loss_D = 0.72788638 (ave = 1.00258944)\n",
            "Loss_G = 4.23664808 (ave = 4.03852283)\n",
            "\n",
            "epoch: [10/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.629s / 10iters, (0.063)\tData load 0.083s / 10iters, (0.008338)\n",
            "Loss_D = 0.35598010 (ave = 1.01249223)\n",
            "Loss_G = 4.75212908 (ave = 4.05737015)\n",
            "\n",
            "epoch: [10/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.622s / 10iters, (0.062)\tData load 0.077s / 10iters, (0.007703)\n",
            "Loss_D = 0.94445729 (ave = 1.00967909)\n",
            "Loss_G = 3.00215673 (ave = 4.05242919)\n",
            "\n",
            "epoch: [10/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.615s / 10iters, (0.061)\tData load 0.074s / 10iters, (0.007419)\n",
            "Loss_D = 0.77028441 (ave = 1.00503197)\n",
            "Loss_G = 4.11628723 (ave = 4.08138474)\n",
            "\n",
            "epoch: [10/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.654s / 10iters, (0.065)\tData load 0.078s / 10iters, (0.007838)\n",
            "Loss_D = 1.18767965 (ave = 1.01167051)\n",
            "Loss_G = 2.59027433 (ave = 4.09305404)\n",
            "\n",
            "epoch: [10/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.627s / 10iters, (0.063)\tData load 0.091s / 10iters, (0.009133)\n",
            "Loss_D = 0.50572383 (ave = 1.00329674)\n",
            "Loss_G = 3.98612809 (ave = 4.09187295)\n",
            "\n",
            "epoch: [10/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.598s / 10iters, (0.060)\tData load 0.081s / 10iters, (0.008096)\n",
            "Loss_D = 1.13082170 (ave = 1.00041085)\n",
            "Loss_G = 3.40898561 (ave = 4.09123106)\n",
            "\n",
            "epoch: [10/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.624s / 10iters, (0.062)\tData load 0.086s / 10iters, (0.008550)\n",
            "Loss_D = 1.64616156 (ave = 0.99685324)\n",
            "Loss_G = 4.90180635 (ave = 4.10520431)\n",
            "\n",
            "epoch: [10/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.322s / 10iters, (0.032)\tData load 0.064s / 10iters, (0.006429)\n",
            "Loss_D = 1.31563044 (ave = 0.99941993)\n",
            "Loss_G = 3.88614178 (ave = 4.09283517)\n",
            "\n",
            "epoch: [10/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.064s / 3iters, (0.021)\tData load 0.015s / 3iters, (0.004890)\n",
            "Loss_D = 0.85680354 (ave = 0.99772897)\n",
            "Loss_G = 5.35902834 (ave = 4.08877410)\n",
            "\n",
            "Real Accuracy : 73.12148295266468\n",
            "Fake Accuracy : 5.296259516716319\n",
            "epoch: [11/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 4.945s / 10iters, (0.495)\tData load 4.263s / 10iters, (0.426298)\n",
            "Loss_D = 0.50769794 (ave = 0.79277071)\n",
            "Loss_G = 2.76135159 (ave = 4.25711999)\n",
            "\n",
            "epoch: [11/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.761s / 10iters, (0.076)\tData load 0.106s / 10iters, (0.010638)\n",
            "Loss_D = 0.53235114 (ave = 0.76757953)\n",
            "Loss_G = 5.17065001 (ave = 4.24315212)\n",
            "\n",
            "epoch: [11/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.667s / 10iters, (0.067)\tData load 0.114s / 10iters, (0.011385)\n",
            "Loss_D = 1.26793373 (ave = 0.89206401)\n",
            "Loss_G = 4.66957283 (ave = 4.24741802)\n",
            "\n",
            "epoch: [11/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.624s / 10iters, (0.062)\tData load 0.089s / 10iters, (0.008896)\n",
            "Loss_D = 1.39592409 (ave = 0.91139926)\n",
            "Loss_G = 9.89960194 (ave = 4.31804793)\n",
            "\n",
            "epoch: [11/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.614s / 10iters, (0.061)\tData load 0.093s / 10iters, (0.009311)\n",
            "Loss_D = 1.08036649 (ave = 1.07417126)\n",
            "Loss_G = 3.01395130 (ave = 4.24622667)\n",
            "\n",
            "epoch: [11/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.627s / 10iters, (0.063)\tData load 0.091s / 10iters, (0.009120)\n",
            "Loss_D = 0.71716821 (ave = 1.11571404)\n",
            "Loss_G = 4.66929817 (ave = 4.23109010)\n",
            "\n",
            "epoch: [11/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.539s / 10iters, (0.054)\tData load 0.082s / 10iters, (0.008186)\n",
            "Loss_D = 1.36008000 (ave = 1.09488229)\n",
            "Loss_G = 5.05421543 (ave = 4.19706052)\n",
            "\n",
            "epoch: [11/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.697s / 10iters, (0.070)\tData load 0.125s / 10iters, (0.012509)\n",
            "Loss_D = 0.80929780 (ave = 1.05294042)\n",
            "Loss_G = 2.60217237 (ave = 4.18346342)\n",
            "\n",
            "epoch: [11/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.550s / 10iters, (0.055)\tData load 0.064s / 10iters, (0.006387)\n",
            "Loss_D = 0.99883735 (ave = 1.01842211)\n",
            "Loss_G = 5.27316713 (ave = 4.16518344)\n",
            "\n",
            "epoch: [11/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.642s / 10iters, (0.064)\tData load 0.096s / 10iters, (0.009590)\n",
            "Loss_D = 0.52958566 (ave = 1.02794974)\n",
            "Loss_G = 2.80621743 (ave = 4.20940754)\n",
            "\n",
            "epoch: [11/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.636s / 10iters, (0.064)\tData load 0.074s / 10iters, (0.007370)\n",
            "Loss_D = 0.85042000 (ave = 1.02944087)\n",
            "Loss_G = 3.55407238 (ave = 4.23648250)\n",
            "\n",
            "epoch: [11/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.751s / 10iters, (0.075)\tData load 0.080s / 10iters, (0.008019)\n",
            "Loss_D = 0.69166148 (ave = 1.01767404)\n",
            "Loss_G = 4.03327751 (ave = 4.22261110)\n",
            "\n",
            "epoch: [11/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.716s / 10iters, (0.072)\tData load 0.082s / 10iters, (0.008249)\n",
            "Loss_D = 1.72629571 (ave = 1.03521028)\n",
            "Loss_G = 11.60304642 (ave = 4.27860613)\n",
            "\n",
            "epoch: [11/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.600s / 10iters, (0.060)\tData load 0.082s / 10iters, (0.008199)\n",
            "Loss_D = 1.22950161 (ave = 1.08028913)\n",
            "Loss_G = 3.63777900 (ave = 4.25156999)\n",
            "\n",
            "epoch: [11/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.599s / 10iters, (0.060)\tData load 0.079s / 10iters, (0.007893)\n",
            "Loss_D = 0.87099856 (ave = 1.09819936)\n",
            "Loss_G = 3.34209061 (ave = 4.24076303)\n",
            "\n",
            "epoch: [11/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.620s / 10iters, (0.062)\tData load 0.090s / 10iters, (0.008989)\n",
            "Loss_D = 1.73898745 (ave = 1.08537318)\n",
            "Loss_G = 3.42356658 (ave = 4.23530009)\n",
            "\n",
            "epoch: [11/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.561s / 10iters, (0.056)\tData load 0.076s / 10iters, (0.007640)\n",
            "Loss_D = 0.90921712 (ave = 1.10932951)\n",
            "Loss_G = 2.30674314 (ave = 4.23315708)\n",
            "\n",
            "epoch: [11/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.707s / 10iters, (0.071)\tData load 0.086s / 10iters, (0.008585)\n",
            "Loss_D = 1.42010021 (ave = 1.11361811)\n",
            "Loss_G = 4.95112658 (ave = 4.20998257)\n",
            "\n",
            "epoch: [11/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.628s / 10iters, (0.063)\tData load 0.097s / 10iters, (0.009722)\n",
            "Loss_D = 1.34850025 (ave = 1.10735005)\n",
            "Loss_G = 3.65713477 (ave = 4.16697008)\n",
            "\n",
            "epoch: [11/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.586s / 10iters, (0.059)\tData load 0.067s / 10iters, (0.006683)\n",
            "Loss_D = 0.70141470 (ave = 1.09818250)\n",
            "Loss_G = 3.45325184 (ave = 4.13472261)\n",
            "\n",
            "epoch: [11/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.457s / 10iters, (0.046)\tData load 0.057s / 10iters, (0.005724)\n",
            "Loss_D = 1.30425072 (ave = 1.09889803)\n",
            "Loss_G = 1.68656278 (ave = 4.08897095)\n",
            "\n",
            "epoch: [11/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.749s / 10iters, (0.075)\tData load 0.105s / 10iters, (0.010498)\n",
            "Loss_D = 0.75891244 (ave = 1.08994660)\n",
            "Loss_G = 4.76029873 (ave = 4.09843785)\n",
            "\n",
            "epoch: [11/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.350s / 10iters, (0.035)\tData load 0.049s / 10iters, (0.004900)\n",
            "Loss_D = 2.42547607 (ave = 1.09954576)\n",
            "Loss_G = 7.91594744 (ave = 4.09522147)\n",
            "\n",
            "epoch: [11/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.063s / 3iters, (0.021)\tData load 0.012s / 3iters, (0.003875)\n",
            "Loss_D = 1.44297493 (ave = 1.10036297)\n",
            "Loss_G = 7.88889599 (ave = 4.10127500)\n",
            "\n",
            "Real Accuracy : 71.83051969546507\n",
            "Fake Accuracy : 5.825885468387951\n",
            "epoch: [12/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.000s / 10iters, (0.500)\tData load 4.336s / 10iters, (0.433594)\n",
            "Loss_D = 0.57517135 (ave = 0.85482931)\n",
            "Loss_G = 4.61640644 (ave = 3.79440218)\n",
            "\n",
            "epoch: [12/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.566s / 10iters, (0.057)\tData load 0.099s / 10iters, (0.009945)\n",
            "Loss_D = 1.08963156 (ave = 1.12071745)\n",
            "Loss_G = 4.25616169 (ave = 4.03652460)\n",
            "\n",
            "epoch: [12/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.655s / 10iters, (0.065)\tData load 0.093s / 10iters, (0.009345)\n",
            "Loss_D = 0.68595135 (ave = 1.13789859)\n",
            "Loss_G = 2.91961169 (ave = 3.91903461)\n",
            "\n",
            "epoch: [12/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.628s / 10iters, (0.063)\tData load 0.092s / 10iters, (0.009234)\n",
            "Loss_D = 0.70093721 (ave = 1.15158515)\n",
            "Loss_G = 4.72035646 (ave = 3.90161486)\n",
            "\n",
            "epoch: [12/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.579s / 10iters, (0.058)\tData load 0.076s / 10iters, (0.007576)\n",
            "Loss_D = 1.16608560 (ave = 1.09300581)\n",
            "Loss_G = 4.51442003 (ave = 3.84601672)\n",
            "\n",
            "epoch: [12/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.638s / 10iters, (0.064)\tData load 0.101s / 10iters, (0.010066)\n",
            "Loss_D = 1.17573142 (ave = 1.12975928)\n",
            "Loss_G = 3.96429825 (ave = 3.89312159)\n",
            "\n",
            "epoch: [12/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.649s / 10iters, (0.065)\tData load 0.073s / 10iters, (0.007255)\n",
            "Loss_D = 1.21226728 (ave = 1.16942936)\n",
            "Loss_G = 2.81077218 (ave = 3.85912817)\n",
            "\n",
            "epoch: [12/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.675s / 10iters, (0.067)\tData load 0.080s / 10iters, (0.008013)\n",
            "Loss_D = 0.41223085 (ave = 1.13592976)\n",
            "Loss_G = 2.98149252 (ave = 3.79724824)\n",
            "\n",
            "epoch: [12/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.588s / 10iters, (0.059)\tData load 0.090s / 10iters, (0.008957)\n",
            "Loss_D = 0.79560655 (ave = 1.17013608)\n",
            "Loss_G = 4.36746645 (ave = 3.79938192)\n",
            "\n",
            "epoch: [12/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.667s / 10iters, (0.067)\tData load 0.082s / 10iters, (0.008168)\n",
            "Loss_D = 1.34762323 (ave = 1.14004608)\n",
            "Loss_G = 6.60515928 (ave = 3.77402611)\n",
            "\n",
            "epoch: [12/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.631s / 10iters, (0.063)\tData load 0.074s / 10iters, (0.007434)\n",
            "Loss_D = 1.64921427 (ave = 1.13870102)\n",
            "Loss_G = 3.55090952 (ave = 3.74811103)\n",
            "\n",
            "epoch: [12/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.636s / 10iters, (0.064)\tData load 0.091s / 10iters, (0.009059)\n",
            "Loss_D = 0.98674405 (ave = 1.12926835)\n",
            "Loss_G = 2.04991508 (ave = 3.75511337)\n",
            "\n",
            "epoch: [12/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.599s / 10iters, (0.060)\tData load 0.083s / 10iters, (0.008293)\n",
            "Loss_D = 1.27523136 (ave = 1.11181074)\n",
            "Loss_G = 5.50969601 (ave = 3.75402505)\n",
            "\n",
            "epoch: [12/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.683s / 10iters, (0.068)\tData load 0.096s / 10iters, (0.009611)\n",
            "Loss_D = 0.99718809 (ave = 1.10207248)\n",
            "Loss_G = 4.27378130 (ave = 3.73137306)\n",
            "\n",
            "epoch: [12/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.611s / 10iters, (0.061)\tData load 0.089s / 10iters, (0.008874)\n",
            "Loss_D = 0.78605109 (ave = 1.08631819)\n",
            "Loss_G = 4.53105211 (ave = 3.73865301)\n",
            "\n",
            "epoch: [12/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.650s / 10iters, (0.065)\tData load 0.086s / 10iters, (0.008649)\n",
            "Loss_D = 0.84230644 (ave = 1.08813252)\n",
            "Loss_G = 6.22889662 (ave = 3.73852888)\n",
            "\n",
            "epoch: [12/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.633s / 10iters, (0.063)\tData load 0.092s / 10iters, (0.009203)\n",
            "Loss_D = 1.35429561 (ave = 1.07460455)\n",
            "Loss_G = 1.57819116 (ave = 3.74788106)\n",
            "\n",
            "epoch: [12/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.594s / 10iters, (0.059)\tData load 0.068s / 10iters, (0.006759)\n",
            "Loss_D = 0.94761318 (ave = 1.06000244)\n",
            "Loss_G = 3.50707078 (ave = 3.78942789)\n",
            "\n",
            "epoch: [12/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.574s / 10iters, (0.057)\tData load 0.067s / 10iters, (0.006692)\n",
            "Loss_D = 0.54646075 (ave = 1.05790913)\n",
            "Loss_G = 4.24504519 (ave = 3.80323753)\n",
            "\n",
            "epoch: [12/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.659s / 10iters, (0.066)\tData load 0.069s / 10iters, (0.006898)\n",
            "Loss_D = 1.26215017 (ave = 1.05776418)\n",
            "Loss_G = 2.48710608 (ave = 3.81361419)\n",
            "\n",
            "epoch: [12/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.642s / 10iters, (0.064)\tData load 0.060s / 10iters, (0.006045)\n",
            "Loss_D = 0.86501545 (ave = 1.06028817)\n",
            "Loss_G = 4.19956732 (ave = 3.84574039)\n",
            "\n",
            "epoch: [12/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.683s / 10iters, (0.068)\tData load 0.095s / 10iters, (0.009485)\n",
            "Loss_D = 0.37955245 (ave = 1.06316092)\n",
            "Loss_G = 4.69438362 (ave = 3.84702541)\n",
            "\n",
            "epoch: [12/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.297s / 10iters, (0.030)\tData load 0.064s / 10iters, (0.006369)\n",
            "Loss_D = 0.78932285 (ave = 1.06134436)\n",
            "Loss_G = 3.01329947 (ave = 3.84261261)\n",
            "\n",
            "epoch: [12/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.069s / 3iters, (0.023)\tData load 0.017s / 3iters, (0.005656)\n",
            "Loss_D = 0.73722392 (ave = 1.05781570)\n",
            "Loss_G = 3.73516893 (ave = 3.85461548)\n",
            "\n",
            "Real Accuracy : 72.16153591525985\n",
            "Fake Accuracy : 6.123800066203244\n",
            "epoch: [13/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.143s / 10iters, (0.514)\tData load 4.380s / 10iters, (0.438024)\n",
            "Loss_D = 1.11944246 (ave = 1.17293342)\n",
            "Loss_G = 3.70992780 (ave = 3.55007139)\n",
            "\n",
            "epoch: [13/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.691s / 10iters, (0.069)\tData load 0.083s / 10iters, (0.008253)\n",
            "Loss_D = 2.64456034 (ave = 1.28948821)\n",
            "Loss_G = 6.91936445 (ave = 3.96022444)\n",
            "\n",
            "epoch: [13/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.576s / 10iters, (0.058)\tData load 0.068s / 10iters, (0.006798)\n",
            "Loss_D = 1.40479374 (ave = 1.31012146)\n",
            "Loss_G = 2.35349369 (ave = 3.85657380)\n",
            "\n",
            "epoch: [13/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.679s / 10iters, (0.068)\tData load 0.084s / 10iters, (0.008409)\n",
            "Loss_D = 1.43610883 (ave = 1.25544649)\n",
            "Loss_G = 2.83892059 (ave = 3.95783780)\n",
            "\n",
            "epoch: [13/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.542s / 10iters, (0.054)\tData load 0.085s / 10iters, (0.008478)\n",
            "Loss_D = 0.25841174 (ave = 1.17258692)\n",
            "Loss_G = 3.60752273 (ave = 3.88420993)\n",
            "\n",
            "epoch: [13/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.757s / 10iters, (0.076)\tData load 0.104s / 10iters, (0.010396)\n",
            "Loss_D = 0.85166204 (ave = 1.16972769)\n",
            "Loss_G = 4.57779932 (ave = 3.91653366)\n",
            "\n",
            "epoch: [13/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.663s / 10iters, (0.066)\tData load 0.068s / 10iters, (0.006848)\n",
            "Loss_D = 0.85497344 (ave = 1.17033274)\n",
            "Loss_G = 4.43687630 (ave = 3.91665649)\n",
            "\n",
            "epoch: [13/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.564s / 10iters, (0.056)\tData load 0.075s / 10iters, (0.007511)\n",
            "Loss_D = 0.62150705 (ave = 1.14763514)\n",
            "Loss_G = 4.88509893 (ave = 3.90429471)\n",
            "\n",
            "epoch: [13/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.734s / 10iters, (0.073)\tData load 0.086s / 10iters, (0.008555)\n",
            "Loss_D = 2.16394377 (ave = 1.14839985)\n",
            "Loss_G = 1.99526322 (ave = 3.85175485)\n",
            "\n",
            "epoch: [13/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.568s / 10iters, (0.057)\tData load 0.096s / 10iters, (0.009554)\n",
            "Loss_D = 1.96669877 (ave = 1.13672531)\n",
            "Loss_G = 3.36800551 (ave = 3.87310297)\n",
            "\n",
            "epoch: [13/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.449s / 10iters, (0.045)\tData load 0.055s / 10iters, (0.005529)\n",
            "Loss_D = 0.92475617 (ave = 1.12308312)\n",
            "Loss_G = 4.69971943 (ave = 3.89148422)\n",
            "\n",
            "epoch: [13/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.766s / 10iters, (0.077)\tData load 0.095s / 10iters, (0.009504)\n",
            "Loss_D = 0.80654520 (ave = 1.09381520)\n",
            "Loss_G = 2.87455988 (ave = 3.86717161)\n",
            "\n",
            "epoch: [13/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.620s / 10iters, (0.062)\tData load 0.103s / 10iters, (0.010282)\n",
            "Loss_D = 0.43143263 (ave = 1.10437120)\n",
            "Loss_G = 4.25537300 (ave = 3.88938807)\n",
            "\n",
            "epoch: [13/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.632s / 10iters, (0.063)\tData load 0.115s / 10iters, (0.011491)\n",
            "Loss_D = 1.38424969 (ave = 1.08266137)\n",
            "Loss_G = 2.66780472 (ave = 3.83495608)\n",
            "\n",
            "epoch: [13/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.626s / 10iters, (0.063)\tData load 0.059s / 10iters, (0.005943)\n",
            "Loss_D = 1.26794899 (ave = 1.07673912)\n",
            "Loss_G = 3.14130163 (ave = 3.82404542)\n",
            "\n",
            "epoch: [13/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.656s / 10iters, (0.066)\tData load 0.090s / 10iters, (0.009035)\n",
            "Loss_D = 0.72588325 (ave = 1.07125736)\n",
            "Loss_G = 4.28259516 (ave = 3.82762631)\n",
            "\n",
            "epoch: [13/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.576s / 10iters, (0.058)\tData load 0.083s / 10iters, (0.008318)\n",
            "Loss_D = 0.39689875 (ave = 1.06244797)\n",
            "Loss_G = 4.81497431 (ave = 3.82730766)\n",
            "\n",
            "epoch: [13/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.650s / 10iters, (0.065)\tData load 0.081s / 10iters, (0.008076)\n",
            "Loss_D = 1.52501225 (ave = 1.05642273)\n",
            "Loss_G = 4.30813265 (ave = 3.79984444)\n",
            "\n",
            "epoch: [13/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.646s / 10iters, (0.065)\tData load 0.062s / 10iters, (0.006221)\n",
            "Loss_D = 1.11402249 (ave = 1.05397708)\n",
            "Loss_G = 3.27680254 (ave = 3.78870642)\n",
            "\n",
            "epoch: [13/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.580s / 10iters, (0.058)\tData load 0.072s / 10iters, (0.007229)\n",
            "Loss_D = 1.03495002 (ave = 1.05351630)\n",
            "Loss_G = 3.34134412 (ave = 3.79263177)\n",
            "\n",
            "epoch: [13/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.588s / 10iters, (0.059)\tData load 0.064s / 10iters, (0.006390)\n",
            "Loss_D = 0.56267393 (ave = 1.05174047)\n",
            "Loss_G = 4.95248413 (ave = 3.80822042)\n",
            "\n",
            "epoch: [13/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.650s / 10iters, (0.065)\tData load 0.105s / 10iters, (0.010498)\n",
            "Loss_D = 1.53102744 (ave = 1.06040265)\n",
            "Loss_G = 3.29621482 (ave = 3.78582136)\n",
            "\n",
            "epoch: [13/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.339s / 10iters, (0.034)\tData load 0.054s / 10iters, (0.005369)\n",
            "Loss_D = 0.89208174 (ave = 1.05669823)\n",
            "Loss_G = 2.97613740 (ave = 3.76835306)\n",
            "\n",
            "epoch: [13/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.065s / 3iters, (0.022)\tData load 0.016s / 3iters, (0.005193)\n",
            "Loss_D = 0.85695988 (ave = 1.05607509)\n",
            "Loss_G = 2.22184420 (ave = 3.77082107)\n",
            "\n",
            "Real Accuracy : 72.92287322078782\n",
            "Fake Accuracy : 5.362462760675273\n",
            "epoch: [14/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.094s / 10iters, (0.509)\tData load 4.479s / 10iters, (0.447943)\n",
            "Loss_D = 1.27234888 (ave = 1.24526128)\n",
            "Loss_G = 5.93205309 (ave = 3.92658726)\n",
            "\n",
            "epoch: [14/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.616s / 10iters, (0.062)\tData load 0.072s / 10iters, (0.007174)\n",
            "Loss_D = 0.56199992 (ave = 1.15962107)\n",
            "Loss_G = 2.51216364 (ave = 3.79361847)\n",
            "\n",
            "epoch: [14/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.636s / 10iters, (0.064)\tData load 0.072s / 10iters, (0.007214)\n",
            "Loss_D = 0.41621453 (ave = 1.11306950)\n",
            "Loss_G = 5.13725710 (ave = 3.88091136)\n",
            "\n",
            "epoch: [14/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.570s / 10iters, (0.057)\tData load 0.071s / 10iters, (0.007108)\n",
            "Loss_D = 1.15744519 (ave = 1.06116291)\n",
            "Loss_G = 2.60878420 (ave = 3.78266893)\n",
            "\n",
            "epoch: [14/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.629s / 10iters, (0.063)\tData load 0.083s / 10iters, (0.008274)\n",
            "Loss_D = 1.37393296 (ave = 1.09362847)\n",
            "Loss_G = 5.95035362 (ave = 3.84759062)\n",
            "\n",
            "epoch: [14/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.646s / 10iters, (0.065)\tData load 0.083s / 10iters, (0.008342)\n",
            "Loss_D = 1.72182262 (ave = 1.09893075)\n",
            "Loss_G = 1.00958526 (ave = 3.76557158)\n",
            "\n",
            "epoch: [14/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.570s / 10iters, (0.057)\tData load 0.095s / 10iters, (0.009543)\n",
            "Loss_D = 0.24698028 (ave = 1.10605499)\n",
            "Loss_G = 4.85974026 (ave = 3.78991805)\n",
            "\n",
            "epoch: [14/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.605s / 10iters, (0.061)\tData load 0.082s / 10iters, (0.008246)\n",
            "Loss_D = 1.59993684 (ave = 1.06796405)\n",
            "Loss_G = 2.99233460 (ave = 3.73424885)\n",
            "\n",
            "epoch: [14/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.575s / 10iters, (0.057)\tData load 0.075s / 10iters, (0.007547)\n",
            "Loss_D = 0.45564246 (ave = 1.05690439)\n",
            "Loss_G = 3.86280298 (ave = 3.74167134)\n",
            "\n",
            "epoch: [14/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.676s / 10iters, (0.068)\tData load 0.084s / 10iters, (0.008436)\n",
            "Loss_D = 0.72372341 (ave = 1.04202516)\n",
            "Loss_G = 3.36871767 (ave = 3.72145716)\n",
            "\n",
            "epoch: [14/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.556s / 10iters, (0.056)\tData load 0.065s / 10iters, (0.006500)\n",
            "Loss_D = 0.55117524 (ave = 1.02266941)\n",
            "Loss_G = 5.12801933 (ave = 3.70737581)\n",
            "\n",
            "epoch: [14/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.684s / 10iters, (0.068)\tData load 0.074s / 10iters, (0.007428)\n",
            "Loss_D = 1.01616216 (ave = 1.01294180)\n",
            "Loss_G = 7.20311451 (ave = 3.74233831)\n",
            "\n",
            "epoch: [14/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.624s / 10iters, (0.062)\tData load 0.083s / 10iters, (0.008261)\n",
            "Loss_D = 1.14474869 (ave = 1.04306578)\n",
            "Loss_G = 2.72652793 (ave = 3.75688663)\n",
            "\n",
            "epoch: [14/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.602s / 10iters, (0.060)\tData load 0.080s / 10iters, (0.007977)\n",
            "Loss_D = 1.02829170 (ave = 1.04163263)\n",
            "Loss_G = 3.00587296 (ave = 3.76580642)\n",
            "\n",
            "epoch: [14/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.618s / 10iters, (0.062)\tData load 0.092s / 10iters, (0.009238)\n",
            "Loss_D = 1.09959650 (ave = 1.06305014)\n",
            "Loss_G = 3.74812222 (ave = 3.74226964)\n",
            "\n",
            "epoch: [14/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.599s / 10iters, (0.060)\tData load 0.082s / 10iters, (0.008198)\n",
            "Loss_D = 1.12360930 (ave = 1.05218457)\n",
            "Loss_G = 5.42253876 (ave = 3.75838670)\n",
            "\n",
            "epoch: [14/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.629s / 10iters, (0.063)\tData load 0.088s / 10iters, (0.008831)\n",
            "Loss_D = 0.53204900 (ave = 1.05072033)\n",
            "Loss_G = 2.26815462 (ave = 3.74919588)\n",
            "\n",
            "epoch: [14/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.608s / 10iters, (0.061)\tData load 0.099s / 10iters, (0.009942)\n",
            "Loss_D = 0.93308103 (ave = 1.03822100)\n",
            "Loss_G = 5.27498388 (ave = 3.74606775)\n",
            "\n",
            "epoch: [14/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.605s / 10iters, (0.061)\tData load 0.063s / 10iters, (0.006325)\n",
            "Loss_D = 0.52352464 (ave = 1.03621878)\n",
            "Loss_G = 4.28894901 (ave = 3.75989376)\n",
            "\n",
            "epoch: [14/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.592s / 10iters, (0.059)\tData load 0.091s / 10iters, (0.009056)\n",
            "Loss_D = 1.67341566 (ave = 1.04925922)\n",
            "Loss_G = 2.58240771 (ave = 3.75422189)\n",
            "\n",
            "epoch: [14/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.650s / 10iters, (0.065)\tData load 0.082s / 10iters, (0.008230)\n",
            "Loss_D = 1.39321256 (ave = 1.05024831)\n",
            "Loss_G = 5.12653542 (ave = 3.76866773)\n",
            "\n",
            "epoch: [14/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.550s / 10iters, (0.055)\tData load 0.072s / 10iters, (0.007227)\n",
            "Loss_D = 0.97846484 (ave = 1.05322084)\n",
            "Loss_G = 3.70118284 (ave = 3.76996604)\n",
            "\n",
            "epoch: [14/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.340s / 10iters, (0.034)\tData load 0.056s / 10iters, (0.005562)\n",
            "Loss_D = 0.90170056 (ave = 1.05978829)\n",
            "Loss_G = 2.93731260 (ave = 3.75465637)\n",
            "\n",
            "epoch: [14/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.070s / 3iters, (0.023)\tData load 0.015s / 3iters, (0.005125)\n",
            "Loss_D = 0.44542035 (ave = 1.05707501)\n",
            "Loss_G = 6.40969372 (ave = 3.76209591)\n",
            "\n",
            "Real Accuracy : 72.62495862297253\n",
            "Fake Accuracy : 5.2631578947368425\n",
            "epoch: [15/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 4.942s / 10iters, (0.494)\tData load 4.328s / 10iters, (0.432783)\n",
            "Loss_D = 1.91089475 (ave = 1.28711594)\n",
            "Loss_G = 2.45372486 (ave = 3.33949151)\n",
            "\n",
            "epoch: [15/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.683s / 10iters, (0.068)\tData load 0.098s / 10iters, (0.009763)\n",
            "Loss_D = 0.97584903 (ave = 1.22502845)\n",
            "Loss_G = 4.11322927 (ave = 3.79528356)\n",
            "\n",
            "epoch: [15/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.654s / 10iters, (0.065)\tData load 0.091s / 10iters, (0.009144)\n",
            "Loss_D = 1.02889085 (ave = 1.27772134)\n",
            "Loss_G = 1.96073771 (ave = 3.76915133)\n",
            "\n",
            "epoch: [15/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.582s / 10iters, (0.058)\tData load 0.100s / 10iters, (0.010036)\n",
            "Loss_D = 0.69658720 (ave = 1.27053854)\n",
            "Loss_G = 4.14851713 (ave = 3.75793609)\n",
            "\n",
            "epoch: [15/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.685s / 10iters, (0.068)\tData load 0.095s / 10iters, (0.009540)\n",
            "Loss_D = 0.53210896 (ave = 1.18969744)\n",
            "Loss_G = 3.58506870 (ave = 3.70395116)\n",
            "\n",
            "epoch: [15/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.592s / 10iters, (0.059)\tData load 0.082s / 10iters, (0.008247)\n",
            "Loss_D = 0.88744789 (ave = 1.16871134)\n",
            "Loss_G = 1.57492876 (ave = 3.67213336)\n",
            "\n",
            "epoch: [15/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.705s / 10iters, (0.070)\tData load 0.077s / 10iters, (0.007713)\n",
            "Loss_D = 0.60046548 (ave = 1.16005031)\n",
            "Loss_G = 3.21731353 (ave = 3.62370997)\n",
            "\n",
            "epoch: [15/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.600s / 10iters, (0.060)\tData load 0.074s / 10iters, (0.007392)\n",
            "Loss_D = 0.94959652 (ave = 1.12478483)\n",
            "Loss_G = 5.75099754 (ave = 3.60205457)\n",
            "\n",
            "epoch: [15/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.571s / 10iters, (0.057)\tData load 0.079s / 10iters, (0.007860)\n",
            "Loss_D = 0.89030766 (ave = 1.10585083)\n",
            "Loss_G = 2.80087137 (ave = 3.59826518)\n",
            "\n",
            "epoch: [15/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.670s / 10iters, (0.067)\tData load 0.104s / 10iters, (0.010382)\n",
            "Loss_D = 0.73654318 (ave = 1.09340187)\n",
            "Loss_G = 3.29980063 (ave = 3.59433162)\n",
            "\n",
            "epoch: [15/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.653s / 10iters, (0.065)\tData load 0.060s / 10iters, (0.006006)\n",
            "Loss_D = 0.74739969 (ave = 1.09879670)\n",
            "Loss_G = 4.46268034 (ave = 3.61977392)\n",
            "\n",
            "epoch: [15/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.637s / 10iters, (0.064)\tData load 0.091s / 10iters, (0.009089)\n",
            "Loss_D = 0.83319497 (ave = 1.10339721)\n",
            "Loss_G = 4.77647829 (ave = 3.62806017)\n",
            "\n",
            "epoch: [15/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.658s / 10iters, (0.066)\tData load 0.069s / 10iters, (0.006913)\n",
            "Loss_D = 1.13508499 (ave = 1.10236003)\n",
            "Loss_G = 3.06084967 (ave = 3.61496323)\n",
            "\n",
            "epoch: [15/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.664s / 10iters, (0.066)\tData load 0.079s / 10iters, (0.007872)\n",
            "Loss_D = 1.01517129 (ave = 1.10183878)\n",
            "Loss_G = 4.10745049 (ave = 3.60520464)\n",
            "\n",
            "epoch: [15/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.627s / 10iters, (0.063)\tData load 0.071s / 10iters, (0.007063)\n",
            "Loss_D = 1.48722005 (ave = 1.09794207)\n",
            "Loss_G = 5.87214899 (ave = 3.59851196)\n",
            "\n",
            "epoch: [15/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.640s / 10iters, (0.064)\tData load 0.094s / 10iters, (0.009392)\n",
            "Loss_D = 1.52776182 (ave = 1.09100192)\n",
            "Loss_G = 2.62094259 (ave = 3.60638704)\n",
            "\n",
            "epoch: [15/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.582s / 10iters, (0.058)\tData load 0.091s / 10iters, (0.009146)\n",
            "Loss_D = 1.62832642 (ave = 1.09091178)\n",
            "Loss_G = 7.30877781 (ave = 3.61917173)\n",
            "\n",
            "epoch: [15/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.617s / 10iters, (0.062)\tData load 0.088s / 10iters, (0.008836)\n",
            "Loss_D = 1.18037868 (ave = 1.09819347)\n",
            "Loss_G = 4.95021629 (ave = 3.61455717)\n",
            "\n",
            "epoch: [15/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.658s / 10iters, (0.066)\tData load 0.063s / 10iters, (0.006260)\n",
            "Loss_D = 0.83783197 (ave = 1.10204831)\n",
            "Loss_G = 4.12561560 (ave = 3.60629072)\n",
            "\n",
            "epoch: [15/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.621s / 10iters, (0.062)\tData load 0.101s / 10iters, (0.010084)\n",
            "Loss_D = 0.59544301 (ave = 1.09713521)\n",
            "Loss_G = 3.86842299 (ave = 3.61208694)\n",
            "\n",
            "epoch: [15/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.546s / 10iters, (0.055)\tData load 0.076s / 10iters, (0.007559)\n",
            "Loss_D = 0.62911862 (ave = 1.08383090)\n",
            "Loss_G = 3.86956406 (ave = 3.59658893)\n",
            "\n",
            "epoch: [15/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.704s / 10iters, (0.070)\tData load 0.086s / 10iters, (0.008586)\n",
            "Loss_D = 1.63423586 (ave = 1.09195654)\n",
            "Loss_G = 3.13104463 (ave = 3.58728418)\n",
            "\n",
            "epoch: [15/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.308s / 10iters, (0.031)\tData load 0.073s / 10iters, (0.007253)\n",
            "Loss_D = 1.61193514 (ave = 1.08698350)\n",
            "Loss_G = 5.36185217 (ave = 3.57550130)\n",
            "\n",
            "epoch: [15/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.069s / 3iters, (0.023)\tData load 0.018s / 3iters, (0.005860)\n",
            "Loss_D = 2.22970891 (ave = 1.10189446)\n",
            "Loss_G = 2.99661660 (ave = 3.56388027)\n",
            "\n",
            "Real Accuracy : 71.96292618338299\n",
            "Fake Accuracy : 6.421714664018537\n",
            "epoch: [16/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.003s / 10iters, (0.500)\tData load 4.371s / 10iters, (0.437116)\n",
            "Loss_D = 1.19439411 (ave = 1.33988022)\n",
            "Loss_G = 2.67552280 (ave = 3.82761130)\n",
            "\n",
            "epoch: [16/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.758s / 10iters, (0.076)\tData load 0.130s / 10iters, (0.013034)\n",
            "Loss_D = 0.47939020 (ave = 1.04949167)\n",
            "Loss_G = 3.61851740 (ave = 3.77018576)\n",
            "\n",
            "epoch: [16/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.630s / 10iters, (0.063)\tData load 0.074s / 10iters, (0.007370)\n",
            "Loss_D = 1.63814569 (ave = 1.06814952)\n",
            "Loss_G = 1.54275334 (ave = 3.58389147)\n",
            "\n",
            "epoch: [16/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.650s / 10iters, (0.065)\tData load 0.065s / 10iters, (0.006537)\n",
            "Loss_D = 0.54189956 (ave = 0.98794360)\n",
            "Loss_G = 3.27146673 (ave = 3.55527199)\n",
            "\n",
            "epoch: [16/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.620s / 10iters, (0.062)\tData load 0.102s / 10iters, (0.010201)\n",
            "Loss_D = 0.40769517 (ave = 0.94176287)\n",
            "Loss_G = 4.54962063 (ave = 3.58796811)\n",
            "\n",
            "epoch: [16/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.647s / 10iters, (0.065)\tData load 0.075s / 10iters, (0.007476)\n",
            "Loss_D = 1.29708385 (ave = 0.97661626)\n",
            "Loss_G = 2.95319009 (ave = 3.62546401)\n",
            "\n",
            "epoch: [16/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.666s / 10iters, (0.067)\tData load 0.105s / 10iters, (0.010535)\n",
            "Loss_D = 0.84328640 (ave = 0.97201904)\n",
            "Loss_G = 2.89721537 (ave = 3.62005434)\n",
            "\n",
            "epoch: [16/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.593s / 10iters, (0.059)\tData load 0.099s / 10iters, (0.009911)\n",
            "Loss_D = 1.10574746 (ave = 1.00312739)\n",
            "Loss_G = 3.18710923 (ave = 3.59131946)\n",
            "\n",
            "epoch: [16/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.634s / 10iters, (0.063)\tData load 0.092s / 10iters, (0.009240)\n",
            "Loss_D = 0.96216333 (ave = 1.00320343)\n",
            "Loss_G = 4.08051395 (ave = 3.57605205)\n",
            "\n",
            "epoch: [16/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.640s / 10iters, (0.064)\tData load 0.101s / 10iters, (0.010072)\n",
            "Loss_D = 0.41946051 (ave = 0.99078939)\n",
            "Loss_G = 4.05133629 (ave = 3.58605619)\n",
            "\n",
            "epoch: [16/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.637s / 10iters, (0.064)\tData load 0.089s / 10iters, (0.008875)\n",
            "Loss_D = 0.55749351 (ave = 0.98245208)\n",
            "Loss_G = 3.43281794 (ave = 3.57564634)\n",
            "\n",
            "epoch: [16/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.660s / 10iters, (0.066)\tData load 0.070s / 10iters, (0.007032)\n",
            "Loss_D = 2.75431848 (ave = 1.02865611)\n",
            "Loss_G = 2.70892692 (ave = 3.59382851)\n",
            "\n",
            "epoch: [16/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.618s / 10iters, (0.062)\tData load 0.088s / 10iters, (0.008803)\n",
            "Loss_D = 2.36635542 (ave = 1.07541653)\n",
            "Loss_G = 5.80183077 (ave = 3.56524648)\n",
            "\n",
            "epoch: [16/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.566s / 10iters, (0.057)\tData load 0.069s / 10iters, (0.006867)\n",
            "Loss_D = 0.92736846 (ave = 1.07219716)\n",
            "Loss_G = 3.84379983 (ave = 3.55681505)\n",
            "\n",
            "epoch: [16/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.714s / 10iters, (0.071)\tData load 0.083s / 10iters, (0.008301)\n",
            "Loss_D = 1.05979729 (ave = 1.08028684)\n",
            "Loss_G = 2.72625399 (ave = 3.55898378)\n",
            "\n",
            "epoch: [16/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.633s / 10iters, (0.063)\tData load 0.069s / 10iters, (0.006885)\n",
            "Loss_D = 0.76062948 (ave = 1.07763706)\n",
            "Loss_G = 3.66175866 (ave = 3.56968553)\n",
            "\n",
            "epoch: [16/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.641s / 10iters, (0.064)\tData load 0.068s / 10iters, (0.006819)\n",
            "Loss_D = 1.02061832 (ave = 1.07273667)\n",
            "Loss_G = 5.10164309 (ave = 3.56013596)\n",
            "\n",
            "epoch: [16/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.537s / 10iters, (0.054)\tData load 0.088s / 10iters, (0.008791)\n",
            "Loss_D = 1.64045489 (ave = 1.07412699)\n",
            "Loss_G = 5.61487293 (ave = 3.56289325)\n",
            "\n",
            "epoch: [16/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.630s / 10iters, (0.063)\tData load 0.074s / 10iters, (0.007391)\n",
            "Loss_D = 1.88147855 (ave = 1.07856002)\n",
            "Loss_G = 2.52238750 (ave = 3.54757141)\n",
            "\n",
            "epoch: [16/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.693s / 10iters, (0.069)\tData load 0.076s / 10iters, (0.007582)\n",
            "Loss_D = 1.05506766 (ave = 1.06968747)\n",
            "Loss_G = 4.90212297 (ave = 3.54333976)\n",
            "\n",
            "epoch: [16/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.612s / 10iters, (0.061)\tData load 0.078s / 10iters, (0.007759)\n",
            "Loss_D = 0.43468919 (ave = 1.08051723)\n",
            "Loss_G = 4.28734064 (ave = 3.54797205)\n",
            "\n",
            "epoch: [16/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.653s / 10iters, (0.065)\tData load 0.098s / 10iters, (0.009780)\n",
            "Loss_D = 2.35377836 (ave = 1.08537186)\n",
            "Loss_G = 4.31608963 (ave = 3.53442032)\n",
            "\n",
            "epoch: [16/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.331s / 10iters, (0.033)\tData load 0.070s / 10iters, (0.006997)\n",
            "Loss_D = 0.92229748 (ave = 1.08764689)\n",
            "Loss_G = 2.34914446 (ave = 3.52428877)\n",
            "\n",
            "epoch: [16/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.068s / 3iters, (0.023)\tData load 0.017s / 3iters, (0.005587)\n",
            "Loss_D = 0.57874942 (ave = 1.08218271)\n",
            "Loss_G = 5.82619715 (ave = 3.53116399)\n",
            "\n",
            "Real Accuracy : 72.3601456471367\n",
            "Fake Accuracy : 5.825885468387951\n",
            "epoch: [17/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.190s / 10iters, (0.519)\tData load 4.474s / 10iters, (0.447395)\n",
            "Loss_D = 0.57799995 (ave = 0.95722789)\n",
            "Loss_G = 5.18181181 (ave = 3.62873384)\n",
            "\n",
            "epoch: [17/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.680s / 10iters, (0.068)\tData load 0.075s / 10iters, (0.007545)\n",
            "Loss_D = 0.79033190 (ave = 0.92133949)\n",
            "Loss_G = 2.89672136 (ave = 3.36345869)\n",
            "\n",
            "epoch: [17/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.592s / 10iters, (0.059)\tData load 0.073s / 10iters, (0.007332)\n",
            "Loss_D = 0.85651708 (ave = 0.88373201)\n",
            "Loss_G = 4.86563444 (ave = 3.37983967)\n",
            "\n",
            "epoch: [17/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.673s / 10iters, (0.067)\tData load 0.094s / 10iters, (0.009432)\n",
            "Loss_D = 1.34061265 (ave = 0.92539083)\n",
            "Loss_G = 2.94645548 (ave = 3.27701331)\n",
            "\n",
            "epoch: [17/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.648s / 10iters, (0.065)\tData load 0.089s / 10iters, (0.008874)\n",
            "Loss_D = 1.21731198 (ave = 0.92607163)\n",
            "Loss_G = 4.33660746 (ave = 3.36108027)\n",
            "\n",
            "epoch: [17/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.615s / 10iters, (0.062)\tData load 0.075s / 10iters, (0.007501)\n",
            "Loss_D = 1.47638941 (ave = 0.94238775)\n",
            "Loss_G = 3.65932941 (ave = 3.42264007)\n",
            "\n",
            "epoch: [17/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.633s / 10iters, (0.063)\tData load 0.076s / 10iters, (0.007633)\n",
            "Loss_D = 1.35580409 (ave = 0.95334619)\n",
            "Loss_G = 2.76162863 (ave = 3.45839789)\n",
            "\n",
            "epoch: [17/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.608s / 10iters, (0.061)\tData load 0.102s / 10iters, (0.010225)\n",
            "Loss_D = 0.74331164 (ave = 0.94115298)\n",
            "Loss_G = 3.47843647 (ave = 3.43219758)\n",
            "\n",
            "epoch: [17/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.640s / 10iters, (0.064)\tData load 0.076s / 10iters, (0.007604)\n",
            "Loss_D = 1.20447755 (ave = 0.94858645)\n",
            "Loss_G = 1.39928293 (ave = 3.39117666)\n",
            "\n",
            "epoch: [17/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.608s / 10iters, (0.061)\tData load 0.109s / 10iters, (0.010897)\n",
            "Loss_D = 0.70603418 (ave = 0.97793418)\n",
            "Loss_G = 4.14697313 (ave = 3.39207777)\n",
            "\n",
            "epoch: [17/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.666s / 10iters, (0.067)\tData load 0.063s / 10iters, (0.006338)\n",
            "Loss_D = 0.82928300 (ave = 0.95598127)\n",
            "Loss_G = 3.35444403 (ave = 3.38521384)\n",
            "\n",
            "epoch: [17/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.696s / 10iters, (0.070)\tData load 0.069s / 10iters, (0.006935)\n",
            "Loss_D = 0.62800759 (ave = 0.95912287)\n",
            "Loss_G = 4.93967199 (ave = 3.38954089)\n",
            "\n",
            "epoch: [17/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.690s / 10iters, (0.069)\tData load 0.104s / 10iters, (0.010370)\n",
            "Loss_D = 0.66902304 (ave = 0.95283569)\n",
            "Loss_G = 3.89239788 (ave = 3.39611209)\n",
            "\n",
            "epoch: [17/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.549s / 10iters, (0.055)\tData load 0.050s / 10iters, (0.005020)\n",
            "Loss_D = 0.99467933 (ave = 0.95241580)\n",
            "Loss_G = 2.85387588 (ave = 3.41336130)\n",
            "\n",
            "epoch: [17/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.774s / 10iters, (0.077)\tData load 0.100s / 10iters, (0.009970)\n",
            "Loss_D = 0.95650929 (ave = 0.93922953)\n",
            "Loss_G = 3.52880716 (ave = 3.41236044)\n",
            "\n",
            "epoch: [17/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.585s / 10iters, (0.059)\tData load 0.061s / 10iters, (0.006096)\n",
            "Loss_D = 0.82175922 (ave = 0.94542769)\n",
            "Loss_G = 4.03070641 (ave = 3.42556336)\n",
            "\n",
            "epoch: [17/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.587s / 10iters, (0.059)\tData load 0.086s / 10iters, (0.008571)\n",
            "Loss_D = 0.81974524 (ave = 0.95448366)\n",
            "Loss_G = 4.20788622 (ave = 3.46492140)\n",
            "\n",
            "epoch: [17/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.668s / 10iters, (0.067)\tData load 0.088s / 10iters, (0.008792)\n",
            "Loss_D = 0.91946161 (ave = 0.95171968)\n",
            "Loss_G = 3.37198782 (ave = 3.46909785)\n",
            "\n",
            "epoch: [17/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.611s / 10iters, (0.061)\tData load 0.093s / 10iters, (0.009320)\n",
            "Loss_D = 0.94798565 (ave = 0.95894945)\n",
            "Loss_G = 3.19988680 (ave = 3.48965535)\n",
            "\n",
            "epoch: [17/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.647s / 10iters, (0.065)\tData load 0.064s / 10iters, (0.006368)\n",
            "Loss_D = 0.69885677 (ave = 0.95483233)\n",
            "Loss_G = 4.24390936 (ave = 3.48276117)\n",
            "\n",
            "epoch: [17/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.658s / 10iters, (0.066)\tData load 0.071s / 10iters, (0.007052)\n",
            "Loss_D = 0.90625489 (ave = 0.95482901)\n",
            "Loss_G = 2.60508823 (ave = 3.45815119)\n",
            "\n",
            "epoch: [17/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.679s / 10iters, (0.068)\tData load 0.065s / 10iters, (0.006495)\n",
            "Loss_D = 1.16732776 (ave = 0.94742911)\n",
            "Loss_G = 4.31608200 (ave = 3.46288325)\n",
            "\n",
            "epoch: [17/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.318s / 10iters, (0.032)\tData load 0.060s / 10iters, (0.005973)\n",
            "Loss_D = 1.30261075 (ave = 0.95418422)\n",
            "Loss_G = 2.20396352 (ave = 3.47257023)\n",
            "\n",
            "epoch: [17/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.066s / 3iters, (0.022)\tData load 0.017s / 3iters, (0.005526)\n",
            "Loss_D = 0.79557741 (ave = 0.95246508)\n",
            "Loss_G = 4.93887615 (ave = 3.47401545)\n",
            "\n",
            "Real Accuracy : 76.19993379675604\n",
            "Fake Accuracy : 6.653426017874876\n",
            "epoch: [18/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.085s / 10iters, (0.508)\tData load 4.438s / 10iters, (0.443825)\n",
            "Loss_D = 1.95824361 (ave = 0.82239559)\n",
            "Loss_G = 4.72854948 (ave = 3.49243368)\n",
            "\n",
            "epoch: [18/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.619s / 10iters, (0.062)\tData load 0.092s / 10iters, (0.009188)\n",
            "Loss_D = 0.81907934 (ave = 0.96579794)\n",
            "Loss_G = 5.74385548 (ave = 3.63352191)\n",
            "\n",
            "epoch: [18/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.612s / 10iters, (0.061)\tData load 0.095s / 10iters, (0.009462)\n",
            "Loss_D = 0.96473324 (ave = 0.96767260)\n",
            "Loss_G = 2.48678684 (ave = 3.49468846)\n",
            "\n",
            "epoch: [18/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.599s / 10iters, (0.060)\tData load 0.091s / 10iters, (0.009090)\n",
            "Loss_D = 0.77951467 (ave = 0.93451225)\n",
            "Loss_G = 4.62639141 (ave = 3.50373470)\n",
            "\n",
            "epoch: [18/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.623s / 10iters, (0.062)\tData load 0.080s / 10iters, (0.007962)\n",
            "Loss_D = 0.62920606 (ave = 0.96447512)\n",
            "Loss_G = 3.10465598 (ave = 3.49926126)\n",
            "\n",
            "epoch: [18/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.680s / 10iters, (0.068)\tData load 0.106s / 10iters, (0.010552)\n",
            "Loss_D = 0.76468092 (ave = 0.97105396)\n",
            "Loss_G = 5.93492889 (ave = 3.51932099)\n",
            "\n",
            "epoch: [18/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.636s / 10iters, (0.064)\tData load 0.080s / 10iters, (0.007975)\n",
            "Loss_D = 0.98955727 (ave = 1.03549207)\n",
            "Loss_G = 1.06861138 (ave = 3.50681207)\n",
            "\n",
            "epoch: [18/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.611s / 10iters, (0.061)\tData load 0.079s / 10iters, (0.007902)\n",
            "Loss_D = 1.33785093 (ave = 1.05458137)\n",
            "Loss_G = 4.80081987 (ave = 3.54554776)\n",
            "\n",
            "epoch: [18/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.659s / 10iters, (0.066)\tData load 0.119s / 10iters, (0.011930)\n",
            "Loss_D = 1.11404085 (ave = 1.06804807)\n",
            "Loss_G = 2.44539905 (ave = 3.53030836)\n",
            "\n",
            "epoch: [18/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.635s / 10iters, (0.063)\tData load 0.062s / 10iters, (0.006166)\n",
            "Loss_D = 0.87388206 (ave = 1.08426728)\n",
            "Loss_G = 2.86236739 (ave = 3.52419978)\n",
            "\n",
            "epoch: [18/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.580s / 10iters, (0.058)\tData load 0.076s / 10iters, (0.007613)\n",
            "Loss_D = 1.00103843 (ave = 1.06818672)\n",
            "Loss_G = 3.42179585 (ave = 3.54857174)\n",
            "\n",
            "epoch: [18/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.636s / 10iters, (0.064)\tData load 0.054s / 10iters, (0.005379)\n",
            "Loss_D = 0.68948847 (ave = 1.05653890)\n",
            "Loss_G = 2.92597342 (ave = 3.52887748)\n",
            "\n",
            "epoch: [18/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.723s / 10iters, (0.072)\tData load 0.088s / 10iters, (0.008790)\n",
            "Loss_D = 0.96285653 (ave = 1.05291678)\n",
            "Loss_G = 5.17976189 (ave = 3.55169021)\n",
            "\n",
            "epoch: [18/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.627s / 10iters, (0.063)\tData load 0.063s / 10iters, (0.006308)\n",
            "Loss_D = 1.73402023 (ave = 1.05676657)\n",
            "Loss_G = 4.25701284 (ave = 3.54718068)\n",
            "\n",
            "epoch: [18/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.645s / 10iters, (0.064)\tData load 0.084s / 10iters, (0.008370)\n",
            "Loss_D = 0.77754378 (ave = 1.06830086)\n",
            "Loss_G = 2.97377372 (ave = 3.53728349)\n",
            "\n",
            "epoch: [18/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.675s / 10iters, (0.067)\tData load 0.097s / 10iters, (0.009720)\n",
            "Loss_D = 0.73664963 (ave = 1.05539233)\n",
            "Loss_G = 2.87469697 (ave = 3.51817451)\n",
            "\n",
            "epoch: [18/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.623s / 10iters, (0.062)\tData load 0.086s / 10iters, (0.008561)\n",
            "Loss_D = 1.02274299 (ave = 1.04199591)\n",
            "Loss_G = 2.22415400 (ave = 3.50834673)\n",
            "\n",
            "epoch: [18/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.600s / 10iters, (0.060)\tData load 0.073s / 10iters, (0.007298)\n",
            "Loss_D = 0.94031286 (ave = 1.03222172)\n",
            "Loss_G = 3.09855700 (ave = 3.49393521)\n",
            "\n",
            "epoch: [18/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.714s / 10iters, (0.071)\tData load 0.077s / 10iters, (0.007657)\n",
            "Loss_D = 0.71657300 (ave = 1.02642662)\n",
            "Loss_G = 3.58569360 (ave = 3.48630245)\n",
            "\n",
            "epoch: [18/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.561s / 10iters, (0.056)\tData load 0.071s / 10iters, (0.007108)\n",
            "Loss_D = 0.87486100 (ave = 1.01617223)\n",
            "Loss_G = 2.75964022 (ave = 3.47141823)\n",
            "\n",
            "epoch: [18/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.445s / 10iters, (0.044)\tData load 0.056s / 10iters, (0.005597)\n",
            "Loss_D = 1.36501753 (ave = 1.02277451)\n",
            "Loss_G = 3.31104445 (ave = 3.48545486)\n",
            "\n",
            "epoch: [18/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.748s / 10iters, (0.075)\tData load 0.073s / 10iters, (0.007344)\n",
            "Loss_D = 1.00536799 (ave = 1.03388491)\n",
            "Loss_G = 4.19131804 (ave = 3.48915929)\n",
            "\n",
            "epoch: [18/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.365s / 10iters, (0.036)\tData load 0.059s / 10iters, (0.005860)\n",
            "Loss_D = 1.38532138 (ave = 1.03332403)\n",
            "Loss_G = 4.47104692 (ave = 3.49782199)\n",
            "\n",
            "epoch: [18/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.067s / 3iters, (0.022)\tData load 0.011s / 3iters, (0.003826)\n",
            "Loss_D = 1.54595590 (ave = 1.03438729)\n",
            "Loss_G = 2.92120099 (ave = 3.49766491)\n",
            "\n",
            "Real Accuracy : 74.54485269778219\n",
            "Fake Accuracy : 6.223104932141675\n",
            "epoch: [19/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.108s / 10iters, (0.511)\tData load 4.399s / 10iters, (0.439900)\n",
            "Loss_D = 1.99879098 (ave = 1.48862464)\n",
            "Loss_G = 6.19497919 (ave = 4.10748842)\n",
            "\n",
            "epoch: [19/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.618s / 10iters, (0.062)\tData load 0.086s / 10iters, (0.008626)\n",
            "Loss_D = 1.31423473 (ave = 1.46270842)\n",
            "Loss_G = 3.10140753 (ave = 3.66423354)\n",
            "\n",
            "epoch: [19/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.607s / 10iters, (0.061)\tData load 0.104s / 10iters, (0.010370)\n",
            "Loss_D = 1.68857241 (ave = 1.26200052)\n",
            "Loss_G = 6.45950603 (ave = 3.53664577)\n",
            "\n",
            "epoch: [19/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.635s / 10iters, (0.064)\tData load 0.090s / 10iters, (0.008980)\n",
            "Loss_D = 0.54439080 (ave = 1.17428691)\n",
            "Loss_G = 3.13865900 (ave = 3.50422139)\n",
            "\n",
            "epoch: [19/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.625s / 10iters, (0.062)\tData load 0.079s / 10iters, (0.007908)\n",
            "Loss_D = 0.89368486 (ave = 1.09867177)\n",
            "Loss_G = 2.21875167 (ave = 3.49771866)\n",
            "\n",
            "epoch: [19/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.629s / 10iters, (0.063)\tData load 0.070s / 10iters, (0.007010)\n",
            "Loss_D = 0.53941417 (ave = 1.06764957)\n",
            "Loss_G = 2.38625574 (ave = 3.48593133)\n",
            "\n",
            "epoch: [19/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.599s / 10iters, (0.060)\tData load 0.055s / 10iters, (0.005537)\n",
            "Loss_D = 0.70513839 (ave = 1.04527681)\n",
            "Loss_G = 4.54412508 (ave = 3.48276269)\n",
            "\n",
            "epoch: [19/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.670s / 10iters, (0.067)\tData load 0.092s / 10iters, (0.009156)\n",
            "Loss_D = 0.97018391 (ave = 1.01159827)\n",
            "Loss_G = 4.72160149 (ave = 3.48000200)\n",
            "\n",
            "epoch: [19/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.684s / 10iters, (0.068)\tData load 0.056s / 10iters, (0.005626)\n",
            "Loss_D = 0.60863739 (ave = 0.99844754)\n",
            "Loss_G = 3.27529240 (ave = 3.51539849)\n",
            "\n",
            "epoch: [19/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.577s / 10iters, (0.058)\tData load 0.081s / 10iters, (0.008083)\n",
            "Loss_D = 1.13536131 (ave = 1.01742254)\n",
            "Loss_G = 5.77452374 (ave = 3.55270459)\n",
            "\n",
            "epoch: [19/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.658s / 10iters, (0.066)\tData load 0.092s / 10iters, (0.009208)\n",
            "Loss_D = 0.71114969 (ave = 0.99788105)\n",
            "Loss_G = 1.97617424 (ave = 3.50529330)\n",
            "\n",
            "epoch: [19/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.685s / 10iters, (0.068)\tData load 0.064s / 10iters, (0.006415)\n",
            "Loss_D = 1.17700410 (ave = 1.00380287)\n",
            "Loss_G = 4.36946726 (ave = 3.50342831)\n",
            "\n",
            "epoch: [19/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.597s / 10iters, (0.060)\tData load 0.088s / 10iters, (0.008768)\n",
            "Loss_D = 0.74904925 (ave = 0.98457581)\n",
            "Loss_G = 2.45654821 (ave = 3.48633978)\n",
            "\n",
            "epoch: [19/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.653s / 10iters, (0.065)\tData load 0.087s / 10iters, (0.008736)\n",
            "Loss_D = 1.02409649 (ave = 0.97896546)\n",
            "Loss_G = 2.93446732 (ave = 3.47109842)\n",
            "\n",
            "epoch: [19/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.696s / 10iters, (0.070)\tData load 0.097s / 10iters, (0.009694)\n",
            "Loss_D = 1.08506846 (ave = 0.97463412)\n",
            "Loss_G = 5.03475428 (ave = 3.48751382)\n",
            "\n",
            "epoch: [19/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.644s / 10iters, (0.064)\tData load 0.097s / 10iters, (0.009672)\n",
            "Loss_D = 1.19376898 (ave = 0.97982361)\n",
            "Loss_G = 3.64350510 (ave = 3.47516264)\n",
            "\n",
            "epoch: [19/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.575s / 10iters, (0.058)\tData load 0.087s / 10iters, (0.008658)\n",
            "Loss_D = 0.57029402 (ave = 0.96637906)\n",
            "Loss_G = 3.56660318 (ave = 3.46357723)\n",
            "\n",
            "epoch: [19/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.529s / 10iters, (0.053)\tData load 0.081s / 10iters, (0.008085)\n",
            "Loss_D = 1.06068826 (ave = 0.96133935)\n",
            "Loss_G = 3.28470182 (ave = 3.46190607)\n",
            "\n",
            "epoch: [19/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.739s / 10iters, (0.074)\tData load 0.076s / 10iters, (0.007623)\n",
            "Loss_D = 1.11104262 (ave = 0.98261217)\n",
            "Loss_G = 2.49773169 (ave = 3.45877556)\n",
            "\n",
            "epoch: [19/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.642s / 10iters, (0.064)\tData load 0.067s / 10iters, (0.006747)\n",
            "Loss_D = 1.06559157 (ave = 0.98237165)\n",
            "Loss_G = 4.90709400 (ave = 3.46276543)\n",
            "\n",
            "epoch: [19/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.607s / 10iters, (0.061)\tData load 0.062s / 10iters, (0.006220)\n",
            "Loss_D = 2.01248288 (ave = 0.99769959)\n",
            "Loss_G = 5.30230618 (ave = 3.46730138)\n",
            "\n",
            "epoch: [19/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.583s / 10iters, (0.058)\tData load 0.095s / 10iters, (0.009525)\n",
            "Loss_D = 0.56715626 (ave = 0.99340521)\n",
            "Loss_G = 3.97318935 (ave = 3.48224991)\n",
            "\n",
            "epoch: [19/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.317s / 10iters, (0.032)\tData load 0.067s / 10iters, (0.006690)\n",
            "Loss_D = 0.59342045 (ave = 1.00027855)\n",
            "Loss_G = 1.25712991 (ave = 3.47598666)\n",
            "\n",
            "epoch: [19/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.066s / 3iters, (0.022)\tData load 0.015s / 3iters, (0.004958)\n",
            "Loss_D = 1.82341218 (ave = 1.00478059)\n",
            "Loss_G = 1.96244299 (ave = 3.46369411)\n",
            "\n",
            "Real Accuracy : 74.80966567361801\n",
            "Fake Accuracy : 5.72658060244952\n",
            "epoch: [20/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.035s / 10iters, (0.504)\tData load 4.356s / 10iters, (0.435628)\n",
            "Loss_D = 3.39596224 (ave = 1.13122193)\n",
            "Loss_G = 5.46824121 (ave = 3.10840284)\n",
            "\n",
            "epoch: [20/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.736s / 10iters, (0.074)\tData load 0.100s / 10iters, (0.009980)\n",
            "Loss_D = 0.98399413 (ave = 1.06533016)\n",
            "Loss_G = 2.61059546 (ave = 3.17744516)\n",
            "\n",
            "epoch: [20/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.573s / 10iters, (0.057)\tData load 0.087s / 10iters, (0.008709)\n",
            "Loss_D = 0.68228769 (ave = 1.02680951)\n",
            "Loss_G = 3.72393441 (ave = 3.21285785)\n",
            "\n",
            "epoch: [20/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.568s / 10iters, (0.057)\tData load 0.090s / 10iters, (0.009009)\n",
            "Loss_D = 0.62397277 (ave = 0.98541900)\n",
            "Loss_G = 2.39910626 (ave = 3.27162563)\n",
            "\n",
            "epoch: [20/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.643s / 10iters, (0.064)\tData load 0.079s / 10iters, (0.007933)\n",
            "Loss_D = 0.95464015 (ave = 0.97806863)\n",
            "Loss_G = 2.33040786 (ave = 3.27510409)\n",
            "\n",
            "epoch: [20/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.624s / 10iters, (0.062)\tData load 0.073s / 10iters, (0.007273)\n",
            "Loss_D = 1.45077395 (ave = 1.01495099)\n",
            "Loss_G = 2.30016112 (ave = 3.31814650)\n",
            "\n",
            "epoch: [20/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.624s / 10iters, (0.062)\tData load 0.077s / 10iters, (0.007666)\n",
            "Loss_D = 0.73238838 (ave = 1.02625132)\n",
            "Loss_G = 3.72297311 (ave = 3.33122486)\n",
            "\n",
            "epoch: [20/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.713s / 10iters, (0.071)\tData load 0.089s / 10iters, (0.008930)\n",
            "Loss_D = 0.96043575 (ave = 0.99980305)\n",
            "Loss_G = 4.94384432 (ave = 3.34344699)\n",
            "\n",
            "epoch: [20/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.614s / 10iters, (0.061)\tData load 0.056s / 10iters, (0.005638)\n",
            "Loss_D = 1.44253004 (ave = 0.98727812)\n",
            "Loss_G = 1.71621752 (ave = 3.35311543)\n",
            "\n",
            "epoch: [20/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.611s / 10iters, (0.061)\tData load 0.048s / 10iters, (0.004766)\n",
            "Loss_D = 1.21782863 (ave = 0.97439476)\n",
            "Loss_G = 2.88386488 (ave = 3.37997092)\n",
            "\n",
            "epoch: [20/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.688s / 10iters, (0.069)\tData load 0.080s / 10iters, (0.007978)\n",
            "Loss_D = 1.83276224 (ave = 0.98372506)\n",
            "Loss_G = 1.74358189 (ave = 3.37577780)\n",
            "\n",
            "epoch: [20/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.600s / 10iters, (0.060)\tData load 0.104s / 10iters, (0.010391)\n",
            "Loss_D = 0.79611605 (ave = 0.97790468)\n",
            "Loss_G = 1.57798564 (ave = 3.35964034)\n",
            "\n",
            "epoch: [20/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.648s / 10iters, (0.065)\tData load 0.080s / 10iters, (0.008023)\n",
            "Loss_D = 1.00653434 (ave = 0.96444849)\n",
            "Loss_G = 5.54766178 (ave = 3.33554686)\n",
            "\n",
            "epoch: [20/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.574s / 10iters, (0.057)\tData load 0.062s / 10iters, (0.006154)\n",
            "Loss_D = 0.21897635 (ave = 0.95450313)\n",
            "Loss_G = 3.94055796 (ave = 3.34946864)\n",
            "\n",
            "epoch: [20/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.668s / 10iters, (0.067)\tData load 0.081s / 10iters, (0.008144)\n",
            "Loss_D = 0.77993786 (ave = 0.94540843)\n",
            "Loss_G = 2.85615110 (ave = 3.36135831)\n",
            "\n",
            "epoch: [20/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.664s / 10iters, (0.066)\tData load 0.066s / 10iters, (0.006574)\n",
            "Loss_D = 0.84342241 (ave = 0.94967939)\n",
            "Loss_G = 3.47711444 (ave = 3.38434283)\n",
            "\n",
            "epoch: [20/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.627s / 10iters, (0.063)\tData load 0.069s / 10iters, (0.006906)\n",
            "Loss_D = 1.65186381 (ave = 0.96102704)\n",
            "Loss_G = 6.17556477 (ave = 3.40176018)\n",
            "\n",
            "epoch: [20/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.606s / 10iters, (0.061)\tData load 0.084s / 10iters, (0.008427)\n",
            "Loss_D = 0.63694727 (ave = 0.95942629)\n",
            "Loss_G = 3.46226072 (ave = 3.42054054)\n",
            "\n",
            "epoch: [20/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.577s / 10iters, (0.058)\tData load 0.078s / 10iters, (0.007776)\n",
            "Loss_D = 2.17910910 (ave = 0.95533117)\n",
            "Loss_G = 6.28397799 (ave = 3.43364438)\n",
            "\n",
            "epoch: [20/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.629s / 10iters, (0.063)\tData load 0.071s / 10iters, (0.007146)\n",
            "Loss_D = 0.77675468 (ave = 0.96426003)\n",
            "Loss_G = 4.64510679 (ave = 3.44821406)\n",
            "\n",
            "epoch: [20/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.619s / 10iters, (0.062)\tData load 0.090s / 10iters, (0.009012)\n",
            "Loss_D = 0.99750841 (ave = 0.96262900)\n",
            "Loss_G = 4.12561893 (ave = 3.45253041)\n",
            "\n",
            "epoch: [20/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.575s / 10iters, (0.057)\tData load 0.079s / 10iters, (0.007929)\n",
            "Loss_D = 1.01804304 (ave = 0.96920882)\n",
            "Loss_G = 2.85715079 (ave = 3.44616617)\n",
            "\n",
            "epoch: [20/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.299s / 10iters, (0.030)\tData load 0.061s / 10iters, (0.006106)\n",
            "Loss_D = 0.79279250 (ave = 0.96698502)\n",
            "Loss_G = 3.87147355 (ave = 3.46276388)\n",
            "\n",
            "epoch: [20/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.066s / 3iters, (0.022)\tData load 0.016s / 3iters, (0.005424)\n",
            "Loss_D = 0.77937227 (ave = 0.96927345)\n",
            "Loss_G = 3.05299520 (ave = 3.46525442)\n",
            "\n",
            "Real Accuracy : 76.266137040715\n",
            "Fake Accuracy : 5.428666004634227\n",
            "epoch: [21/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.082s / 10iters, (0.508)\tData load 4.421s / 10iters, (0.442095)\n",
            "Loss_D = 0.48922259 (ave = 0.84440584)\n",
            "Loss_G = 3.13333917 (ave = 3.68743167)\n",
            "\n",
            "epoch: [21/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.611s / 10iters, (0.061)\tData load 0.092s / 10iters, (0.009199)\n",
            "Loss_D = 1.51934373 (ave = 0.94990886)\n",
            "Loss_G = 4.11173868 (ave = 3.62060987)\n",
            "\n",
            "epoch: [21/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.615s / 10iters, (0.062)\tData load 0.099s / 10iters, (0.009925)\n",
            "Loss_D = 0.64412415 (ave = 0.94641658)\n",
            "Loss_G = 5.08218145 (ave = 3.60294526)\n",
            "\n",
            "epoch: [21/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.647s / 10iters, (0.065)\tData load 0.087s / 10iters, (0.008732)\n",
            "Loss_D = 0.56275231 (ave = 0.96801524)\n",
            "Loss_G = 2.69048929 (ave = 3.59732923)\n",
            "\n",
            "epoch: [21/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.617s / 10iters, (0.062)\tData load 0.105s / 10iters, (0.010526)\n",
            "Loss_D = 1.12051439 (ave = 0.95960792)\n",
            "Loss_G = 5.04116106 (ave = 3.54572930)\n",
            "\n",
            "epoch: [21/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.627s / 10iters, (0.063)\tData load 0.106s / 10iters, (0.010588)\n",
            "Loss_D = 0.82469064 (ave = 0.95355824)\n",
            "Loss_G = 3.14269686 (ave = 3.55401229)\n",
            "\n",
            "epoch: [21/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.592s / 10iters, (0.059)\tData load 0.090s / 10iters, (0.008973)\n",
            "Loss_D = 1.34906149 (ave = 0.94695209)\n",
            "Loss_G = 4.04511452 (ave = 3.53807542)\n",
            "\n",
            "epoch: [21/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.632s / 10iters, (0.063)\tData load 0.083s / 10iters, (0.008350)\n",
            "Loss_D = 0.42215756 (ave = 0.91702861)\n",
            "Loss_G = 4.40666294 (ave = 3.50678114)\n",
            "\n",
            "epoch: [21/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.594s / 10iters, (0.059)\tData load 0.082s / 10iters, (0.008192)\n",
            "Loss_D = 0.59059274 (ave = 0.90344224)\n",
            "Loss_G = 2.39517951 (ave = 3.49979671)\n",
            "\n",
            "epoch: [21/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.638s / 10iters, (0.064)\tData load 0.091s / 10iters, (0.009069)\n",
            "Loss_D = 0.59263909 (ave = 0.90525906)\n",
            "Loss_G = 3.18424749 (ave = 3.54339305)\n",
            "\n",
            "epoch: [21/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.659s / 10iters, (0.066)\tData load 0.105s / 10iters, (0.010541)\n",
            "Loss_D = 0.75855488 (ave = 0.89534381)\n",
            "Loss_G = 3.67095995 (ave = 3.53367033)\n",
            "\n",
            "epoch: [21/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.716s / 10iters, (0.072)\tData load 0.076s / 10iters, (0.007637)\n",
            "Loss_D = 0.66188890 (ave = 0.88131427)\n",
            "Loss_G = 3.71463656 (ave = 3.51728018)\n",
            "\n",
            "epoch: [21/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.633s / 10iters, (0.063)\tData load 0.097s / 10iters, (0.009706)\n",
            "Loss_D = 0.64519507 (ave = 0.88527779)\n",
            "Loss_G = 1.97631443 (ave = 3.50050379)\n",
            "\n",
            "epoch: [21/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.631s / 10iters, (0.063)\tData load 0.103s / 10iters, (0.010315)\n",
            "Loss_D = 1.87936139 (ave = 0.91275163)\n",
            "Loss_G = 2.14645147 (ave = 3.53590212)\n",
            "\n",
            "epoch: [21/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.647s / 10iters, (0.065)\tData load 0.089s / 10iters, (0.008868)\n",
            "Loss_D = 1.31658709 (ave = 0.91892976)\n",
            "Loss_G = 1.42776382 (ave = 3.52527705)\n",
            "\n",
            "epoch: [21/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.619s / 10iters, (0.062)\tData load 0.099s / 10iters, (0.009858)\n",
            "Loss_D = 0.85076094 (ave = 0.91984464)\n",
            "Loss_G = 4.04575253 (ave = 3.53240218)\n",
            "\n",
            "epoch: [21/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.569s / 10iters, (0.057)\tData load 0.107s / 10iters, (0.010652)\n",
            "Loss_D = 0.47990716 (ave = 0.93609120)\n",
            "Loss_G = 2.05581760 (ave = 3.50813761)\n",
            "\n",
            "epoch: [21/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.639s / 10iters, (0.064)\tData load 0.116s / 10iters, (0.011559)\n",
            "Loss_D = 1.19009995 (ave = 0.93797866)\n",
            "Loss_G = 6.45383024 (ave = 3.51091736)\n",
            "\n",
            "epoch: [21/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.606s / 10iters, (0.061)\tData load 0.096s / 10iters, (0.009576)\n",
            "Loss_D = 0.71678537 (ave = 0.94084846)\n",
            "Loss_G = 4.05339575 (ave = 3.50698381)\n",
            "\n",
            "epoch: [21/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.646s / 10iters, (0.065)\tData load 0.096s / 10iters, (0.009626)\n",
            "Loss_D = 1.48147953 (ave = 0.93891884)\n",
            "Loss_G = 6.33366299 (ave = 3.50051831)\n",
            "\n",
            "epoch: [21/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.611s / 10iters, (0.061)\tData load 0.100s / 10iters, (0.009981)\n",
            "Loss_D = 0.85541970 (ave = 0.95292196)\n",
            "Loss_G = 2.94378662 (ave = 3.48789597)\n",
            "\n",
            "epoch: [21/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.620s / 10iters, (0.062)\tData load 0.070s / 10iters, (0.006952)\n",
            "Loss_D = 1.02437997 (ave = 0.95752858)\n",
            "Loss_G = 1.70623755 (ave = 3.47428160)\n",
            "\n",
            "epoch: [21/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.343s / 10iters, (0.034)\tData load 0.068s / 10iters, (0.006783)\n",
            "Loss_D = 0.58554399 (ave = 0.96107372)\n",
            "Loss_G = 2.66438031 (ave = 3.46273278)\n",
            "\n",
            "epoch: [21/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.066s / 3iters, (0.022)\tData load 0.016s / 3iters, (0.005193)\n",
            "Loss_D = 0.39831468 (ave = 0.95694876)\n",
            "Loss_G = 1.22391105 (ave = 3.45686552)\n",
            "\n",
            "Real Accuracy : 76.19993379675604\n",
            "Fake Accuracy : 6.156901688182721\n",
            "epoch: [22/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.116s / 10iters, (0.512)\tData load 4.323s / 10iters, (0.432281)\n",
            "Loss_D = 1.56693923 (ave = 0.99621115)\n",
            "Loss_G = 5.64610624 (ave = 3.59606044)\n",
            "\n",
            "epoch: [22/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.567s / 10iters, (0.057)\tData load 0.095s / 10iters, (0.009486)\n",
            "Loss_D = 1.10604763 (ave = 0.95821989)\n",
            "Loss_G = 3.76053762 (ave = 3.46979771)\n",
            "\n",
            "epoch: [22/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.720s / 10iters, (0.072)\tData load 0.099s / 10iters, (0.009916)\n",
            "Loss_D = 0.32873613 (ave = 0.88367403)\n",
            "Loss_G = 3.51333666 (ave = 3.38152413)\n",
            "\n",
            "epoch: [22/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.627s / 10iters, (0.063)\tData load 0.093s / 10iters, (0.009251)\n",
            "Loss_D = 0.80426407 (ave = 0.84637467)\n",
            "Loss_G = 4.10199785 (ave = 3.40614403)\n",
            "\n",
            "epoch: [22/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.642s / 10iters, (0.064)\tData load 0.096s / 10iters, (0.009588)\n",
            "Loss_D = 0.40712869 (ave = 0.88477993)\n",
            "Loss_G = 5.87000036 (ave = 3.47279010)\n",
            "\n",
            "epoch: [22/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.578s / 10iters, (0.058)\tData load 0.090s / 10iters, (0.008969)\n",
            "Loss_D = 0.97053933 (ave = 0.87827415)\n",
            "Loss_G = 4.28195381 (ave = 3.47914175)\n",
            "\n",
            "epoch: [22/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.614s / 10iters, (0.061)\tData load 0.079s / 10iters, (0.007917)\n",
            "Loss_D = 0.46129149 (ave = 0.88074914)\n",
            "Loss_G = 3.75382972 (ave = 3.50791356)\n",
            "\n",
            "epoch: [22/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.622s / 10iters, (0.062)\tData load 0.101s / 10iters, (0.010132)\n",
            "Loss_D = 0.77530193 (ave = 0.90271869)\n",
            "Loss_G = 2.56547499 (ave = 3.51155908)\n",
            "\n",
            "epoch: [22/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.681s / 10iters, (0.068)\tData load 0.099s / 10iters, (0.009918)\n",
            "Loss_D = 1.02280855 (ave = 0.89381725)\n",
            "Loss_G = 5.20927238 (ave = 3.50425499)\n",
            "\n",
            "epoch: [22/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.484s / 10iters, (0.048)\tData load 0.071s / 10iters, (0.007060)\n",
            "Loss_D = 0.67444634 (ave = 0.88978146)\n",
            "Loss_G = 2.43043590 (ave = 3.49104873)\n",
            "\n",
            "epoch: [22/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.678s / 10iters, (0.068)\tData load 0.123s / 10iters, (0.012344)\n",
            "Loss_D = 0.43709409 (ave = 0.89299668)\n",
            "Loss_G = 3.83429575 (ave = 3.51238548)\n",
            "\n",
            "epoch: [22/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.733s / 10iters, (0.073)\tData load 0.080s / 10iters, (0.007997)\n",
            "Loss_D = 0.64653456 (ave = 0.89940794)\n",
            "Loss_G = 5.09373283 (ave = 3.52755735)\n",
            "\n",
            "epoch: [22/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.636s / 10iters, (0.064)\tData load 0.076s / 10iters, (0.007616)\n",
            "Loss_D = 0.53369999 (ave = 0.89389749)\n",
            "Loss_G = 4.53208733 (ave = 3.52333326)\n",
            "\n",
            "epoch: [22/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.638s / 10iters, (0.064)\tData load 0.087s / 10iters, (0.008678)\n",
            "Loss_D = 0.81104016 (ave = 0.91168927)\n",
            "Loss_G = 3.01303697 (ave = 3.51245048)\n",
            "\n",
            "epoch: [22/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.614s / 10iters, (0.061)\tData load 0.104s / 10iters, (0.010449)\n",
            "Loss_D = 1.25597227 (ave = 0.91803297)\n",
            "Loss_G = 4.70521212 (ave = 3.51875976)\n",
            "\n",
            "epoch: [22/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.615s / 10iters, (0.062)\tData load 0.107s / 10iters, (0.010705)\n",
            "Loss_D = 0.50000834 (ave = 0.90219244)\n",
            "Loss_G = 3.11780763 (ave = 3.49248063)\n",
            "\n",
            "epoch: [22/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.650s / 10iters, (0.065)\tData load 0.069s / 10iters, (0.006851)\n",
            "Loss_D = 1.09461236 (ave = 0.90570196)\n",
            "Loss_G = 3.71529818 (ave = 3.49987981)\n",
            "\n",
            "epoch: [22/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.557s / 10iters, (0.056)\tData load 0.086s / 10iters, (0.008648)\n",
            "Loss_D = 0.97270250 (ave = 0.90146293)\n",
            "Loss_G = 2.31436110 (ave = 3.49454887)\n",
            "\n",
            "epoch: [22/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.678s / 10iters, (0.068)\tData load 0.102s / 10iters, (0.010163)\n",
            "Loss_D = 0.66499591 (ave = 0.91068653)\n",
            "Loss_G = 3.89788413 (ave = 3.49711697)\n",
            "\n",
            "epoch: [22/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.627s / 10iters, (0.063)\tData load 0.089s / 10iters, (0.008912)\n",
            "Loss_D = 2.24490404 (ave = 0.92775380)\n",
            "Loss_G = 2.09186387 (ave = 3.52090163)\n",
            "\n",
            "epoch: [22/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.615s / 10iters, (0.062)\tData load 0.092s / 10iters, (0.009173)\n",
            "Loss_D = 1.44715476 (ave = 0.94321161)\n",
            "Loss_G = 2.69480634 (ave = 3.50815737)\n",
            "\n",
            "epoch: [22/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.667s / 10iters, (0.067)\tData load 0.067s / 10iters, (0.006663)\n",
            "Loss_D = 0.64352256 (ave = 0.93719135)\n",
            "Loss_G = 4.53709221 (ave = 3.52244276)\n",
            "\n",
            "epoch: [22/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.330s / 10iters, (0.033)\tData load 0.045s / 10iters, (0.004517)\n",
            "Loss_D = 1.23474073 (ave = 0.95481103)\n",
            "Loss_G = 2.86295605 (ave = 3.52339857)\n",
            "\n",
            "epoch: [22/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.070s / 3iters, (0.023)\tData load 0.013s / 3iters, (0.004263)\n",
            "Loss_D = 4.21103096 (ave = 0.96972899)\n",
            "Loss_G = 2.26557636 (ave = 3.53103229)\n",
            "\n",
            "Real Accuracy : 76.49784839457134\n",
            "Fake Accuracy : 5.527970870572658\n",
            "epoch: [23/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.183s / 10iters, (0.518)\tData load 4.445s / 10iters, (0.444509)\n",
            "Loss_D = 1.23903215 (ave = 1.40786741)\n",
            "Loss_G = 2.04078269 (ave = 3.70623847)\n",
            "\n",
            "epoch: [23/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.616s / 10iters, (0.062)\tData load 0.085s / 10iters, (0.008525)\n",
            "Loss_D = 1.64314198 (ave = 1.31167666)\n",
            "Loss_G = 5.05676174 (ave = 3.61545374)\n",
            "\n",
            "epoch: [23/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.624s / 10iters, (0.062)\tData load 0.087s / 10iters, (0.008652)\n",
            "Loss_D = 0.53685439 (ave = 1.24654502)\n",
            "Loss_G = 3.35448170 (ave = 3.53079830)\n",
            "\n",
            "epoch: [23/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.640s / 10iters, (0.064)\tData load 0.074s / 10iters, (0.007395)\n",
            "Loss_D = 0.80052394 (ave = 1.19021583)\n",
            "Loss_G = 4.13580847 (ave = 3.50131671)\n",
            "\n",
            "epoch: [23/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.643s / 10iters, (0.064)\tData load 0.105s / 10iters, (0.010522)\n",
            "Loss_D = 0.67196023 (ave = 1.13585670)\n",
            "Loss_G = 2.46113682 (ave = 3.45396946)\n",
            "\n",
            "epoch: [23/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.613s / 10iters, (0.061)\tData load 0.081s / 10iters, (0.008075)\n",
            "Loss_D = 1.25952804 (ave = 1.10471871)\n",
            "Loss_G = 2.05429769 (ave = 3.40644189)\n",
            "\n",
            "epoch: [23/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.690s / 10iters, (0.069)\tData load 0.088s / 10iters, (0.008832)\n",
            "Loss_D = 0.91178405 (ave = 1.08849053)\n",
            "Loss_G = 2.03108072 (ave = 3.38397132)\n",
            "\n",
            "epoch: [23/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.577s / 10iters, (0.058)\tData load 0.075s / 10iters, (0.007542)\n",
            "Loss_D = 1.05544758 (ave = 1.07822080)\n",
            "Loss_G = 6.07383680 (ave = 3.42632564)\n",
            "\n",
            "epoch: [23/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.600s / 10iters, (0.060)\tData load 0.075s / 10iters, (0.007514)\n",
            "Loss_D = 1.61373401 (ave = 1.08229608)\n",
            "Loss_G = 3.37359762 (ave = 3.44029651)\n",
            "\n",
            "epoch: [23/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.627s / 10iters, (0.063)\tData load 0.098s / 10iters, (0.009791)\n",
            "Loss_D = 1.69434738 (ave = 1.09290620)\n",
            "Loss_G = 2.65290689 (ave = 3.46932038)\n",
            "\n",
            "epoch: [23/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.629s / 10iters, (0.063)\tData load 0.095s / 10iters, (0.009467)\n",
            "Loss_D = 1.29798579 (ave = 1.08105136)\n",
            "Loss_G = 4.48883438 (ave = 3.48617487)\n",
            "\n",
            "epoch: [23/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.782s / 10iters, (0.078)\tData load 0.098s / 10iters, (0.009786)\n",
            "Loss_D = 0.92615277 (ave = 1.07782316)\n",
            "Loss_G = 2.83443952 (ave = 3.46749823)\n",
            "\n",
            "epoch: [23/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.668s / 10iters, (0.067)\tData load 0.072s / 10iters, (0.007204)\n",
            "Loss_D = 0.79514283 (ave = 1.08264043)\n",
            "Loss_G = 2.61166334 (ave = 3.47340386)\n",
            "\n",
            "epoch: [23/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.606s / 10iters, (0.061)\tData load 0.088s / 10iters, (0.008829)\n",
            "Loss_D = 0.29688051 (ave = 1.07045930)\n",
            "Loss_G = 2.90132928 (ave = 3.47479568)\n",
            "\n",
            "epoch: [23/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.615s / 10iters, (0.062)\tData load 0.109s / 10iters, (0.010932)\n",
            "Loss_D = 0.97912014 (ave = 1.05859057)\n",
            "Loss_G = 4.30313158 (ave = 3.47767993)\n",
            "\n",
            "epoch: [23/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.624s / 10iters, (0.062)\tData load 0.070s / 10iters, (0.006990)\n",
            "Loss_D = 1.40725493 (ave = 1.05280787)\n",
            "Loss_G = 4.58633137 (ave = 3.46001327)\n",
            "\n",
            "epoch: [23/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.680s / 10iters, (0.068)\tData load 0.086s / 10iters, (0.008594)\n",
            "Loss_D = 0.84083825 (ave = 1.05456234)\n",
            "Loss_G = 4.34517384 (ave = 3.45536275)\n",
            "\n",
            "epoch: [23/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.666s / 10iters, (0.067)\tData load 0.072s / 10iters, (0.007198)\n",
            "Loss_D = 0.77073836 (ave = 1.04679963)\n",
            "Loss_G = 4.35688925 (ave = 3.47888318)\n",
            "\n",
            "epoch: [23/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.658s / 10iters, (0.066)\tData load 0.079s / 10iters, (0.007914)\n",
            "Loss_D = 1.37331700 (ave = 1.05284474)\n",
            "Loss_G = 2.77823281 (ave = 3.46162671)\n",
            "\n",
            "epoch: [23/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.619s / 10iters, (0.062)\tData load 0.073s / 10iters, (0.007311)\n",
            "Loss_D = 1.70129251 (ave = 1.05133759)\n",
            "Loss_G = 4.31035280 (ave = 3.49121824)\n",
            "\n",
            "epoch: [23/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.677s / 10iters, (0.068)\tData load 0.081s / 10iters, (0.008100)\n",
            "Loss_D = 0.53817207 (ave = 1.04184909)\n",
            "Loss_G = 3.54271555 (ave = 3.49627479)\n",
            "\n",
            "epoch: [23/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.577s / 10iters, (0.058)\tData load 0.079s / 10iters, (0.007922)\n",
            "Loss_D = 0.94947845 (ave = 1.03023035)\n",
            "Loss_G = 1.59950876 (ave = 3.48749946)\n",
            "\n",
            "epoch: [23/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.368s / 10iters, (0.037)\tData load 0.069s / 10iters, (0.006930)\n",
            "Loss_D = 1.41502059 (ave = 1.02941718)\n",
            "Loss_G = 1.18696761 (ave = 3.47638765)\n",
            "\n",
            "epoch: [23/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.073s / 3iters, (0.024)\tData load 0.015s / 3iters, (0.004870)\n",
            "Loss_D = 0.51833838 (ave = 1.02686604)\n",
            "Loss_G = 5.44003820 (ave = 3.48848162)\n",
            "\n",
            "Real Accuracy : 75.30619000331016\n",
            "Fake Accuracy : 6.71962926183383\n",
            "epoch: [24/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.066s / 10iters, (0.507)\tData load 4.342s / 10iters, (0.434162)\n",
            "Loss_D = 0.52843291 (ave = 0.73282009)\n",
            "Loss_G = 3.24651361 (ave = 3.34753118)\n",
            "\n",
            "epoch: [24/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.689s / 10iters, (0.069)\tData load 0.086s / 10iters, (0.008564)\n",
            "Loss_D = 0.61804831 (ave = 0.82012473)\n",
            "Loss_G = 3.42282844 (ave = 3.29653237)\n",
            "\n",
            "epoch: [24/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.606s / 10iters, (0.061)\tData load 0.074s / 10iters, (0.007445)\n",
            "Loss_D = 1.07047558 (ave = 0.81657168)\n",
            "Loss_G = 3.35001373 (ave = 3.32481780)\n",
            "\n",
            "epoch: [24/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.741s / 10iters, (0.074)\tData load 0.075s / 10iters, (0.007504)\n",
            "Loss_D = 0.96909916 (ave = 0.83622354)\n",
            "Loss_G = 3.24262905 (ave = 3.35558315)\n",
            "\n",
            "epoch: [24/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.614s / 10iters, (0.061)\tData load 0.086s / 10iters, (0.008632)\n",
            "Loss_D = 0.82160544 (ave = 0.83610778)\n",
            "Loss_G = 3.66692495 (ave = 3.31679097)\n",
            "\n",
            "epoch: [24/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.656s / 10iters, (0.066)\tData load 0.077s / 10iters, (0.007749)\n",
            "Loss_D = 1.03866732 (ave = 0.84315556)\n",
            "Loss_G = 4.31274414 (ave = 3.33839884)\n",
            "\n",
            "epoch: [24/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.720s / 10iters, (0.072)\tData load 0.057s / 10iters, (0.005701)\n",
            "Loss_D = 0.78530562 (ave = 0.86612932)\n",
            "Loss_G = 3.33215046 (ave = 3.32193453)\n",
            "\n",
            "epoch: [24/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.662s / 10iters, (0.066)\tData load 0.076s / 10iters, (0.007626)\n",
            "Loss_D = 0.95649052 (ave = 0.84885221)\n",
            "Loss_G = 5.16878462 (ave = 3.34372539)\n",
            "\n",
            "epoch: [24/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.700s / 10iters, (0.070)\tData load 0.077s / 10iters, (0.007669)\n",
            "Loss_D = 1.39639473 (ave = 0.85512808)\n",
            "Loss_G = 5.10906410 (ave = 3.36436210)\n",
            "\n",
            "epoch: [24/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.599s / 10iters, (0.060)\tData load 0.098s / 10iters, (0.009808)\n",
            "Loss_D = 0.61327660 (ave = 0.85232367)\n",
            "Loss_G = 2.43132043 (ave = 3.33146273)\n",
            "\n",
            "epoch: [24/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.583s / 10iters, (0.058)\tData load 0.081s / 10iters, (0.008062)\n",
            "Loss_D = 1.45548975 (ave = 0.84242633)\n",
            "Loss_G = 1.87242532 (ave = 3.33192974)\n",
            "\n",
            "epoch: [24/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.726s / 10iters, (0.073)\tData load 0.091s / 10iters, (0.009094)\n",
            "Loss_D = 0.34207296 (ave = 0.85873372)\n",
            "Loss_G = 4.43933773 (ave = 3.36612771)\n",
            "\n",
            "epoch: [24/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.499s / 10iters, (0.050)\tData load 0.043s / 10iters, (0.004346)\n",
            "Loss_D = 1.31455874 (ave = 0.86067812)\n",
            "Loss_G = 2.93059659 (ave = 3.38323718)\n",
            "\n",
            "epoch: [24/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.836s / 10iters, (0.084)\tData load 0.095s / 10iters, (0.009529)\n",
            "Loss_D = 1.05175471 (ave = 0.86206080)\n",
            "Loss_G = 2.57646513 (ave = 3.41352119)\n",
            "\n",
            "epoch: [24/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.503s / 10iters, (0.050)\tData load 0.062s / 10iters, (0.006214)\n",
            "Loss_D = 0.66246128 (ave = 0.87334487)\n",
            "Loss_G = 2.58664703 (ave = 3.42275820)\n",
            "\n",
            "epoch: [24/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.748s / 10iters, (0.075)\tData load 0.080s / 10iters, (0.008035)\n",
            "Loss_D = 1.47410953 (ave = 0.87924920)\n",
            "Loss_G = 3.96196270 (ave = 3.45465224)\n",
            "\n",
            "epoch: [24/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.644s / 10iters, (0.064)\tData load 0.091s / 10iters, (0.009108)\n",
            "Loss_D = 1.06838214 (ave = 0.87743607)\n",
            "Loss_G = 2.74868822 (ave = 3.44176719)\n",
            "\n",
            "epoch: [24/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.632s / 10iters, (0.063)\tData load 0.092s / 10iters, (0.009173)\n",
            "Loss_D = 0.99532527 (ave = 0.86644828)\n",
            "Loss_G = 1.51569068 (ave = 3.43007044)\n",
            "\n",
            "epoch: [24/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.596s / 10iters, (0.060)\tData load 0.064s / 10iters, (0.006444)\n",
            "Loss_D = 0.92862296 (ave = 0.88129510)\n",
            "Loss_G = 2.94139194 (ave = 3.45235033)\n",
            "\n",
            "epoch: [24/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.661s / 10iters, (0.066)\tData load 0.091s / 10iters, (0.009054)\n",
            "Loss_D = 1.12061214 (ave = 0.88176240)\n",
            "Loss_G = 4.19943285 (ave = 3.45760708)\n",
            "\n",
            "epoch: [24/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.662s / 10iters, (0.066)\tData load 0.083s / 10iters, (0.008283)\n",
            "Loss_D = 0.78323513 (ave = 0.88164956)\n",
            "Loss_G = 5.33728838 (ave = 3.47489361)\n",
            "\n",
            "epoch: [24/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.604s / 10iters, (0.060)\tData load 0.101s / 10iters, (0.010070)\n",
            "Loss_D = 0.52634519 (ave = 0.88647720)\n",
            "Loss_G = 3.16573477 (ave = 3.48050724)\n",
            "\n",
            "epoch: [24/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.325s / 10iters, (0.033)\tData load 0.072s / 10iters, (0.007238)\n",
            "Loss_D = 0.36011794 (ave = 0.88650629)\n",
            "Loss_G = 1.96287775 (ave = 3.43971881)\n",
            "\n",
            "epoch: [24/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.065s / 3iters, (0.022)\tData load 0.015s / 3iters, (0.005156)\n",
            "Loss_D = 2.08869648 (ave = 0.89425249)\n",
            "Loss_G = 1.45453012 (ave = 3.44258579)\n",
            "\n",
            "Real Accuracy : 78.25223435948361\n",
            "Fake Accuracy : 5.693478980470043\n",
            "epoch: [25/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.139s / 10iters, (0.514)\tData load 4.426s / 10iters, (0.442617)\n",
            "Loss_D = 0.44944537 (ave = 0.75140669)\n",
            "Loss_G = 3.34951949 (ave = 3.50597987)\n",
            "\n",
            "epoch: [25/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.688s / 10iters, (0.069)\tData load 0.115s / 10iters, (0.011458)\n",
            "Loss_D = 0.97426939 (ave = 0.78709570)\n",
            "Loss_G = 3.74738789 (ave = 3.45545665)\n",
            "\n",
            "epoch: [25/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.630s / 10iters, (0.063)\tData load 0.097s / 10iters, (0.009693)\n",
            "Loss_D = 0.49198231 (ave = 0.84326161)\n",
            "Loss_G = 4.00082159 (ave = 3.52652737)\n",
            "\n",
            "epoch: [25/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.644s / 10iters, (0.064)\tData load 0.140s / 10iters, (0.014033)\n",
            "Loss_D = 0.92585444 (ave = 0.82330869)\n",
            "Loss_G = 5.53116179 (ave = 3.47304720)\n",
            "\n",
            "epoch: [25/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.678s / 10iters, (0.068)\tData load 0.062s / 10iters, (0.006195)\n",
            "Loss_D = 0.34505045 (ave = 0.77335835)\n",
            "Loss_G = 2.58379006 (ave = 3.41817812)\n",
            "\n",
            "epoch: [25/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.659s / 10iters, (0.066)\tData load 0.071s / 10iters, (0.007149)\n",
            "Loss_D = 1.91546488 (ave = 0.79890365)\n",
            "Loss_G = 6.45719671 (ave = 3.47813946)\n",
            "\n",
            "epoch: [25/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.569s / 10iters, (0.057)\tData load 0.094s / 10iters, (0.009447)\n",
            "Loss_D = 1.58952320 (ave = 0.80910069)\n",
            "Loss_G = 5.58835268 (ave = 3.50875936)\n",
            "\n",
            "epoch: [25/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.687s / 10iters, (0.069)\tData load 0.093s / 10iters, (0.009301)\n",
            "Loss_D = 0.85718691 (ave = 0.82399216)\n",
            "Loss_G = 3.61430454 (ave = 3.47890600)\n",
            "\n",
            "epoch: [25/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.604s / 10iters, (0.060)\tData load 0.081s / 10iters, (0.008136)\n",
            "Loss_D = 0.68745863 (ave = 0.83217153)\n",
            "Loss_G = 4.52302647 (ave = 3.51288124)\n",
            "\n",
            "epoch: [25/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.622s / 10iters, (0.062)\tData load 0.083s / 10iters, (0.008327)\n",
            "Loss_D = 0.78864324 (ave = 0.85580986)\n",
            "Loss_G = 4.89496803 (ave = 3.50609637)\n",
            "\n",
            "epoch: [25/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.604s / 10iters, (0.060)\tData load 0.096s / 10iters, (0.009582)\n",
            "Loss_D = 0.63333941 (ave = 0.88835171)\n",
            "Loss_G = 6.19436407 (ave = 3.55811437)\n",
            "\n",
            "epoch: [25/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.689s / 10iters, (0.069)\tData load 0.083s / 10iters, (0.008314)\n",
            "Loss_D = 0.76670414 (ave = 0.89286538)\n",
            "Loss_G = 3.53566957 (ave = 3.55942597)\n",
            "\n",
            "epoch: [25/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.588s / 10iters, (0.059)\tData load 0.077s / 10iters, (0.007698)\n",
            "Loss_D = 0.57178330 (ave = 0.89049066)\n",
            "Loss_G = 4.06135845 (ave = 3.55101725)\n",
            "\n",
            "epoch: [25/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.607s / 10iters, (0.061)\tData load 0.047s / 10iters, (0.004703)\n",
            "Loss_D = 0.94037819 (ave = 0.88226648)\n",
            "Loss_G = 3.32246804 (ave = 3.52875664)\n",
            "\n",
            "epoch: [25/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.657s / 10iters, (0.066)\tData load 0.088s / 10iters, (0.008806)\n",
            "Loss_D = 0.55077094 (ave = 0.86374320)\n",
            "Loss_G = 2.27887130 (ave = 3.52843402)\n",
            "\n",
            "epoch: [25/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.597s / 10iters, (0.060)\tData load 0.105s / 10iters, (0.010490)\n",
            "Loss_D = 0.73426497 (ave = 0.86688756)\n",
            "Loss_G = 2.03143787 (ave = 3.51849768)\n",
            "\n",
            "epoch: [25/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.613s / 10iters, (0.061)\tData load 0.063s / 10iters, (0.006343)\n",
            "Loss_D = 0.61917597 (ave = 0.86496766)\n",
            "Loss_G = 5.06380129 (ave = 3.54560094)\n",
            "\n",
            "epoch: [25/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.653s / 10iters, (0.065)\tData load 0.074s / 10iters, (0.007407)\n",
            "Loss_D = 1.44970727 (ave = 0.86964918)\n",
            "Loss_G = 4.71234417 (ave = 3.52897901)\n",
            "\n",
            "epoch: [25/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.627s / 10iters, (0.063)\tData load 0.082s / 10iters, (0.008156)\n",
            "Loss_D = 1.05481374 (ave = 0.87401531)\n",
            "Loss_G = 4.86764240 (ave = 3.52987760)\n",
            "\n",
            "epoch: [25/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.577s / 10iters, (0.058)\tData load 0.083s / 10iters, (0.008318)\n",
            "Loss_D = 1.80631661 (ave = 0.89393027)\n",
            "Loss_G = 4.48502684 (ave = 3.54764282)\n",
            "\n",
            "epoch: [25/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.577s / 10iters, (0.058)\tData load 0.094s / 10iters, (0.009421)\n",
            "Loss_D = 0.99728739 (ave = 0.88836182)\n",
            "Loss_G = 5.42559528 (ave = 3.54966253)\n",
            "\n",
            "epoch: [25/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.636s / 10iters, (0.064)\tData load 0.071s / 10iters, (0.007074)\n",
            "Loss_D = 0.62085146 (ave = 0.89724665)\n",
            "Loss_G = 1.87286997 (ave = 3.53990116)\n",
            "\n",
            "epoch: [25/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.301s / 10iters, (0.030)\tData load 0.057s / 10iters, (0.005748)\n",
            "Loss_D = 0.78820550 (ave = 0.89815218)\n",
            "Loss_G = 3.52335477 (ave = 3.53977103)\n",
            "\n",
            "epoch: [25/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.066s / 3iters, (0.022)\tData load 0.016s / 3iters, (0.005392)\n",
            "Loss_D = 1.99763179 (ave = 0.90259738)\n",
            "Loss_G = 9.19964886 (ave = 3.56636819)\n",
            "\n",
            "Real Accuracy : 77.9874213836478\n",
            "Fake Accuracy : 5.428666004634227\n",
            "epoch: [26/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.039s / 10iters, (0.504)\tData load 4.273s / 10iters, (0.427273)\n",
            "Loss_D = 1.51076174 (ave = 1.04161617)\n",
            "Loss_G = 5.42947626 (ave = 3.65499783)\n",
            "\n",
            "epoch: [26/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.709s / 10iters, (0.071)\tData load 0.088s / 10iters, (0.008814)\n",
            "Loss_D = 1.21932030 (ave = 0.94647408)\n",
            "Loss_G = 3.34407258 (ave = 3.62836577)\n",
            "\n",
            "epoch: [26/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.641s / 10iters, (0.064)\tData load 0.078s / 10iters, (0.007830)\n",
            "Loss_D = 0.76878542 (ave = 0.87124033)\n",
            "Loss_G = 3.54781246 (ave = 3.56101202)\n",
            "\n",
            "epoch: [26/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.626s / 10iters, (0.063)\tData load 0.120s / 10iters, (0.012049)\n",
            "Loss_D = 0.85283685 (ave = 0.82921253)\n",
            "Loss_G = 2.94630098 (ave = 3.51983587)\n",
            "\n",
            "epoch: [26/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.669s / 10iters, (0.067)\tData load 0.084s / 10iters, (0.008369)\n",
            "Loss_D = 0.71754897 (ave = 0.81459760)\n",
            "Loss_G = 5.49406195 (ave = 3.54546344)\n",
            "\n",
            "epoch: [26/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.567s / 10iters, (0.057)\tData load 0.086s / 10iters, (0.008617)\n",
            "Loss_D = 0.88544959 (ave = 0.81104303)\n",
            "Loss_G = 3.46885800 (ave = 3.50175272)\n",
            "\n",
            "epoch: [26/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.632s / 10iters, (0.063)\tData load 0.084s / 10iters, (0.008438)\n",
            "Loss_D = 0.98019278 (ave = 0.83127867)\n",
            "Loss_G = 2.12633061 (ave = 3.52574441)\n",
            "\n",
            "epoch: [26/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.624s / 10iters, (0.062)\tData load 0.103s / 10iters, (0.010342)\n",
            "Loss_D = 1.02560401 (ave = 0.82533034)\n",
            "Loss_G = 3.71014118 (ave = 3.53072405)\n",
            "\n",
            "epoch: [26/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.715s / 10iters, (0.071)\tData load 0.079s / 10iters, (0.007863)\n",
            "Loss_D = 0.46806416 (ave = 0.81356901)\n",
            "Loss_G = 3.22839880 (ave = 3.52700927)\n",
            "\n",
            "epoch: [26/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.567s / 10iters, (0.057)\tData load 0.086s / 10iters, (0.008590)\n",
            "Loss_D = 0.50475305 (ave = 0.82151136)\n",
            "Loss_G = 2.60155773 (ave = 3.49708152)\n",
            "\n",
            "epoch: [26/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.598s / 10iters, (0.060)\tData load 0.073s / 10iters, (0.007262)\n",
            "Loss_D = 0.55767989 (ave = 0.83170608)\n",
            "Loss_G = 3.92816186 (ave = 3.51676992)\n",
            "\n",
            "epoch: [26/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.653s / 10iters, (0.065)\tData load 0.080s / 10iters, (0.007970)\n",
            "Loss_D = 0.84038174 (ave = 0.82819457)\n",
            "Loss_G = 5.76910400 (ave = 3.51978594)\n",
            "\n",
            "epoch: [26/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.702s / 10iters, (0.070)\tData load 0.130s / 10iters, (0.012984)\n",
            "Loss_D = 0.78841817 (ave = 0.83273483)\n",
            "Loss_G = 4.30812502 (ave = 3.50212172)\n",
            "\n",
            "epoch: [26/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.663s / 10iters, (0.066)\tData load 0.107s / 10iters, (0.010734)\n",
            "Loss_D = 0.74359733 (ave = 0.82659518)\n",
            "Loss_G = 2.92304492 (ave = 3.46841482)\n",
            "\n",
            "epoch: [26/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.701s / 10iters, (0.070)\tData load 0.092s / 10iters, (0.009172)\n",
            "Loss_D = 1.26028490 (ave = 0.83258853)\n",
            "Loss_G = 6.39461279 (ave = 3.49058345)\n",
            "\n",
            "epoch: [26/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.587s / 10iters, (0.059)\tData load 0.086s / 10iters, (0.008585)\n",
            "Loss_D = 0.93959200 (ave = 0.84054178)\n",
            "Loss_G = 5.51100254 (ave = 3.52165992)\n",
            "\n",
            "epoch: [26/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.587s / 10iters, (0.059)\tData load 0.071s / 10iters, (0.007129)\n",
            "Loss_D = 0.33824354 (ave = 0.83825973)\n",
            "Loss_G = 3.94722414 (ave = 3.54105950)\n",
            "\n",
            "epoch: [26/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.692s / 10iters, (0.069)\tData load 0.074s / 10iters, (0.007411)\n",
            "Loss_D = 0.97038186 (ave = 0.83347275)\n",
            "Loss_G = 3.51416612 (ave = 3.54233638)\n",
            "\n",
            "epoch: [26/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.612s / 10iters, (0.061)\tData load 0.060s / 10iters, (0.005972)\n",
            "Loss_D = 0.72460222 (ave = 0.85086764)\n",
            "Loss_G = 2.50395036 (ave = 3.56177708)\n",
            "\n",
            "epoch: [26/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.635s / 10iters, (0.063)\tData load 0.074s / 10iters, (0.007444)\n",
            "Loss_D = 0.54045743 (ave = 0.84677798)\n",
            "Loss_G = 2.02899575 (ave = 3.54764606)\n",
            "\n",
            "epoch: [26/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.623s / 10iters, (0.062)\tData load 0.083s / 10iters, (0.008258)\n",
            "Loss_D = 0.55572659 (ave = 0.85689614)\n",
            "Loss_G = 3.55067873 (ave = 3.54894373)\n",
            "\n",
            "epoch: [26/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.668s / 10iters, (0.067)\tData load 0.080s / 10iters, (0.008000)\n",
            "Loss_D = 0.52792269 (ave = 0.85704006)\n",
            "Loss_G = 2.42950487 (ave = 3.54527317)\n",
            "\n",
            "epoch: [26/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.309s / 10iters, (0.031)\tData load 0.052s / 10iters, (0.005196)\n",
            "Loss_D = 0.73611641 (ave = 0.86897677)\n",
            "Loss_G = 5.46685743 (ave = 3.56540404)\n",
            "\n",
            "epoch: [26/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.073s / 3iters, (0.024)\tData load 0.013s / 3iters, (0.004210)\n",
            "Loss_D = 0.29731604 (ave = 0.86979909)\n",
            "Loss_G = 3.64685678 (ave = 3.55686547)\n",
            "\n",
            "Real Accuracy : 79.84111221449851\n",
            "Fake Accuracy : 6.487917907977491\n",
            "epoch: [27/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.235s / 10iters, (0.524)\tData load 4.415s / 10iters, (0.441496)\n",
            "Loss_D = 0.44730508 (ave = 0.79104736)\n",
            "Loss_G = 3.13202024 (ave = 3.63382469)\n",
            "\n",
            "epoch: [27/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.767s / 10iters, (0.077)\tData load 0.100s / 10iters, (0.010029)\n",
            "Loss_D = 1.66381001 (ave = 1.04989520)\n",
            "Loss_G = 5.93276978 (ave = 3.61940023)\n",
            "\n",
            "epoch: [27/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.627s / 10iters, (0.063)\tData load 0.080s / 10iters, (0.008033)\n",
            "Loss_D = 0.56832796 (ave = 1.00270608)\n",
            "Loss_G = 3.17910361 (ave = 3.43296281)\n",
            "\n",
            "epoch: [27/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.665s / 10iters, (0.067)\tData load 0.083s / 10iters, (0.008348)\n",
            "Loss_D = 0.29986465 (ave = 0.96358748)\n",
            "Loss_G = 3.42743778 (ave = 3.57431456)\n",
            "\n",
            "epoch: [27/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.595s / 10iters, (0.060)\tData load 0.081s / 10iters, (0.008054)\n",
            "Loss_D = 0.87339818 (ave = 0.91751253)\n",
            "Loss_G = 3.30959702 (ave = 3.56671411)\n",
            "\n",
            "epoch: [27/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.651s / 10iters, (0.065)\tData load 0.117s / 10iters, (0.011730)\n",
            "Loss_D = 0.88756305 (ave = 0.87413387)\n",
            "Loss_G = 2.69337559 (ave = 3.56781224)\n",
            "\n",
            "epoch: [27/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.689s / 10iters, (0.069)\tData load 0.088s / 10iters, (0.008759)\n",
            "Loss_D = 1.06117165 (ave = 0.85747160)\n",
            "Loss_G = 4.26245689 (ave = 3.54699879)\n",
            "\n",
            "epoch: [27/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.639s / 10iters, (0.064)\tData load 0.082s / 10iters, (0.008209)\n",
            "Loss_D = 0.79784471 (ave = 0.88968682)\n",
            "Loss_G = 3.69255424 (ave = 3.58184558)\n",
            "\n",
            "epoch: [27/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.654s / 10iters, (0.065)\tData load 0.090s / 10iters, (0.008980)\n",
            "Loss_D = 1.04958379 (ave = 0.89264024)\n",
            "Loss_G = 3.91845036 (ave = 3.58810898)\n",
            "\n",
            "epoch: [27/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.643s / 10iters, (0.064)\tData load 0.057s / 10iters, (0.005740)\n",
            "Loss_D = 1.55060017 (ave = 0.89382809)\n",
            "Loss_G = 2.07786775 (ave = 3.56263949)\n",
            "\n",
            "epoch: [27/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.703s / 10iters, (0.070)\tData load 0.126s / 10iters, (0.012557)\n",
            "Loss_D = 1.04259133 (ave = 0.88841615)\n",
            "Loss_G = 2.74364853 (ave = 3.53962569)\n",
            "\n",
            "epoch: [27/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.641s / 10iters, (0.064)\tData load 0.080s / 10iters, (0.008019)\n",
            "Loss_D = 0.86273658 (ave = 0.88832889)\n",
            "Loss_G = 3.66513705 (ave = 3.53443168)\n",
            "\n",
            "epoch: [27/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.637s / 10iters, (0.064)\tData load 0.104s / 10iters, (0.010410)\n",
            "Loss_D = 0.78147179 (ave = 0.86470550)\n",
            "Loss_G = 2.95068860 (ave = 3.51269988)\n",
            "\n",
            "epoch: [27/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.677s / 10iters, (0.068)\tData load 0.085s / 10iters, (0.008490)\n",
            "Loss_D = 0.98411924 (ave = 0.86106586)\n",
            "Loss_G = 3.66716099 (ave = 3.50831219)\n",
            "\n",
            "epoch: [27/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.634s / 10iters, (0.063)\tData load 0.073s / 10iters, (0.007336)\n",
            "Loss_D = 0.77813345 (ave = 0.85725328)\n",
            "Loss_G = 3.82330966 (ave = 3.50843208)\n",
            "\n",
            "epoch: [27/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.659s / 10iters, (0.066)\tData load 0.094s / 10iters, (0.009382)\n",
            "Loss_D = 0.49941760 (ave = 0.84671120)\n",
            "Loss_G = 4.18051481 (ave = 3.48751685)\n",
            "\n",
            "epoch: [27/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.619s / 10iters, (0.062)\tData load 0.074s / 10iters, (0.007443)\n",
            "Loss_D = 0.75288725 (ave = 0.84492409)\n",
            "Loss_G = 4.13144112 (ave = 3.50087456)\n",
            "\n",
            "epoch: [27/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.596s / 10iters, (0.060)\tData load 0.083s / 10iters, (0.008345)\n",
            "Loss_D = 0.44980612 (ave = 0.84018095)\n",
            "Loss_G = 4.00873995 (ave = 3.50515464)\n",
            "\n",
            "epoch: [27/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.630s / 10iters, (0.063)\tData load 0.082s / 10iters, (0.008161)\n",
            "Loss_D = 0.34361506 (ave = 0.84297182)\n",
            "Loss_G = 3.12344027 (ave = 3.52479628)\n",
            "\n",
            "epoch: [27/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.675s / 10iters, (0.068)\tData load 0.096s / 10iters, (0.009561)\n",
            "Loss_D = 0.68383163 (ave = 0.85185073)\n",
            "Loss_G = 3.97687888 (ave = 3.52479969)\n",
            "\n",
            "epoch: [27/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.654s / 10iters, (0.065)\tData load 0.082s / 10iters, (0.008244)\n",
            "Loss_D = 1.29241133 (ave = 0.86038135)\n",
            "Loss_G = 3.91030121 (ave = 3.53145084)\n",
            "\n",
            "epoch: [27/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.568s / 10iters, (0.057)\tData load 0.079s / 10iters, (0.007859)\n",
            "Loss_D = 0.45574975 (ave = 0.85460239)\n",
            "Loss_G = 4.26829815 (ave = 3.52700611)\n",
            "\n",
            "epoch: [27/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.364s / 10iters, (0.036)\tData load 0.069s / 10iters, (0.006911)\n",
            "Loss_D = 0.99209565 (ave = 0.86122316)\n",
            "Loss_G = 4.17800236 (ave = 3.52390363)\n",
            "\n",
            "epoch: [27/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.069s / 3iters, (0.023)\tData load 0.018s / 3iters, (0.005897)\n",
            "Loss_D = 0.52305228 (ave = 0.86763686)\n",
            "Loss_G = 6.24025393 (ave = 3.53143830)\n",
            "\n",
            "Real Accuracy : 79.41079112876531\n",
            "Fake Accuracy : 5.958291956305859\n",
            "epoch: [28/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.151s / 10iters, (0.515)\tData load 4.404s / 10iters, (0.440394)\n",
            "Loss_D = 0.47508493 (ave = 0.86682125)\n",
            "Loss_G = 2.47693610 (ave = 3.52852721)\n",
            "\n",
            "epoch: [28/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.642s / 10iters, (0.064)\tData load 0.089s / 10iters, (0.008853)\n",
            "Loss_D = 0.92498833 (ave = 0.90254909)\n",
            "Loss_G = 3.32881260 (ave = 3.67837855)\n",
            "\n",
            "epoch: [28/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.649s / 10iters, (0.065)\tData load 0.111s / 10iters, (0.011054)\n",
            "Loss_D = 0.59058350 (ave = 0.86266098)\n",
            "Loss_G = 2.85222268 (ave = 3.46409953)\n",
            "\n",
            "epoch: [28/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.666s / 10iters, (0.067)\tData load 0.102s / 10iters, (0.010224)\n",
            "Loss_D = 0.56712198 (ave = 0.83925887)\n",
            "Loss_G = 3.36378956 (ave = 3.49292460)\n",
            "\n",
            "epoch: [28/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.619s / 10iters, (0.062)\tData load 0.099s / 10iters, (0.009921)\n",
            "Loss_D = 0.91388965 (ave = 0.83189997)\n",
            "Loss_G = 2.35461903 (ave = 3.51483120)\n",
            "\n",
            "epoch: [28/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.620s / 10iters, (0.062)\tData load 0.085s / 10iters, (0.008536)\n",
            "Loss_D = 0.44005814 (ave = 0.81906801)\n",
            "Loss_G = 2.26914120 (ave = 3.46013766)\n",
            "\n",
            "epoch: [28/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.538s / 10iters, (0.054)\tData load 0.066s / 10iters, (0.006629)\n",
            "Loss_D = 1.15162444 (ave = 0.80890245)\n",
            "Loss_G = 2.90317631 (ave = 3.47313312)\n",
            "\n",
            "epoch: [28/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.693s / 10iters, (0.069)\tData load 0.090s / 10iters, (0.008988)\n",
            "Loss_D = 0.73485017 (ave = 0.80617083)\n",
            "Loss_G = 5.16430712 (ave = 3.46761929)\n",
            "\n",
            "epoch: [28/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.609s / 10iters, (0.061)\tData load 0.084s / 10iters, (0.008436)\n",
            "Loss_D = 0.54249173 (ave = 0.81025498)\n",
            "Loss_G = 2.82591200 (ave = 3.47247033)\n",
            "\n",
            "epoch: [28/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.655s / 10iters, (0.066)\tData load 0.080s / 10iters, (0.008029)\n",
            "Loss_D = 0.99057364 (ave = 0.80867641)\n",
            "Loss_G = 1.47481489 (ave = 3.46387124)\n",
            "\n",
            "epoch: [28/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.528s / 10iters, (0.053)\tData load 0.079s / 10iters, (0.007921)\n",
            "Loss_D = 0.53545159 (ave = 0.83557814)\n",
            "Loss_G = 3.91759777 (ave = 3.52017847)\n",
            "\n",
            "epoch: [28/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.795s / 10iters, (0.080)\tData load 0.101s / 10iters, (0.010144)\n",
            "Loss_D = 0.45806414 (ave = 0.82434541)\n",
            "Loss_G = 3.11497164 (ave = 3.49743088)\n",
            "\n",
            "epoch: [28/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.570s / 10iters, (0.057)\tData load 0.061s / 10iters, (0.006134)\n",
            "Loss_D = 1.13565397 (ave = 0.81995255)\n",
            "Loss_G = 2.77556324 (ave = 3.51605365)\n",
            "\n",
            "epoch: [28/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.679s / 10iters, (0.068)\tData load 0.108s / 10iters, (0.010792)\n",
            "Loss_D = 0.44777027 (ave = 0.81639853)\n",
            "Loss_G = 4.92180157 (ave = 3.57203578)\n",
            "\n",
            "epoch: [28/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.578s / 10iters, (0.058)\tData load 0.070s / 10iters, (0.007044)\n",
            "Loss_D = 1.21334648 (ave = 0.85385206)\n",
            "Loss_G = 3.68784308 (ave = 3.58926576)\n",
            "\n",
            "epoch: [28/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.635s / 10iters, (0.064)\tData load 0.079s / 10iters, (0.007896)\n",
            "Loss_D = 0.79948038 (ave = 0.85493909)\n",
            "Loss_G = 4.49398613 (ave = 3.60127569)\n",
            "\n",
            "epoch: [28/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.612s / 10iters, (0.061)\tData load 0.107s / 10iters, (0.010727)\n",
            "Loss_D = 0.40673417 (ave = 0.85389932)\n",
            "Loss_G = 1.67434764 (ave = 3.57857712)\n",
            "\n",
            "epoch: [28/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.630s / 10iters, (0.063)\tData load 0.070s / 10iters, (0.006965)\n",
            "Loss_D = 0.93201423 (ave = 0.85515962)\n",
            "Loss_G = 2.38875556 (ave = 3.57817642)\n",
            "\n",
            "epoch: [28/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.674s / 10iters, (0.067)\tData load 0.104s / 10iters, (0.010368)\n",
            "Loss_D = 0.47854614 (ave = 0.84824717)\n",
            "Loss_G = 4.36643648 (ave = 3.57674654)\n",
            "\n",
            "epoch: [28/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.613s / 10iters, (0.061)\tData load 0.070s / 10iters, (0.007042)\n",
            "Loss_D = 0.53434080 (ave = 0.84329665)\n",
            "Loss_G = 3.03009677 (ave = 3.57548266)\n",
            "\n",
            "epoch: [28/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.637s / 10iters, (0.064)\tData load 0.093s / 10iters, (0.009302)\n",
            "Loss_D = 0.40249637 (ave = 0.84393765)\n",
            "Loss_G = 3.01578140 (ave = 3.57307090)\n",
            "\n",
            "epoch: [28/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.737s / 10iters, (0.074)\tData load 0.066s / 10iters, (0.006629)\n",
            "Loss_D = 0.71965307 (ave = 0.84500653)\n",
            "Loss_G = 3.98141193 (ave = 3.57088690)\n",
            "\n",
            "epoch: [28/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.307s / 10iters, (0.031)\tData load 0.054s / 10iters, (0.005430)\n",
            "Loss_D = 1.77893281 (ave = 0.85134884)\n",
            "Loss_G = 2.06144524 (ave = 3.58979167)\n",
            "\n",
            "epoch: [28/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.073s / 3iters, (0.024)\tData load 0.011s / 3iters, (0.003597)\n",
            "Loss_D = 1.37049961 (ave = 0.85291503)\n",
            "Loss_G = 3.67466164 (ave = 3.59181230)\n",
            "\n",
            "Real Accuracy : 79.77490897053956\n",
            "Fake Accuracy : 5.72658060244952\n",
            "epoch: [29/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.045s / 10iters, (0.505)\tData load 4.348s / 10iters, (0.434812)\n",
            "Loss_D = 0.52144271 (ave = 0.90088716)\n",
            "Loss_G = 1.94647551 (ave = 3.73697670)\n",
            "\n",
            "epoch: [29/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.630s / 10iters, (0.063)\tData load 0.085s / 10iters, (0.008487)\n",
            "Loss_D = 0.93357444 (ave = 0.85882959)\n",
            "Loss_G = 2.98528242 (ave = 3.57110049)\n",
            "\n",
            "epoch: [29/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.649s / 10iters, (0.065)\tData load 0.089s / 10iters, (0.008931)\n",
            "Loss_D = 0.77761441 (ave = 0.78430933)\n",
            "Loss_G = 2.61730838 (ave = 3.53078392)\n",
            "\n",
            "epoch: [29/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.657s / 10iters, (0.066)\tData load 0.084s / 10iters, (0.008444)\n",
            "Loss_D = 0.53281415 (ave = 0.85958084)\n",
            "Loss_G = 4.22104073 (ave = 3.62130347)\n",
            "\n",
            "epoch: [29/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.607s / 10iters, (0.061)\tData load 0.064s / 10iters, (0.006433)\n",
            "Loss_D = 0.88319826 (ave = 0.88242677)\n",
            "Loss_G = 3.54809904 (ave = 3.63738145)\n",
            "\n",
            "epoch: [29/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.650s / 10iters, (0.065)\tData load 0.077s / 10iters, (0.007676)\n",
            "Loss_D = 0.32942206 (ave = 0.86129768)\n",
            "Loss_G = 3.36067986 (ave = 3.60556407)\n",
            "\n",
            "epoch: [29/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.618s / 10iters, (0.062)\tData load 0.091s / 10iters, (0.009102)\n",
            "Loss_D = 0.42421415 (ave = 0.86935767)\n",
            "Loss_G = 3.68186927 (ave = 3.60821446)\n",
            "\n",
            "epoch: [29/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.684s / 10iters, (0.068)\tData load 0.091s / 10iters, (0.009055)\n",
            "Loss_D = 0.53557110 (ave = 0.83533921)\n",
            "Loss_G = 3.52851725 (ave = 3.55351454)\n",
            "\n",
            "epoch: [29/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.649s / 10iters, (0.065)\tData load 0.080s / 10iters, (0.007986)\n",
            "Loss_D = 0.70181650 (ave = 0.82184588)\n",
            "Loss_G = 4.07418346 (ave = 3.58907985)\n",
            "\n",
            "epoch: [29/100] iteration: [100/233]\tLearning rate: 0.0002\n",
            "Time 0.739s / 10iters, (0.074)\tData load 0.069s / 10iters, (0.006948)\n",
            "Loss_D = 0.19506426 (ave = 0.83587111)\n",
            "Loss_G = 3.21655869 (ave = 3.55225709)\n",
            "\n",
            "epoch: [29/100] iteration: [110/233]\tLearning rate: 0.0002\n",
            "Time 0.751s / 10iters, (0.075)\tData load 0.113s / 10iters, (0.011265)\n",
            "Loss_D = 0.74846721 (ave = 0.83073132)\n",
            "Loss_G = 4.43402386 (ave = 3.56574297)\n",
            "\n",
            "epoch: [29/100] iteration: [120/233]\tLearning rate: 0.0002\n",
            "Time 0.678s / 10iters, (0.068)\tData load 0.074s / 10iters, (0.007369)\n",
            "Loss_D = 1.62050891 (ave = 0.84106046)\n",
            "Loss_G = 4.75131178 (ave = 3.59532987)\n",
            "\n",
            "epoch: [29/100] iteration: [130/233]\tLearning rate: 0.0002\n",
            "Time 0.626s / 10iters, (0.063)\tData load 0.113s / 10iters, (0.011256)\n",
            "Loss_D = 0.95451713 (ave = 0.84267628)\n",
            "Loss_G = 5.96564054 (ave = 3.63034038)\n",
            "\n",
            "epoch: [29/100] iteration: [140/233]\tLearning rate: 0.0002\n",
            "Time 0.677s / 10iters, (0.068)\tData load 0.104s / 10iters, (0.010427)\n",
            "Loss_D = 0.82053918 (ave = 0.84499408)\n",
            "Loss_G = 4.64567280 (ave = 3.65296800)\n",
            "\n",
            "epoch: [29/100] iteration: [150/233]\tLearning rate: 0.0002\n",
            "Time 0.606s / 10iters, (0.061)\tData load 0.075s / 10iters, (0.007517)\n",
            "Loss_D = 0.59759825 (ave = 0.84557502)\n",
            "Loss_G = 5.12304449 (ave = 3.63544993)\n",
            "\n",
            "epoch: [29/100] iteration: [160/233]\tLearning rate: 0.0002\n",
            "Time 0.611s / 10iters, (0.061)\tData load 0.088s / 10iters, (0.008754)\n",
            "Loss_D = 1.75347316 (ave = 0.84692960)\n",
            "Loss_G = 3.01831341 (ave = 3.65541725)\n",
            "\n",
            "epoch: [29/100] iteration: [170/233]\tLearning rate: 0.0002\n",
            "Time 0.634s / 10iters, (0.063)\tData load 0.091s / 10iters, (0.009056)\n",
            "Loss_D = 0.68299425 (ave = 0.83565388)\n",
            "Loss_G = 3.49990630 (ave = 3.62861135)\n",
            "\n",
            "epoch: [29/100] iteration: [180/233]\tLearning rate: 0.0002\n",
            "Time 0.631s / 10iters, (0.063)\tData load 0.100s / 10iters, (0.009989)\n",
            "Loss_D = 0.91683090 (ave = 0.82348623)\n",
            "Loss_G = 3.80220509 (ave = 3.63252802)\n",
            "\n",
            "epoch: [29/100] iteration: [190/233]\tLearning rate: 0.0002\n",
            "Time 0.625s / 10iters, (0.062)\tData load 0.088s / 10iters, (0.008800)\n",
            "Loss_D = 0.68561292 (ave = 0.83324007)\n",
            "Loss_G = 3.78339243 (ave = 3.66075174)\n",
            "\n",
            "epoch: [29/100] iteration: [200/233]\tLearning rate: 0.0002\n",
            "Time 0.636s / 10iters, (0.064)\tData load 0.076s / 10iters, (0.007636)\n",
            "Loss_D = 0.46850967 (ave = 0.83641637)\n",
            "Loss_G = 2.01105165 (ave = 3.65780268)\n",
            "\n",
            "epoch: [29/100] iteration: [210/233]\tLearning rate: 0.0002\n",
            "Time 0.578s / 10iters, (0.058)\tData load 0.071s / 10iters, (0.007140)\n",
            "Loss_D = 0.71295404 (ave = 0.84240247)\n",
            "Loss_G = 2.86947751 (ave = 3.66228529)\n",
            "\n",
            "epoch: [29/100] iteration: [220/233]\tLearning rate: 0.0002\n",
            "Time 0.667s / 10iters, (0.067)\tData load 0.101s / 10iters, (0.010085)\n",
            "Loss_D = 0.47101146 (ave = 0.83963679)\n",
            "Loss_G = 4.26731539 (ave = 3.65411837)\n",
            "\n",
            "epoch: [29/100] iteration: [230/233]\tLearning rate: 0.0002\n",
            "Time 0.301s / 10iters, (0.030)\tData load 0.063s / 10iters, (0.006252)\n",
            "Loss_D = 1.14257765 (ave = 0.83865290)\n",
            "Loss_G = 3.89251733 (ave = 3.65008151)\n",
            "\n",
            "epoch: [29/100] iteration: [233/233]\tLearning rate: 0.0002\n",
            "Time 0.071s / 3iters, (0.024)\tData load 0.015s / 3iters, (0.004845)\n",
            "Loss_D = 0.34823197 (ave = 0.83302592)\n",
            "Loss_G = 4.79809427 (ave = 3.65390884)\n",
            "\n",
            "Real Accuracy : 80.63555114200595\n",
            "Fake Accuracy : 4.799735187024164\n",
            "epoch: [30/100] iteration: [10/233]\tLearning rate: 0.0002\n",
            "Time 5.169s / 10iters, (0.517)\tData load 4.510s / 10iters, (0.450975)\n",
            "Loss_D = 1.04124403 (ave = 0.64500868)\n",
            "Loss_G = 4.69918299 (ave = 3.52156692)\n",
            "\n",
            "epoch: [30/100] iteration: [20/233]\tLearning rate: 0.0002\n",
            "Time 0.683s / 10iters, (0.068)\tData load 0.097s / 10iters, (0.009705)\n",
            "Loss_D = 0.61537665 (ave = 0.67435460)\n",
            "Loss_G = 4.26402903 (ave = 3.58150189)\n",
            "\n",
            "epoch: [30/100] iteration: [30/233]\tLearning rate: 0.0002\n",
            "Time 0.582s / 10iters, (0.058)\tData load 0.085s / 10iters, (0.008458)\n",
            "Loss_D = 0.66644132 (ave = 0.68801541)\n",
            "Loss_G = 4.24148607 (ave = 3.58982114)\n",
            "\n",
            "epoch: [30/100] iteration: [40/233]\tLearning rate: 0.0002\n",
            "Time 0.665s / 10iters, (0.067)\tData load 0.122s / 10iters, (0.012216)\n",
            "Loss_D = 0.56564391 (ave = 0.73611559)\n",
            "Loss_G = 3.71323061 (ave = 3.62363043)\n",
            "\n",
            "epoch: [30/100] iteration: [50/233]\tLearning rate: 0.0002\n",
            "Time 0.643s / 10iters, (0.064)\tData load 0.085s / 10iters, (0.008475)\n",
            "Loss_D = 0.63605750 (ave = 0.76452664)\n",
            "Loss_G = 3.71798348 (ave = 3.56759465)\n",
            "\n",
            "epoch: [30/100] iteration: [60/233]\tLearning rate: 0.0002\n",
            "Time 0.574s / 10iters, (0.057)\tData load 0.072s / 10iters, (0.007170)\n",
            "Loss_D = 1.03711188 (ave = 0.77610423)\n",
            "Loss_G = 3.86657095 (ave = 3.60268563)\n",
            "\n",
            "epoch: [30/100] iteration: [70/233]\tLearning rate: 0.0002\n",
            "Time 0.765s / 10iters, (0.076)\tData load 0.080s / 10iters, (0.008030)\n",
            "Loss_D = 0.81552756 (ave = 0.78113341)\n",
            "Loss_G = 4.35952187 (ave = 3.60138128)\n",
            "\n",
            "epoch: [30/100] iteration: [80/233]\tLearning rate: 0.0002\n",
            "Time 0.663s / 10iters, (0.066)\tData load 0.090s / 10iters, (0.008999)\n",
            "Loss_D = 0.58373570 (ave = 0.78143519)\n",
            "Loss_G = 2.96040750 (ave = 3.59083540)\n",
            "\n",
            "epoch: [30/100] iteration: [90/233]\tLearning rate: 0.0002\n",
            "Time 0.674s / 10iters, (0.067)\tData load 0.069s / 10iters, (0.006913)\n",
            "Loss_D = 0.56178892 (ave = 0.77273344)\n",
            "Loss_G = 3.52269578 (ave = 3.60478353)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NNhwNi5BSr0",
        "outputId": "8c041122-42d3-4249-87ca-09476b01e3e7"
      },
      "source": [
        "#load the saved models here\r\n",
        "def generate_images(batch_size):\r\n",
        "  #fake_num = math.ceil(batch_size/class_num)\r\n",
        "  conditional_z, z_label = conditional_latent_generator(distribution, 2, batch_size)\r\n",
        "\r\n",
        "  noise = conditional_z.view(-1, z_dim, 1, 1)\r\n",
        "  print(noise.shape)\r\n",
        "  if use_cuda:\r\n",
        "    noise = noise.cuda(gpu)\r\n",
        "\r\n",
        "  fake = G(noise)\r\n",
        "  print(fake.shape)\r\n",
        "\r\n",
        "  for i, label in enumerate(z_label):\r\n",
        "    cv = output_images_dir+\"/covid\"\r\n",
        "    ncv=output_images_dir+\"/noncovid\"\r\n",
        "\r\n",
        "    os.makedirs(cv, exist_ok = True)\r\n",
        "    os.makedirs(ncv, exist_ok = True)\r\n",
        "\r\n",
        "    if label == 0:\r\n",
        "      vutils.save_image(fake[i].detach(), ncv+'/fake_samples_{:03d}.png'.format(i),normalize=True, nrow=5)\r\n",
        "    else:\r\n",
        "      vutils.save_image(fake[i].detach(), cv+'/fake_samples_{:03d}.png'.format(i),normalize=True, nrow=5)\r\n",
        "\r\n",
        "\r\n",
        "generate_images(2000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2000, 100, 1, 1])\n",
            "torch.Size([2000, 3, 64, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ5RSip1LMOP",
        "outputId": "00a3e63e-1e4f-4a26-ed9b-3a9adaadf1f0"
      },
      "source": [
        "# G = torch.load(checkpoint_dir+\"/gan/G_epoch_19.pth\")\r\n",
        "# generate_images(50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 100, 1, 1])\n",
            "torch.Size([32, 3, 64, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTWp89VcJe24"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z2UMjnXI8jL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXo26KV2I6fj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VytkymqOIzO6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}