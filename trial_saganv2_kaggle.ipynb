{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "trial_saganv2_kaggle.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abbyambita/Diagnosing-COVID-from-CT-Scan-Images/blob/main/trial_saganv2_kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axVHKs9vwqad"
      },
      "source": [
        "https://github.com/rosinality/sagan-pytorch/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrbY_X-nvYFM",
        "outputId": "66b90c73-fe52-425c-b840-946dca2da94b"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncGTysumvhSl",
        "outputId": "28878aee-f87e-4369-eb32-9b7a80597974"
      },
      "source": [
        "import os \r\n",
        "\r\n",
        "os.chdir(\"/content/gdrive/My Drive\")\r\n",
        "\r\n",
        "!ls  '/content/gdrive/My Drive/CS 284 Mini-Project/Code/'\r\n",
        "\r\n",
        "%cd \"/content/gdrive/My Drive/CS 284 Mini-Project/Code/\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ACGAN.ipynb\t\t       models\n",
            " acgan_output_images\t       new_sars_cov\n",
            " BAGAN.ipynb\t\t       output_result\n",
            " bagan_output_images\t       plots\n",
            " build_datasets.ipynb\t       revised-git\n",
            " build_datasets_v2.ipynb       revised-kaggle-validation\n",
            " build_datasets_v3.ipynb       runs\n",
            " COVID-CT-master\t       sagan_output_images\n",
            " DCGAN.ipynb\t\t      'synthetic images'\n",
            " ECN_git.ipynb\t\t       training-from-scratch-git.ipynb\n",
            " ECN_git_with_acgan.ipynb      transfer_learning_models_git.ipynb\n",
            " ECN_git_with_bagan.ipynb      transfer_learning_models_kaggle.ipynb\n",
            " ECN_kaggle.ipynb\t       transfer_learning_with_acgan_git.ipynb\n",
            " ECN_kaggle_with_acgan.ipynb   transfer_learning_with_acgan_kaggle.ipynb\n",
            " ECN_kaggle_with_bagan.ipynb   transfer_learning_with_bagan_git.ipynb\n",
            " EN_git.ipynb\t\t       transfer_learning_with_bagan_kaggle.ipynb\n",
            " EN_git_with_acgan.ipynb       trial_acgan_git.ipynb\n",
            " EN_git_with_bagan.ipynb       trial_acgan_kaggle.ipynb\n",
            " EN_kaggle.ipynb\t       trial_bagan_git.ipynb\n",
            " EN_kaggle_with_acgan.ipynb    trial_bagan_kaggle.ipynb\n",
            " EN_kaggle_with_bagan.ipynb    trial_GAN.ipynb\n",
            " generator_epoch_2.pth\t       trial.ipynb\n",
            " images.zip\t\t       trial_sagan_git.ipynb\n",
            " Inception_github.ipynb        trial_saganv2_git.ipynb\n",
            " master.ipynb\t\t       trial_saganv2_kaggle.ipynb\n",
            " model_backup\t\t       tsne_acgan_git.ipynb\n",
            " model_result\t\t       tsne_acgan_kaggle.ipynb\n",
            "/content/gdrive/.shortcut-targets-by-id/1eVFVz23F6ROX0s10Oe3tT9HVzr502iW2/CS 284 Mini-Project/Code\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu35A4u7wEDx"
      },
      "source": [
        "from __future__ import print_function\r\n",
        "#%matplotlib inline\r\n",
        "import argparse\r\n",
        "import os\r\n",
        "import PIL\r\n",
        "import glob\r\n",
        "import xml.etree.ElementTree as ET\r\n",
        "import random\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.parallel\r\n",
        "import torch.backends.cudnn as cudnn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.utils.data\r\n",
        "import torchvision.datasets as dset\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torchvision.utils as vutils\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.animation as animation\r\n",
        "import seaborn as sns\r\n",
        "from IPython.display import HTML\r\n",
        "from torchvision.utils import save_image\r\n",
        "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\r\n",
        "from tqdm import tqdm_notebook as tqdm\r\n",
        "from IPython.display import clear_output\r\n",
        "from scipy.stats import truncnorm\r\n",
        "%matplotlib inline\r\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\r\n",
        "\r\n",
        "import torch\r\n",
        "\r\n",
        "from torch import nn\r\n",
        "from torch.nn import init\r\n",
        "from torch.nn import functional as F\r\n",
        "\r\n",
        "import functools\r\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF2S8MPFYpIA"
      },
      "source": [
        "def init_linear(linear):\r\n",
        "    init.xavier_uniform_(linear.weight)\r\n",
        "    linear.bias.data.zero_()\r\n",
        "\r\n",
        "\r\n",
        "def init_conv(conv, glu=True):\r\n",
        "    init.xavier_uniform_(conv.weight)\r\n",
        "    if conv.bias is not None:\r\n",
        "        conv.bias.data.zero_()\r\n",
        "\r\n",
        "\r\n",
        "class SpectralNorm:\r\n",
        "    def __init__(self, name):\r\n",
        "        self.name = name\r\n",
        "\r\n",
        "    def compute_weight(self, module):\r\n",
        "        weight = getattr(module, self.name + '_orig')\r\n",
        "        u = getattr(module, self.name + '_u')\r\n",
        "        size = weight.size()\r\n",
        "        weight_mat = weight.contiguous().view(size[0], -1)\r\n",
        "        with torch.no_grad():\r\n",
        "            v = weight_mat.t() @ u\r\n",
        "            v = v / v.norm()\r\n",
        "            u = weight_mat @ v\r\n",
        "            u = u / u.norm()\r\n",
        "        sigma = u @ weight_mat @ v\r\n",
        "        weight_sn = weight / sigma\r\n",
        "        # weight_sn = weight_sn.view(*size)\r\n",
        "\r\n",
        "        return weight_sn, u\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def apply(module, name):\r\n",
        "        fn = SpectralNorm(name)\r\n",
        "\r\n",
        "        weight = getattr(module, name)\r\n",
        "        del module._parameters[name]\r\n",
        "        module.register_parameter(name + '_orig', weight)\r\n",
        "        input_size = weight.size(0)\r\n",
        "        u = weight.new_empty(input_size).normal_()\r\n",
        "        module.register_buffer(name, weight)\r\n",
        "        module.register_buffer(name + '_u', u)\r\n",
        "\r\n",
        "        module.register_forward_pre_hook(fn)\r\n",
        "\r\n",
        "        return fn\r\n",
        "\r\n",
        "    def __call__(self, module, input):\r\n",
        "        weight_sn, u = self.compute_weight(module)\r\n",
        "        setattr(module, self.name, weight_sn)\r\n",
        "        setattr(module, self.name + '_u', u)\r\n",
        "\r\n",
        "\r\n",
        "def spectral_norm(module, name='weight'):\r\n",
        "    SpectralNorm.apply(module, name)\r\n",
        "\r\n",
        "    return module\r\n",
        "\r\n",
        "\r\n",
        "def spectral_init(module, gain=1):\r\n",
        "    init.kaiming_uniform_(module.weight, gain)\r\n",
        "    if module.bias is not None:\r\n",
        "        module.bias.data.zero_()\r\n",
        "\r\n",
        "    return spectral_norm(module)\r\n",
        "\r\n",
        "\r\n",
        "def leaky_relu(input):\r\n",
        "    return F.leaky_relu(input, negative_slope=0.2)\r\n",
        "\r\n",
        "\r\n",
        "class SelfAttention(nn.Module):\r\n",
        "    def __init__(self, in_channel, gain=1):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.query = spectral_init(nn.Conv1d(in_channel, in_channel // 8, 1),\r\n",
        "                                   gain=gain)\r\n",
        "        self.key = spectral_init(nn.Conv1d(in_channel, in_channel // 8, 1),\r\n",
        "                                 gain=gain)\r\n",
        "        self.value = spectral_init(nn.Conv1d(in_channel, in_channel, 1),\r\n",
        "                                   gain=gain)\r\n",
        "\r\n",
        "        self.gamma = nn.Parameter(torch.tensor(0.0))\r\n",
        "\r\n",
        "    def forward(self, input):\r\n",
        "        shape = input.shape\r\n",
        "        flatten = input.view(shape[0], shape[1], -1)\r\n",
        "        query = self.query(flatten).permute(0, 2, 1)\r\n",
        "        key = self.key(flatten)\r\n",
        "        value = self.value(flatten)\r\n",
        "        query_key = torch.bmm(query, key)\r\n",
        "        attn = F.softmax(query_key, 1)\r\n",
        "        attn = torch.bmm(value, attn)\r\n",
        "        attn = attn.view(*shape)\r\n",
        "        out = self.gamma * attn + input\r\n",
        "\r\n",
        "        return out\r\n",
        "\r\n",
        "\r\n",
        "class ConditionalNorm(nn.Module):\r\n",
        "    def __init__(self, in_channel, n_class):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.bn = nn.BatchNorm2d(in_channel, affine=False)\r\n",
        "        self.embed = nn.Embedding(n_class, in_channel * 2)\r\n",
        "        self.embed.weight.data[:, :in_channel] = 1\r\n",
        "        self.embed.weight.data[:, in_channel:] = 0\r\n",
        "\r\n",
        "    def forward(self, input, class_id):\r\n",
        "        out = self.bn(input)\r\n",
        "        embed = self.embed(class_id)\r\n",
        "        gamma, beta = embed.chunk(2, 1)\r\n",
        "        gamma = gamma.unsqueeze(2).unsqueeze(3)\r\n",
        "        beta = beta.unsqueeze(2).unsqueeze(3)\r\n",
        "        out = gamma * out + beta\r\n",
        "\r\n",
        "        return out\r\n",
        "\r\n",
        "\r\n",
        "class ConvBlock(nn.Module):\r\n",
        "    def __init__(self, in_channel, out_channel, kernel_size=[3, 3],\r\n",
        "                 padding=1, stride=1, n_class=None, bn=True,\r\n",
        "                 activation=F.relu, upsample=True, self_attention=False):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.conv = spectral_init(nn.Conv2d(in_channel, out_channel,\r\n",
        "                                            kernel_size, stride, padding,\r\n",
        "                                            bias=False if bn else True))\r\n",
        "\r\n",
        "        self.upsample = upsample\r\n",
        "        self.activation = activation\r\n",
        "        self.bn = bn\r\n",
        "        if bn:\r\n",
        "            self.norm = ConditionalNorm(out_channel, n_class)\r\n",
        "\r\n",
        "        self.self_attention = self_attention\r\n",
        "        if self_attention:\r\n",
        "            self.attention = SelfAttention(out_channel, 1)\r\n",
        "\r\n",
        "    def forward(self, input, class_id=None):\r\n",
        "        out = input\r\n",
        "        if self.upsample:\r\n",
        "            out = F.upsample(out, scale_factor=2)\r\n",
        "\r\n",
        "        out = self.conv(out)\r\n",
        "\r\n",
        "        if self.bn:\r\n",
        "            out = self.norm(out, class_id)\r\n",
        "\r\n",
        "        if self.activation is not None:\r\n",
        "            out = self.activation(out)\r\n",
        "\r\n",
        "        if self.self_attention:\r\n",
        "            out = self.attention(out)\r\n",
        "\r\n",
        "        return out\r\n",
        "\r\n",
        "\r\n",
        "class Generator(nn.Module):\r\n",
        "    def __init__(self, code_dim=100, n_class=2):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.lin_code = spectral_init(nn.Linear(code_dim, 4 * 4 * 512))\r\n",
        "        self.conv = nn.ModuleList([ConvBlock(512, 512, n_class=n_class),\r\n",
        "                                   ConvBlock(512, 512, n_class=n_class),\r\n",
        "                                   ConvBlock(512, 512, n_class=n_class,\r\n",
        "                                             self_attention=True),\r\n",
        "                                   ConvBlock(512, 256, n_class=n_class),\r\n",
        "                                   ConvBlock(256, 128, n_class=n_class)])\r\n",
        "\r\n",
        "        self.colorize = spectral_init(nn.Conv2d(128, 3, [3, 3], padding=1))\r\n",
        "\r\n",
        "    def forward(self, input, class_id):\r\n",
        "        out = self.lin_code(input)\r\n",
        "        out = F.relu(out)\r\n",
        "        out = out.view(-1, 512, 4, 4)\r\n",
        "\r\n",
        "        for conv in self.conv:\r\n",
        "            out = conv(out, class_id)\r\n",
        "\r\n",
        "        out = self.colorize(out)\r\n",
        "\r\n",
        "        return F.tanh(out)\r\n",
        "\r\n",
        "\r\n",
        "class Discriminator(nn.Module):\r\n",
        "    def __init__(self, n_class=2):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        def conv(in_channel, out_channel, stride=2,\r\n",
        "                 self_attention=False):\r\n",
        "            return ConvBlock(in_channel, out_channel, stride=stride,\r\n",
        "                             bn=False, activation=leaky_relu,\r\n",
        "                             upsample=False, self_attention=self_attention)\r\n",
        "\r\n",
        "        self.conv = nn.Sequential(conv(3, 128),\r\n",
        "                                  conv(128, 256),\r\n",
        "                                  conv(256, 512, stride=1,\r\n",
        "                                       self_attention=True),\r\n",
        "                                  conv(512, 512),\r\n",
        "                                  conv(512, 512),\r\n",
        "                                  conv(512, 512))\r\n",
        "\r\n",
        "        self.linear = spectral_init(nn.Linear(512, 1))\r\n",
        "\r\n",
        "        self.embed = nn.Embedding(n_class, 512)\r\n",
        "        self.embed.weight.data.uniform_(-0.1, 0.1)\r\n",
        "        self.embed = spectral_norm(self.embed)\r\n",
        "\r\n",
        "    def forward(self, input, class_id):\r\n",
        "        out = self.conv(input)\r\n",
        "        out = out.view(out.size(0), out.size(1), -1)\r\n",
        "        out = out.sum(2)\r\n",
        "        out_linear = self.linear(out).squeeze(1)\r\n",
        "        embed = self.embed(class_id)\r\n",
        "        prod = (out * embed).sum(1)\r\n",
        "\r\n",
        "        return out_linear + prod"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK7E49C8bGYB"
      },
      "source": [
        "from tqdm import tqdm\r\n",
        "import numpy as np\r\n",
        "import glob\r\n",
        "import os\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "import argparse\r\n",
        "\r\n",
        "import torch\r\n",
        "from torch import nn, optim\r\n",
        "from torch.nn import functional as F\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from torchvision import datasets, transforms, utils"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FZ6-P4zh2Ax"
      },
      "source": [
        "batch=64\r\n",
        "steps = 100\r\n",
        "code=128\r\n",
        "lr_g=1e-4\r\n",
        "lr_d=4e-4\r\n",
        "n_d=1\r\n",
        "model='dcgan'\r\n",
        "path='revised-kaggle-validation/train'\r\n",
        "n_class = 2\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "\r\n",
        "transform = transforms.Compose(\r\n",
        "    [\r\n",
        "        transforms.Resize(128),\r\n",
        "        transforms.CenterCrop(128),\r\n",
        "        transforms.RandomHorizontalFlip(),\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\r\n",
        "    ]\r\n",
        ")\r\n",
        "\r\n",
        "def requires_grad(model, flag=True):\r\n",
        "    for p in model.parameters():\r\n",
        "        p.requires_grad = flag\r\n",
        "\r\n",
        "\r\n",
        "def sample_data(path, batch_size):\r\n",
        "    \r\n",
        "    #dataroot = \"revised-git/train\"\r\n",
        "\r\n",
        "    dataset = datasets.ImageFolder(path, transform=transform)\r\n",
        "    loader = DataLoader(dataset, shuffle=True, batch_size=batch_size, num_workers=4)\r\n",
        "    \r\n",
        "    return loader\r\n",
        "    #loader = iter(loader)\r\n",
        "\r\n",
        "    # while True:\r\n",
        "    #     try:\r\n",
        "    #         yield next(loader)\r\n",
        "\r\n",
        "    #     except StopIteration:\r\n",
        "    #         loader = DataLoader(\r\n",
        "    #             dataset, shuffle=True, batch_size=batch_size, num_workers=4\r\n",
        "    #         )\r\n",
        "    #         loader = iter(loader)\r\n",
        "    #         yield next(loader)\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M2S0mWGrpLp"
      },
      "source": [
        "num_epochs = 3500\r\n",
        "\r\n",
        "dir = \"output_result/sagan/kaggle/batch_size=64,epoch=\"+str(num_epochs)\r\n",
        "os.makedirs(dir, exist_ok=True)\r\n",
        "\r\n",
        "\r\n",
        "def cuda(data):\r\n",
        "    if torch.cuda.is_available():\r\n",
        "        return data.cuda()\r\n",
        "    else:\r\n",
        "        return data\r\n",
        "\r\n",
        "fixed_z = cuda(torch.randn(64, 100))\r\n",
        "\r\n",
        "def denorm(x):\r\n",
        "    out = (x + 1) / 2\r\n",
        "    return out.clamp_(0, 1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTDalXrrkw8u"
      },
      "source": [
        "def generate_images(epoch, batch_size):\r\n",
        "  input_class = torch.arange(n_class).long().repeat(batch_size).to(device)\r\n",
        "  print(len(input_class))\r\n",
        "\r\n",
        "  preset_code = torch.randn(n_class * batch_size, code).to(device)\r\n",
        "  print(len(preset_code))\r\n",
        "  \r\n",
        "  fake_image = generator(preset_code, input_class)\r\n",
        "  print(len(fake_image))\r\n",
        "\r\n",
        "  ncv = \"sagan_output_images/kaggle/batch_size=64,epoch=\"+str(epoch+1)+\"/noncovid\"\r\n",
        "  cv = \"sagan_output_images/kaggle/batch_size=64,epoch=\"+str(epoch+1)+\"/covid\"\r\n",
        "\r\n",
        "  os.makedirs(ncv, exist_ok=True)\r\n",
        "  os.makedirs(cv, exist_ok=True)\r\n",
        "\r\n",
        "  for i, img in enumerate(fake_image):\r\n",
        "    if(input_class[i]==0):\r\n",
        "      utils.save_image(\r\n",
        "                img.cpu().data,\r\n",
        "                #f'sample/{str(i + 1).zfill(7)}.png',\r\n",
        "                ncv+'/fake_img_'+str(i)+'.png'\r\n",
        "            )\r\n",
        "    else:\r\n",
        "      utils.save_image(\r\n",
        "                img.cpu().data,\r\n",
        "                #f'sample/{str(i + 1).zfill(7)}.png',\r\n",
        "                cv+'/fake_img_'+str(i)+'.png'\r\n",
        "             )\r\n",
        "\r\n",
        "#generate_images(2000)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myy-aGGbiqDc"
      },
      "source": [
        "def train(n_class, generator, discriminator):\r\n",
        "    dataset = sample_data(path,batch)\r\n",
        "    #pbar = tqdm(range(iter), dynamic_ncols=True)\r\n",
        "\r\n",
        "    requires_grad(generator, False)\r\n",
        "    requires_grad(discriminator, True)\r\n",
        "\r\n",
        "    preset_code = torch.randn(n_class * 5, code).to(device)\r\n",
        "\r\n",
        "    disc_loss_val = 0\r\n",
        "    gen_loss_val = 0\r\n",
        "\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "      for i, data in enumerate(dataset):\r\n",
        "        discriminator.zero_grad()\r\n",
        "        #real_image, label = next(dataset)\r\n",
        "        real_image = data[0]\r\n",
        "        label = data[1]\r\n",
        "        real_image = real_image.to(device)\r\n",
        "        label = label.to(device)\r\n",
        "\r\n",
        "        b_size = real_image.size(0)\r\n",
        "        \r\n",
        "\r\n",
        "        fake_image = generator(\r\n",
        "            torch.randn(b_size, code).to(device), label.to(device)\r\n",
        "        )\r\n",
        "        \r\n",
        "        fake_predict = discriminator(fake_image, label)\r\n",
        "        real_predict = discriminator(real_image, label)\r\n",
        "        loss = F.relu(1 + fake_predict).mean()\r\n",
        "\r\n",
        "        loss = loss + F.relu(1 - real_predict).mean()\r\n",
        "        disc_loss_val = loss.detach().item()\r\n",
        "        loss.backward()\r\n",
        "        d_optimizer.step()\r\n",
        "\r\n",
        "        generator.zero_grad()\r\n",
        "        requires_grad(generator, True)\r\n",
        "        requires_grad(discriminator, False)\r\n",
        "        input_class = torch.multinomial(\r\n",
        "            torch.ones(n_class), batch, replacement=True\r\n",
        "        ).to(device)\r\n",
        "        fake_image = generator(\r\n",
        "            torch.randn(batch, code).to(device), input_class\r\n",
        "        )\r\n",
        "        predict = discriminator(fake_image, input_class)\r\n",
        "        loss = -predict.mean()\r\n",
        "        gen_loss_val = loss.detach().item()\r\n",
        "        loss.backward()\r\n",
        "        g_optimizer.step()\r\n",
        "        requires_grad(generator, False)\r\n",
        "        requires_grad(discriminator, True)\r\n",
        "\r\n",
        "        # if (epoch + 1) % 2 == 0:\r\n",
        "        #     generator.train(False)\r\n",
        "        #     input_class = torch.arange(n_class).long().repeat(5).to(device)\r\n",
        "        #     fake_image = generator(preset_code, input_class)\r\n",
        "        #     generator.train(True)\r\n",
        "        #     utils.save_image(\r\n",
        "        #         fake_image.cpu().data,\r\n",
        "        #         #f'sample/{str(i + 1).zfill(7)}.png',\r\n",
        "        #         f'output_result/sagan/batch_size=64,epoch=1000/{str(i + 1).zfill(7)}.png',\r\n",
        "        #         nrow=n_class,\r\n",
        "        #         normalize=True,\r\n",
        "        #         range=(-1, 1),\r\n",
        "        #     )\r\n",
        "\r\n",
        "        print(\"Epoch \"+str(epoch)+\"Dis \"+str(disc_loss_val))\r\n",
        "\r\n",
        "        if (epoch + 1) % (50) == 0:\r\n",
        "            input_class = torch.arange(n_class).long().repeat(5).to(device)\r\n",
        "            fake_image = generator(preset_code, input_class)\r\n",
        "            utils.save_image(\r\n",
        "                fake_image.cpu().data,\r\n",
        "                #f'sample/{str(i + 1).zfill(7)}.png',\r\n",
        "                f'output_result/sagan/kaggle/batch_size=64,epoch=3500/{str(epoch + 1).zfill(7)}.png',\r\n",
        "                nrow=n_class,\r\n",
        "                normalize=True,\r\n",
        "                range=(-1, 1),\r\n",
        "            )\r\n",
        "        \r\n",
        "        if (epoch + 1) % (100) == 0:\r\n",
        "            torch.save(generator, dir+\"/generator_epoch_\"+str(epoch)+\".pth\")\r\n",
        "            torch.save(discriminator, dir+\"/discriminator_epoch_\"+str(epoch)+\".pth\")\r\n",
        "\r\n",
        "        if (epoch + 1) % (500) == 0:\r\n",
        "            generate_images(epoch, 2000)\r\n",
        "        \r\n",
        "\r\n",
        "        # if (i + 1) % 10000 == 0:\r\n",
        "        #     no = str(i + 1).zfill(7)\r\n",
        "        #     torch.save(generator.state_dict(), f'checkpoint/generator_{no}.pt')\r\n",
        "        #     torch.save(discriminator.state_dict(), f'checkpoint/discriminator_{no}.pt')\r\n",
        "        #     torch.save(g_optimizer.state_dict(), f'checkpoint/gen_optimizer_{no}.pt')\r\n",
        "        #     torch.save(d_optimizer.state_dict(), f'checkpoint/dis_optimizer_{no}.pt')\r\n",
        "\r\n",
        "        # pbar.set_description(\r\n",
        "        #     (f'{i + 1}; G: {gen_loss_val:.5f};' f' D: {disc_loss_val:.5f}')\r\n",
        "        # )"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u34b-RV-iskV",
        "outputId": "245f1265-d945-4959-d1f6-4d83f4c4b32e"
      },
      "source": [
        "if __name__ == '__main__':\r\n",
        "\r\n",
        "    n_class = len(glob.glob(os.path.join(path, '*/')))\r\n",
        "    print(n_class)\r\n",
        "\r\n",
        "    # if model == 'dcgan':\r\n",
        "    #     from model import Generator, Discriminator\r\n",
        "\r\n",
        "    # elif model == 'resnet':\r\n",
        "    #     from model_resnet import Generator, Discriminator\r\n",
        "\r\n",
        "    generator = Generator(code, n_class).to(device)\r\n",
        "    discriminator = Discriminator(n_class).to(device)\r\n",
        "\r\n",
        "    g_optimizer = optim.Adam(generator.parameters(), lr=lr_g, betas=(0, 0.9))\r\n",
        "    d_optimizer = optim.Adam(discriminator.parameters(), lr=lr_d, betas=(0, 0.9))\r\n",
        "    train(n_class, generator, discriminator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0Dis 2.1207282543182373\n",
            "Epoch 0Dis 1.1945257186889648\n",
            "Epoch 0Dis 21.378101348876953\n",
            "Epoch 0Dis 1.992255449295044\n",
            "Epoch 0Dis 1.9415959119796753\n",
            "Epoch 0Dis 1.8857680559158325\n",
            "Epoch 0Dis 1.8023732900619507\n",
            "Epoch 0Dis 1.6474653482437134\n",
            "Epoch 0Dis 1.314348816871643\n",
            "Epoch 0Dis 1.2640995979309082\n",
            "Epoch 0Dis 5.995900630950928\n",
            "Epoch 0Dis 1.952614188194275\n",
            "Epoch 0Dis 1.9239976406097412\n",
            "Epoch 0Dis 1.8831889629364014\n",
            "Epoch 0Dis 1.8158683776855469\n",
            "Epoch 0Dis 1.7120161056518555\n",
            "Epoch 0Dis 1.5610880851745605\n",
            "Epoch 0Dis 1.39585542678833\n",
            "Epoch 0Dis 1.73940110206604\n",
            "Epoch 0Dis 1.762914776802063\n",
            "Epoch 0Dis 1.28487229347229\n",
            "Epoch 0Dis 2.1417295932769775\n",
            "Epoch 0Dis 2.492520809173584\n",
            "Epoch 0Dis 1.9485276937484741\n",
            "Epoch 0Dis 1.9172455072402954\n",
            "Epoch 0Dis 1.9079504013061523\n",
            "Epoch 0Dis 1.8971387147903442\n",
            "Epoch 0Dis 1.8267104625701904\n",
            "Epoch 1Dis 1.9368767738342285\n",
            "Epoch 1Dis 1.880864143371582\n",
            "Epoch 1Dis 1.8238544464111328\n",
            "Epoch 1Dis 1.4410576820373535\n",
            "Epoch 1Dis 4.417212009429932\n",
            "Epoch 1Dis 4.204819202423096\n",
            "Epoch 1Dis 2.0057239532470703\n",
            "Epoch 1Dis 1.9819610118865967\n",
            "Epoch 1Dis 1.9504408836364746\n",
            "Epoch 1Dis 1.9126038551330566\n",
            "Epoch 1Dis 1.8807727098464966\n",
            "Epoch 1Dis 1.8471084833145142\n",
            "Epoch 1Dis 1.8235111236572266\n",
            "Epoch 1Dis 1.7836289405822754\n",
            "Epoch 1Dis 1.9257011413574219\n",
            "Epoch 1Dis 1.896815538406372\n",
            "Epoch 1Dis 1.9365581274032593\n",
            "Epoch 1Dis 1.8798507452011108\n",
            "Epoch 1Dis 1.7486156225204468\n",
            "Epoch 1Dis 1.0543875694274902\n",
            "Epoch 1Dis 4.375184059143066\n",
            "Epoch 1Dis 1.9341249465942383\n",
            "Epoch 1Dis 1.8469722270965576\n",
            "Epoch 1Dis 1.8991838693618774\n",
            "Epoch 1Dis 1.9701566696166992\n",
            "Epoch 1Dis 1.952684998512268\n",
            "Epoch 1Dis 1.929226279258728\n",
            "Epoch 1Dis 1.885174036026001\n",
            "Epoch 2Dis 1.8442474603652954\n",
            "Epoch 2Dis 1.878996729850769\n",
            "Epoch 2Dis 1.9236129522323608\n",
            "Epoch 2Dis 1.8639675378799438\n",
            "Epoch 2Dis 1.7788487672805786\n",
            "Epoch 2Dis 1.4494237899780273\n",
            "Epoch 2Dis 1.8594573736190796\n",
            "Epoch 2Dis 11.138431549072266\n",
            "Epoch 2Dis 1.9412152767181396\n",
            "Epoch 2Dis 1.9212913513183594\n",
            "Epoch 2Dis 1.8847973346710205\n",
            "Epoch 2Dis 1.8316305875778198\n",
            "Epoch 2Dis 1.833292007446289\n",
            "Epoch 2Dis 1.7922992706298828\n",
            "Epoch 2Dis 1.823750615119934\n",
            "Epoch 2Dis 1.7941913604736328\n",
            "Epoch 2Dis 1.8025426864624023\n",
            "Epoch 2Dis 1.79606032371521\n",
            "Epoch 2Dis 1.7630525827407837\n",
            "Epoch 2Dis 1.7006163597106934\n",
            "Epoch 2Dis 1.6667516231536865\n",
            "Epoch 2Dis 1.658948302268982\n",
            "Epoch 2Dis 2.0511114597320557\n",
            "Epoch 2Dis 1.8651713132858276\n",
            "Epoch 2Dis 1.7388596534729004\n",
            "Epoch 2Dis 1.6010591983795166\n",
            "Epoch 2Dis 1.5571987628936768\n",
            "Epoch 2Dis 1.4910125732421875\n",
            "Epoch 3Dis 1.5038331747055054\n",
            "Epoch 3Dis 3.426992416381836\n",
            "Epoch 3Dis 1.9439499378204346\n",
            "Epoch 3Dis 1.8593839406967163\n",
            "Epoch 3Dis 1.8167080879211426\n",
            "Epoch 3Dis 1.9199981689453125\n",
            "Epoch 3Dis 1.7108476161956787\n",
            "Epoch 3Dis 1.53473961353302\n",
            "Epoch 3Dis 1.6959871053695679\n",
            "Epoch 3Dis 1.5384947061538696\n",
            "Epoch 3Dis 1.547355055809021\n",
            "Epoch 3Dis 1.9326286315917969\n",
            "Epoch 3Dis 1.9432032108306885\n",
            "Epoch 3Dis 1.979640245437622\n",
            "Epoch 3Dis 1.7976453304290771\n",
            "Epoch 3Dis 1.584355115890503\n",
            "Epoch 3Dis 1.5915021896362305\n",
            "Epoch 3Dis 1.2902343273162842\n",
            "Epoch 3Dis 5.179819107055664\n",
            "Epoch 3Dis 1.867704153060913\n",
            "Epoch 3Dis 1.8498499393463135\n",
            "Epoch 3Dis 1.7812175750732422\n",
            "Epoch 3Dis 1.7102985382080078\n",
            "Epoch 3Dis 1.5186787843704224\n",
            "Epoch 3Dis 1.4128074645996094\n",
            "Epoch 3Dis 2.0661795139312744\n",
            "Epoch 3Dis 1.9170997142791748\n",
            "Epoch 3Dis 1.830138921737671\n",
            "Epoch 4Dis 1.615833044052124\n",
            "Epoch 4Dis 1.6651614904403687\n",
            "Epoch 4Dis 1.9943495988845825\n",
            "Epoch 4Dis 1.874704122543335\n",
            "Epoch 4Dis 1.8481935262680054\n",
            "Epoch 4Dis 1.6191939115524292\n",
            "Epoch 4Dis 1.6969972848892212\n",
            "Epoch 4Dis 1.4618840217590332\n",
            "Epoch 4Dis 1.8528320789337158\n",
            "Epoch 4Dis 1.8229362964630127\n",
            "Epoch 4Dis 1.802709698677063\n",
            "Epoch 4Dis 1.764358639717102\n",
            "Epoch 4Dis 1.7710455656051636\n",
            "Epoch 4Dis 1.9958748817443848\n",
            "Epoch 4Dis 1.8682703971862793\n",
            "Epoch 4Dis 1.7789099216461182\n",
            "Epoch 4Dis 1.7570652961730957\n",
            "Epoch 4Dis 2.4865782260894775\n",
            "Epoch 4Dis 1.8724961280822754\n",
            "Epoch 4Dis 1.838328242301941\n",
            "Epoch 4Dis 1.6308238506317139\n",
            "Epoch 4Dis 1.5540313720703125\n",
            "Epoch 4Dis 1.3578819036483765\n",
            "Epoch 4Dis 2.9532558917999268\n",
            "Epoch 4Dis 1.6160253286361694\n",
            "Epoch 4Dis 1.436764121055603\n",
            "Epoch 4Dis 1.403346300125122\n",
            "Epoch 4Dis 1.4918192625045776\n",
            "Epoch 5Dis 1.4824392795562744\n",
            "Epoch 5Dis 0.5796172022819519\n",
            "Epoch 5Dis 1.1682597398757935\n",
            "Epoch 5Dis 2.7942185401916504\n",
            "Epoch 5Dis 1.9564406871795654\n",
            "Epoch 5Dis 1.488656759262085\n",
            "Epoch 5Dis 1.1907243728637695\n",
            "Epoch 5Dis 1.1524841785430908\n",
            "Epoch 5Dis 0.650729238986969\n",
            "Epoch 5Dis 2.644909143447876\n",
            "Epoch 5Dis 1.4308321475982666\n",
            "Epoch 5Dis 1.7588289976119995\n",
            "Epoch 5Dis 1.332599401473999\n",
            "Epoch 5Dis 1.2746813297271729\n",
            "Epoch 5Dis 1.324629545211792\n",
            "Epoch 5Dis 1.799804449081421\n",
            "Epoch 5Dis 1.4341644048690796\n",
            "Epoch 5Dis 1.4840115308761597\n",
            "Epoch 5Dis 0.7703097462654114\n",
            "Epoch 5Dis 0.25924795866012573\n",
            "Epoch 5Dis 1.4113224744796753\n",
            "Epoch 5Dis 3.951754093170166\n",
            "Epoch 5Dis 1.3243231773376465\n",
            "Epoch 5Dis 1.0400032997131348\n",
            "Epoch 5Dis 0.7375502586364746\n",
            "Epoch 5Dis 0.8463937640190125\n",
            "Epoch 5Dis 3.493539810180664\n",
            "Epoch 5Dis 1.4021962881088257\n",
            "Epoch 6Dis 1.0663771629333496\n",
            "Epoch 6Dis 1.07597815990448\n",
            "Epoch 6Dis 0.5855112075805664\n",
            "Epoch 6Dis 1.9499850273132324\n",
            "Epoch 6Dis 0.44096142053604126\n",
            "Epoch 6Dis 1.4974955320358276\n",
            "Epoch 6Dis 1.4397999048233032\n",
            "Epoch 6Dis 1.66987943649292\n",
            "Epoch 6Dis 0.726521909236908\n",
            "Epoch 6Dis 0.2995475232601166\n",
            "Epoch 6Dis 0.3768424391746521\n",
            "Epoch 6Dis 1.95263671875\n",
            "Epoch 6Dis 2.0461723804473877\n",
            "Epoch 6Dis 0.8930975198745728\n",
            "Epoch 6Dis 0.3880101442337036\n",
            "Epoch 6Dis 1.0130035877227783\n",
            "Epoch 6Dis 1.2440747022628784\n",
            "Epoch 6Dis 0.9613485336303711\n",
            "Epoch 6Dis 0.38010457158088684\n",
            "Epoch 6Dis 0.477018266916275\n",
            "Epoch 6Dis 0.3143496513366699\n",
            "Epoch 6Dis 0.8332732319831848\n",
            "Epoch 6Dis 0.9780119061470032\n",
            "Epoch 6Dis 1.249629259109497\n",
            "Epoch 6Dis 1.1675326824188232\n",
            "Epoch 6Dis 1.0363925695419312\n",
            "Epoch 6Dis 1.3176854848861694\n",
            "Epoch 6Dis 1.0186489820480347\n",
            "Epoch 7Dis 1.5428805351257324\n",
            "Epoch 7Dis 0.9809203147888184\n",
            "Epoch 7Dis 0.8935492634773254\n",
            "Epoch 7Dis 0.5866047143936157\n",
            "Epoch 7Dis 1.2363804578781128\n",
            "Epoch 7Dis 1.4799622297286987\n",
            "Epoch 7Dis 0.7354148030281067\n",
            "Epoch 7Dis 0.558414101600647\n",
            "Epoch 7Dis 0.12248726934194565\n",
            "Epoch 7Dis 0.14675948023796082\n",
            "Epoch 7Dis 0.21630725264549255\n",
            "Epoch 7Dis 0.9860458970069885\n",
            "Epoch 7Dis 2.4208433628082275\n",
            "Epoch 7Dis 0.5913564562797546\n",
            "Epoch 7Dis 0.3070702850818634\n",
            "Epoch 7Dis 0.4841728210449219\n",
            "Epoch 7Dis 0.6012662053108215\n",
            "Epoch 7Dis 1.0010416507720947\n",
            "Epoch 7Dis 2.3778462409973145\n",
            "Epoch 7Dis 0.47848713397979736\n",
            "Epoch 7Dis 0.5124847292900085\n",
            "Epoch 7Dis 1.0348811149597168\n",
            "Epoch 7Dis 0.5141593217849731\n",
            "Epoch 7Dis 0.5364285707473755\n",
            "Epoch 7Dis 0.08033324778079987\n",
            "Epoch 7Dis 0.2708209753036499\n",
            "Epoch 7Dis 0.5695755481719971\n",
            "Epoch 7Dis 2.878652572631836\n",
            "Epoch 8Dis 2.3516530990600586\n",
            "Epoch 8Dis 1.078295111656189\n",
            "Epoch 8Dis 0.8671950101852417\n",
            "Epoch 8Dis 1.232612133026123\n",
            "Epoch 8Dis 0.9410295486450195\n",
            "Epoch 8Dis 0.6285618543624878\n",
            "Epoch 8Dis 0.1772802621126175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxW_rmiqi8EF"
      },
      "source": [
        ""
      ]
    }
  ]
}